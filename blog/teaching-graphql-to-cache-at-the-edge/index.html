<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no"><title>Teaching GraphQL to Cache at the Edge · Leonardo Benicio</title><meta name=description content="A deep dive into making GraphQL play nicely with edge caches without breaking declarative APIs."><link rel=alternate type=application/rss+xml title=RSS href=https://lbenicio.dev/index.xml><link rel=canonical href=https://blog.lbenicio.dev/blog/teaching-graphql-to-cache-at-the-edge/><link rel=preload href=/static/fonts/OpenSans-Regular.ttf as=font type=font/ttf crossorigin><link rel="stylesheet" href="/assets/css/fonts.min.40e2054b739ac45a0f9c940f4b44ec00c3b372356ebf61440a413c0337c5512e.css" crossorigin="anonymous" integrity="sha256-QOIFS3OaxFoPnJQPS0TsAMOzcjVuv2FECkE8AzfFUS4="><link rel="shortcut icon" href=/static/assets/favicon/favicon.ico><link rel=icon type=image/x-icon href=/static/assets/favicon/favicon.ico><link rel=icon href=/static/assets/favicon/favicon.svg type=image/svg+xml><link rel=icon href=/static/assets/favicon/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=/static/assets/favicon/favicon-16x16.png sizes=16x16 type=image/png><link rel=apple-touch-icon href=/static/assets/favicon/apple-touch-icon.png><link rel=manifest href=/static/assets/favicon/site.webmanifest><link rel=mask-icon href=/static/assets/favicon/safari-pinned-tab.svg color=#209cee><meta name=msapplication-TileColor content="#209cee"><meta name=msapplication-config content="/static/assets/favicon/browserconfig.xml"><meta name=theme-color content="#d2e9f8"><meta property="og:title" content="Teaching GraphQL to Cache at the Edge · Leonardo Benicio"><meta property="og:description" content="A deep dive into making GraphQL play nicely with edge caches without breaking declarative APIs."><meta property="og:url" content="https://blog.lbenicio.dev/blog/teaching-graphql-to-cache-at-the-edge/"><meta property="og:type" content="article"><meta property="og:image" content="https://blog.lbenicio.dev/static/assets/images/blog/graphql-edge-cache.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Teaching GraphQL to Cache at the Edge · Leonardo Benicio"><meta name=twitter:description content="A deep dive into making GraphQL play nicely with edge caches without breaking declarative APIs."><meta name=twitter:site content="@lbenicio_"><script type=application/ld+json>"{\"@context\":\"https://schema.org\",\"@type\":\"WebSite\",\"name\":\"About Leonardo Benicio\",\"url\":\"https://blog.lbenicio.dev\"}"</script><script type=application/ld+json>"{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"name\":\"Leonardo Benicio\",\"sameAs\":[\"https://github.com/lbenicio\",\"https://www.linkedin.com/in/leonardo-benicio\",\"https://twitter.com/lbenicio_\"],\"url\":\"https://blog.lbenicio.dev\"}"</script><script type=application/ld+json>"{\"@context\":\"https://schema.org\",\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"item\":\"https://blog.lbenicio.dev/\",\"name\":\"Home\",\"position\":1},{\"@type\":\"ListItem\",\"item\":\"https://blog.lbenicio.dev/\",\"name\":\"Blog\",\"position\":2},{\"@type\":\"ListItem\",\"item\":\"https://blog.lbenicio.dev/blog/teaching-graphql-to-cache-at-the-edge/\",\"name\":\"Teaching Graphql to Cache at the Edge\",\"position\":3}]}"</script><link rel="stylesheet" href="/assets/css/main.min.23cb77fd3186d94b425cf879bfff3195d7648b23b860d880dbb47fe2e115b884.css" crossorigin="anonymous" integrity="sha256-owHVkwE1+9dguAma85DLJbKG8+7vYa137CVrUeaaaxk="></head><body class="c6942b3 c03620d cf3bd2e"><script>(function(){try{document.addEventListener("gesturestart",function(e){e.preventDefault()}),document.addEventListener("touchstart",function(e){e.touches&&e.touches.length>1&&e.preventDefault()},{passive:!1});var e=0;document.addEventListener("touchend",function(t){var n=Date.now();n-e<=300&&t.preventDefault(),e=n},{passive:!1})}catch{}})()</script><a href=#content class="cba5854 c21e770 caffa6e cc5f604 cf2c31d cdd44dd c10dda9 c43876e c787e9b cddc2d2 cf55a7b c6dfb1e c9391e2">Skip to content</a>
<script>(function(){try{const e=localStorage.getItem("theme");e==="dark"&&document.documentElement.classList.add("dark");const t=document.querySelector('button[aria-label="Toggle theme"]');t&&t.setAttribute("aria-pressed",String(e==="dark"))}catch{}})();function toggleTheme(e){const s=document.documentElement,t=s.classList.toggle("dark");try{localStorage.setItem("theme",t?"dark":"light")}catch{}try{var n=e&&e.nodeType===1?e:document.querySelector('button[aria-label="Toggle theme"]');n&&n.setAttribute("aria-pressed",String(!!t))}catch{}}</script><header class="cd019ba c98dfae cdd44dd cfdda01 c9ee25d ce2dc7a cd72dd7 cc0dc37" role=banner><div class="cfdda01 c6942b3 ccf47f4 c7c11d8"><a href=/ class="c87e2b0 c6942b3 c7c11d8 c1838fa cb594e4" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=32 height=32 class="c3de71a c4d5191">
<span class="cf8f011 c4d1253 cbd72bc cd7e69e">Leonardo Benicio</span></a><div class="c6942b3 c85cbd4 c7c11d8 ca798da c1838fa c7a0580"><nav class="cc1689c cd9b445 c75065d c04bab1" aria-label=Main><a href=/ class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Home</a>
<a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">About</a>
<a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Timeline</a>
<a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Reading</a>
<a href=https://lbenicio.dev/publications target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Publications</a>
<a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Contact</a></nav><button id="i1d73d4" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 c097fa1 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" onclick=toggleTheme(this) aria-label="Toggle theme" aria-pressed=false title="Toggle theme">
<svg class="cb26e41 c50ceea cb69a5c c4f45c8 c8c2c40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="cb26e41 c8fca2b cb69a5c c4f45c8 cc1689c c9c27ff" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><circle cx="12" cy="12" r="4"/><path d="M12 2v4"/><path d="M12 18v4"/><path d="M2 12h4"/><path d="M18 12h4"/><path d="M4.93 4.93l2.83 2.83"/><path d="M16.24 16.24l2.83 2.83"/><path d="M6.34 17.66l2.83-2.83"/><path d="M14.83 9.17l2.83-2.83"/></svg>
<span class="cba5854">Toggle theme</span></button><div class="c658bcf c097fa1"><details class="ccd45bf"><summary class="cc7a258 c1d6c20 c7c11d8 c1d0018 c10dda9 c000b66 cf55a7b"><svg class="c20e4eb cb58471" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
<span class="cba5854">Open menu</span></summary><div class="ce49c1e c437fa9 c1b4412 c8c0110 c887979 c43876e c10dda9 c60a4cc c401fa1 cb2c551 cf514a5 cadfe0b ce3dbb2 c72ad85 cbd4710 c6988b4"><a href=/ class="c62aaf0 c364589 c6942b3 c7c11d8 c1838fa" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=24 height=24 class="c20e4eb cb58471">
<span class="cf8f011 c7c1b66 cbd72bc cbac0b8">Leonardo Benicio</span></a><nav class="c6942b3 c03620d cd69733"><a href=/ class="c4d1253 cbbda39 c3ecea6 c19ee42">Home</a>
<a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c4d1253 cbbda39 c3ecea6 c19ee42">About</a>
<a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c4d1253 cbbda39 c3ecea6 c19ee42">Timeline</a>
<a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c4d1253 cbbda39 c3ecea6 c19ee42">Reading</a>
<a href=https://lbenicio.dev/publications target=_blank rel="noopener noreferrer" class="c4d1253 cbbda39 c3ecea6 c19ee42">Publications</a>
<a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c4d1253 cbbda39 c3ecea6 c19ee42">Contact</a></nav></div></details></div></div></div></header><div class="caffa6e c437fa9 ce9aced c97bba6 c15da2a c975cba" role=complementary aria-label="GitHub repository"><div class="c9d056d c252f85 ca22532 ca88a1a c876315"><div class="c6942b3 c7c11d8 c1d0018 cd1fd22 c6066e4 c43876e ce3d5b6 caa20d2 c3ecea6 c0cd2e2 cddc2d2 c3ed5c9 cd4074c c876315"><a href=https://github.com/lbenicio/aboutme target=_blank rel="noopener noreferrer" class="c6942b3 c7c11d8 cd1fd22 c71bae8 cfac1ac c19ee42 c25dc7c cb40739 cbbda39 cf55a7b" aria-label="View source on GitHub"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="cb26e41 c41bcd4 cf17690 cfa4e34 c78d562" aria-hidden="true"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></svg>
<span class="cb5c327 cd7e69e">Fork me</span></a></div></div></div><main id="i7eccc0" class="cfdda01 c5df473 c0eecc8 c85cbd4" role=main aria-label=Content><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Teaching Graphql to Cache at the Edge</span></li></ol></nav><article class="c461ba0 c1c203f cfb6084 c995404 c6ca165"><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Teaching Graphql to Cache at the Edge</span></li></ol></nav><header class="c8aedc7"><h1 class="cf304bc c6fb0fe cf8f011 cc484e1">Teaching GraphQL to Cache at the Edge</h1><div class="c277478 c3ecea6 c8fb24a">2022-09-03
· Leonardo Benicio</div><div class="c1a1a3f c8124f2"><img src=/static/assets/images/blog/graphql-edge-cache.png alt class="cfdda01 c524300 c677556"></div><p class="lead c3ecea6">A deep dive into making GraphQL play nicely with edge caches without breaking declarative APIs.</p></header><div class="content"><p>GraphQL promises tailor-made responses, but tailor-made payloads resist caching. For years, we treated GraphQL responses as ephemeral: generated on demand, personalized, too unique to reuse. Then mobile latency complaints reached a boiling point. Edge locations sat underutilized while origin clusters sweated. We set out to teach GraphQL how to cache—respecting declarative queries, personalization boundaries, and real-time freshness. This is the story of building an edge caching layer that felt invisible to developers yet shaved hundreds of milliseconds off user interactions.</p><p>If you&rsquo;ve ever been told &ldquo;GraphQL can&rsquo;t cache,&rdquo; this post is for you. We&rsquo;ll explore schema annotations, persisted queries, cache keys, invalidation, and the human choreography required to make deductive caching decisions feel natural. Expect war stories: cache stampedes, stale user state, and the joy of a 95th percentile response that finally fits under 150 ms.</p><h2 id="1-why-graphql-resists-caching">1. Why GraphQL resists caching</h2><p>Traditional REST endpoints map one URL to one resource. Caches key off URLs easily. GraphQL collapses everything into a single endpoint, with queries describing desired fields. The same endpoint can produce vastly different responses per request. Personalized data (like user settings), fine-grained field selection, and mutations complicate caching. Developers often disable caching to avoid serving wrong data. Result: every query hits origin, even if thousands of users ask the same question.</p><p>We needed a strategy that respected GraphQL&rsquo;s flexibility while unlocking reuse. Our hypothesis: most queries have structure. With the right metadata and discipline, we can derive cacheable signatures.</p><h2 id="2-persisted-queries-and-signatures">2. Persisted queries and signatures</h2><p>We started by adopting persisted queries. Clients register queries ahead of time, receiving a hash identifier. At runtime, clients send the hash and variables instead of raw query text. Persisted queries prevent injection attacks and standardize structure. They also produce stable signatures we can use for caching. We stored persisted query metadata in a schema registry, including cache hints like TTL and scope.</p><p>Each persisted query includes:</p><ul><li>Query hash (SHA-256).</li><li>GraphQL document with field selections.</li><li>Variable schema and allowed defaults.</li><li>Cache policy annotation (discussed later).</li><li>Tags indicating personalization requirements.</li></ul><p>Runtime requests include the hash, variables, and authentication context. Edge caches reconstruct a cache key: <code>hash + normalized variables + user scope</code>. Normalization ensures variable ordering and default values don&rsquo;t produce different keys.</p><h2 id="3-cache-policy-annotations">3. Cache policy annotations</h2><p>We extended our GraphQL schema with directives, inspired by <code>@cacheControl</code> but richer. Example:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class="language-graphql" data-lang=graphql><span style=display:flex><span><span style=color:#ff7b72>type</span><span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>Query</span><span style=color:#6e7681> </span>{<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>  </span><span style=color:#79c0ff>product</span>(<span style=color:#79c0ff>id</span>:<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>ID</span>!):<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>Product</span><span style=color:#6e7681> </span><span style=color:#d2a8ff;font-weight:700>@cacheable</span>(<span style=color:#79c0ff>ttl</span>:<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>300</span>,<span style=color:#6e7681> </span><span style=color:#79c0ff>scope</span>:<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>PUBLIC</span>,<span style=color:#6e7681> </span><span style=color:#79c0ff>vary</span>:<span style=color:#6e7681> </span>[<span style=color:#a5d6ff>&#34;locale&#34;</span>,<span style=color:#6e7681> </span><span style=color:#a5d6ff>&#34;currency&#34;</span>])<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681></span>}<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681></span><span style=color:#f0883e;font-weight:700>type</span><span style=color:#6e7681> </span><span style=color:#79c0ff>Product</span><span style=color:#6e7681> </span>{<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>  </span><span style=color:#79c0ff>price</span>(<span style=color:#79c0ff>currency</span>:<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>Currency</span>!):<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>Money</span><span style=color:#6e7681> </span><span style=color:#d2a8ff;font-weight:700>@cacheable</span>(<span style=color:#79c0ff>ttl</span>:<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>120</span>,<span style=color:#6e7681> </span><span style=color:#79c0ff>scope</span>:<span style=color:#6e7681> </span><span style=color:#f0883e;font-weight:700>USER</span>)<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681></span>}<span style=color:#6e7681>
</span></span></span></code></pre></div><p>Directives describe caching intent:</p><ul><li><code>ttl</code>: seconds to cache.</li><li><code>scope</code>: <code>PUBLIC</code>, <code>PRIVATE</code>, or <code>USER</code> (scoped to authenticated identity).</li><li><code>vary</code>: list of headers or variables affecting cache key.</li><li><code>invalidation</code> rules for downstream updates.</li></ul><p>The schema registry compiles directives into metadata consumed by the edge layer. Developers think declaratively; the platform handles implementation.</p><h2 id="4-edge-cache-architecture">4. Edge cache architecture</h2><p>We deployed caching capabilities into our global edge network (based on Varnish and custom Lua). The flow:</p><ol><li>Client sends persisted query hash and variables to edge.</li><li>Edge looks up query metadata.</li><li>Edge computes cache key, including scope tokens (e.g., user ID hashed into a token) and vary parameters.</li><li>On cache hit, edge returns stored response.</li><li>On miss, edge forwards request to origin GraphQL gateway.</li><li>Origin responds with data and cache metadata headers.</li><li>Edge stores response according to TTL and scope.</li></ol><p>We partitioned caches by scope: public caches share across users; user-scoped caches store per-identity entries, with quotas to avoid unbounded growth. Edge nodes replicate metadata but not private responses.</p><h2 id="5-normalizing-variables-and-responses">5. Normalizing variables and responses</h2><p>Cache keys must be deterministic. Variables include objects or arrays; we normalized them using canonical JSON serialization (sorted keys, trimmed whitespace). We rejected requests with unregistered variable shapes to prevent bypassing caching via shape drift.</p><p>Responses include timestamp fields and ephemeral IDs. To maximize cache hits, we taught the origin to omit volatile fields unless necessary. For fields requiring freshness (e.g., &ldquo;time since last login&rdquo;), we computed them client-side or via on-demand fragments.</p><h2 id="6-handling-mutations-and-invalidation">6. Handling mutations and invalidation</h2><p>Mutations change data and must invalidate caches. We built an invalidation bus. When a mutation commits, it emits events describing affected entities (e.g., Product 123). The cache layer subscribes to the bus and evicts relevant cache keys.</p><p>We map entities to queries via a dependency graph stored in Redis. When a persisted query runs, origin records which entities contributed to the response. Dependencies include entity IDs and field-level hints. The invalidation worker uses this map to evict precise cache entries. To avoid stale reads during propagation, we adopted write-through semantics: origins respond with updated payloads and include <code>Cache-Status: Bypass</code> headers, prompting edges to refresh entries.</p><h2 id="7-staleness-and-revalidation">7. Staleness and revalidation</h2><p>Some data tolerates staleness. We implemented stale-while-revalidate (SWR). During TTL, cache returns responses immediately. After TTL but within <code>staleWindow</code>, edge serves stale response while asynchronously fetching fresh data. Developers configure these windows via directives. SWR improved tail latency and absorbed thundering herds during revalidation.</p><h2 id="8-personalization-boundaries">8. Personalization boundaries</h2><p>Personalized data complicates caching. We categorized personalization:</p><ul><li><strong>Identity-based</strong>: user profile info. Cache per user with small TTLs.</li><li><strong>Segment-based</strong>: locale, subscription tier, feature flags. We derived cache keys from segment tokens rather than raw attributes.</li><li><strong>Opaque</strong>: data unique per request (e.g., recommendations). We bypass caching.</li></ul><p>We encouraged developers to factor queries into fragments: cacheable public data + personalized overlays fetched separately. This decomposition let us cache heavy public fragments while leaving private data dynamic.</p><h2 id="9-observability-and-metrics">9. Observability and metrics</h2><p>We instrumented the cache layer with metrics:</p><ul><li>Hit/miss rates by query hash.</li><li>Average TTL utilization.</li><li>Invalidation latency from mutation to eviction.</li><li>Cache size per scope and edge region.</li><li>Origin offload percentage.</li><li>Error rates when cache metadata missing or malformed.</li></ul><p>Dashboards spotlight top misses, guiding optimization. We logged cache decision traces, letting developers debug why a request bypassed cache. Trace entries show hash, resolved key, TTL, scope, and invalidation watchers.</p><h2 id="10-developer-workflow">10. Developer workflow</h2><p>Implementing caching required new workflows:</p><ol><li>Design GraphQL schema with cache directives.</li><li>Register persisted query with metadata, including default variables.</li><li>Monitor observability dashboards after deployment.</li><li>Iterate: adjust TTLs, add vary dimensions, refactor fragments.</li></ol><p>We built lint rules: queries lacking cache directives emit warnings. A CLI tool simulates requests, showing resolved cache keys and predicted hitability. Pull request templates prompt developers to declare caching decisions and invalidation strategy.</p><h2 id="11-edge-logic-implementation">11. Edge logic implementation</h2><p>Edge behavior runs in Lua. Snippet:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class="language-lua" data-lang=lua><span style=display:flex><span><span style=color:#ff7b72>local</span> metadata <span style=color:#ff7b72;font-weight:700>=</span> get_query_metadata(hash)
</span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> <span style=color:#ff7b72;font-weight:700>not</span> metadata.cacheable <span style=color:#ff7b72>then</span>
</span></span><span style=display:flex><span>  <span style=color:#ff7b72>return</span> fetch_origin()
</span></span><span style=display:flex><span><span style=color:#ff7b72>end</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>local</span> key <span style=color:#ff7b72;font-weight:700>=</span> build_cache_key(hash, metadata, request)
</span></span><span style=display:flex><span><span style=color:#ff7b72>local</span> cached <span style=color:#ff7b72;font-weight:700>=</span> cache_lookup(key)
</span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> cached <span style=color:#ff7b72>then</span>
</span></span><span style=display:flex><span>  <span style=color:#ff7b72>return</span> cached
</span></span><span style=display:flex><span><span style=color:#ff7b72>end</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>local</span> response <span style=color:#ff7b72;font-weight:700>=</span> fetch_origin()
</span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> response.cacheable <span style=color:#ff7b72>then</span>
</span></span><span style=display:flex><span>  cache_store(key, response.body, metadata.ttl)
</span></span><span style=display:flex><span><span style=color:#ff7b72>end</span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>return</span> response
</span></span></code></pre></div><p>We handle <code>stale-while-revalidate</code> by storing extra metadata alongside the payload and scheduling background refreshes via a lightweight job queue. Lua coroutines allow asynchronous fetches without blocking other requests.</p><h2 id="12-security-and-correctness">12. Security and correctness</h2><p>Caching introduces risks: leaking user data across tenants, serving stale authorization state. We mitigated by:</p><ul><li>Encrypting cache entries for user scope, with keys derived per tenant.</li><li>Including authorization scopes in cache keys, so changes to permissions trigger cache misses.</li><li>Validating that responses lack Set-Cookie or sensitive headers before caching.</li><li>Running automated tests injecting tainted data to ensure isolation.</li></ul><p>We also audited GraphQL resolvers to ensure <code>@cacheable(scope: PUBLIC)</code> annotations only appear on resolvers that never touch user-specific state.</p><h2 id="13-handling-real-time-data">13. Handling real-time data</h2><p>Some GraphQL queries power real-time dashboards. For them, we combined caching with subscriptions. Base data loads from cache; overlays arrive via subscriptions. We tuned TTLs to seconds and used SWR to mask refresh jitter. For stock tickers, we kept caches disabled but optimized resolvers separately.</p><h2 id="14-cold-start-optimization">14. Cold start optimization</h2><p>Edge nodes warm caches opportunistically. During deploys, we run prefetch jobs replaying popular queries through edges, priming caches. Prefetch uses safe credentials and respects rate limits. We also share cache digests across regions: when region A computes a new response, it publishes digest metadata. Regions B/C decide whether to fetch proactively based on popularity.</p><h2 id="15-handling-graphql-directives-and-fragments">15. Handling GraphQL directives and fragments</h2><p>Developers use conditional directives (<code>@include</code>, <code>@skip</code>). We encode directive outcomes into cache keys. For fragments, we compute structural hashes. This ensures different selections produce distinct cache keys even if they share base query hash.</p><h2 id="16-testing-and-validation">16. Testing and validation</h2><p>We expanded integration tests. Test suites run queries against a sandbox edge environment, asserting expected caching behavior. We built a &ldquo;cache inspector&rdquo; tool that visualizes dependency graphs, TTL countdowns, and invalidation triggers. QA uses the inspector to confirm correct behavior during feature rollouts.</p><h2 id="17-case-study-product-detail-pages">17. Case study: product detail pages</h2><p>Before caching, product pages fetched data via three GraphQL queries, totaling 450 ms median. After applying cache directives, persisted queries, and fragment decomposition, we achieved:</p><ul><li>80% cache hit rate on public product data.</li><li>120 ms median response at the edge.</li><li>65% reduction in origin CPU load.</li></ul><p>Observability also surfaced hidden dependencies. A marketing banner resolver pulled inventory counts indirectly, triggering invalidations every time stock refreshed. Once telemetry highlighted the culprit, we split the resolver into two persisted queries—one cache-friendly, one dynamic—restoring stability. The lesson: caching audits double as architecture reviews, exposing tight coupling masked by GraphQL&rsquo;s abstraction.</p><p>Invalidation triggered when merchants updated inventory. The dependency graph ensured targeted evictions, with average 1.8 seconds from mutation commit to cache purge. Users saw fresher data than before because origin computations no longer throttled under load.</p><h2 id="18-case-study-user-dashboards">18. Case study: user dashboards</h2><p>Dashboards combined heavy analytics (public) with personalized summaries. We cached analytics fragments for 10 minutes. User-specific widgets fetched live data. Results: 45% latency reduction, but more importantly, developers embraced caching by default, adding directives as part of schema design.</p><p>Dashboards also benefited from network cost savings. Edge caches served 72% of total dashboard traffic, shrinking inter-region data transfer costs by five figures monthly. Product managers used the newfound slack to experiment with richer visualizations, confident that caches would shield origin layers. As we expanded internationally, localized dashboards reused cached global fragments, letting small regional teams launch new experiences without complex backend rewrites.</p><h2 id="19-failure-modes">19. Failure modes</h2><p>We hit bugs:</p><ul><li>Missing invalidation events left stale prices. We added replay queues and idempotent handlers.</li><li>Cache stampedes when TTL expired simultaneously. SWR plus jittered TTL solved this.</li><li>Oversized responses busted cache memory. We enforced payload size limits and encouraged field-level pagination.</li><li>Hash collisions (extremely rare) triggered fallback to origin. We now check for collisions when registering persisted queries.</li></ul><h2 id="20-metrics-and-dashboards-that-kept-us-honest">20. Metrics and dashboards that kept us honest</h2><p>Caching success hinges on visibility. Our canonical dashboard includes:</p><ul><li><strong>Hit rate heatmap</strong>: rows for services, columns for edge regions. Cells colored by hit rate with tooltips showing sample size. Outliers reveal misconfigured directives.</li><li><strong>TTL utilization</strong>: measures how long entries survive relative to configured TTL. Early evictions indicate invalidation churn; overlong survival suggests room to shorten TTL.</li><li><strong>Origin offload</strong>: charts request volume absorbed by caches. We compare to baseline weeks to quantify savings.</li><li><strong>Staleness monitor</strong>: tracks percentage of responses served from stale-while-revalidate along with latency impact. Spikes expose blocked revalidation jobs.</li><li><strong>Error correlation</strong>: overlays cache bypass reasons (auth mismatch, schema drift) with origin error rates, helping teams prioritize fixes.</li></ul><p>Dashboards feed weekly reviews where teams annotate anomalies. We export snapshots for executive updates, translating cache metrics into revenue and latency language.</p><h2 id="21-operational-runbook">21. Operational runbook</h2><p>We codified cache operations into a runbook:</p><ol><li><strong>Incident triage</strong>: confirm scope by checking hit rate heatmap and origin offload. If hit rates plummet across regions, suspect metadata outages.</li><li><strong>Invalidate safely</strong>: prefer targeted invalidation via dependency graph. Only purge entire caches with VP approval; mass purges risk stampedes.</li><li><strong>Warm start</strong>: after purges or deploys, trigger prefetch jobs for top queries using traffic recordings. Monitor CPU and bandwidth while warming.</li><li><strong>Measure blast radius</strong>: use synthetic probes to simulate user flows during incidents, ensuring caches recover globally.</li><li><strong>Postmortem</strong>: capture root causes, update directives or tooling, and add regression tests. Share learnings in the cache guild channel.</li></ol><p>Runbooks live alongside playbooks for scaling, maintenance windows, and schema migrations. We rehearse quarterly with game days focusing on invalidation storms and edge outages.</p><h2 id="22-frequently-asked-questions">22. Frequently asked questions</h2><p><strong>&ldquo;Does caching break GraphQL&rsquo;s flexibility?&rdquo;</strong> No—developers still compose fragments freely. Persisted queries cover 95% of traffic; dynamic queries fall back to origin with minimal overhead.</p><p><strong>&ldquo;What about user-specific data?&rdquo;</strong> Cache scope handles it. User caches live in encrypted stores with tight TTLs and quotas. Truly unique responses bypass caching gracefully.</p><p><strong>&ldquo;How do we prevent stale feature flags?&rdquo;</strong> Flags become part of vary parameters. When flag sets change, cache keys rotate automatically, forcing fresh fetches.</p><p><strong>&ldquo;Is schema evolution painful?&rdquo;</strong> Schema registry enforces versioning. When fields deprecate, we maintain aliasing until caches expire. Migration guides outline safe rollout patterns.</p><p><strong>&ldquo;Do we still need CDNs?&rdquo;</strong> Absolutely. Edge caching complements CDN delivery for static assets. In fact, we piggybacked on the CDN network to deploy our caching logic.</p><h2 id="23-migration-timeline-example">23. Migration timeline example</h2><p>Our 12-month rollout followed phases:</p><ul><li><strong>Months 0–2</strong>: build schema registry, define cache directives, implement persisted query infrastructure.</li><li><strong>Months 2–4</strong>: onboard search pages as pilot, tune invalidation bus, create dashboards.</li><li><strong>Months 4–6</strong>: expand to product detail and checkout flows, deliver developer training, integrate QA automation.</li><li><strong>Months 6–9</strong>: add personalization overlays, enforce lint rules, negotiate cache guardrails with security.</li><li><strong>Months 9–12</strong>: migrate long-tail services, optimize cost, formalize cache guild, and publish public post describing performance wins.</li></ul><p>Pausing between phases allowed us to absorb feedback and iterate on tooling. Attempting a big-bang migration would have overwhelmed support teams.</p><h2 id="24-glossary-for-cache-literacy">24. Glossary for cache literacy</h2><ul><li><strong>Cache scope</strong>: level of sharing—public, private, user-specific—that determines key structure and storage location.</li><li><strong>Cache stampede</strong>: surge of requests when entries expire simultaneously, overwhelming origin.</li><li><strong>Dependency graph</strong>: mapping between backend entities and queries relying on them, used for precise invalidation.</li><li><strong>Persisted query</strong>: pre-registered GraphQL query identified by hash, enabling stable cache keys.</li><li><strong>SWR (stale-while-revalidate)</strong>: strategy serving stale data briefly while refreshing in background.</li></ul><p>We plaster these definitions on dashboards and in onboarding decks to align vocabulary across frontend, backend, and platform teams.</p><h2 id="25-analytics-and-experimentation">25. Analytics and experimentation</h2><p>Caching impacted experimentation. A/B tests rely on quick propagation of feature flags. We integrated experiment assignment into cache keys via vary parameters. Experiment frameworks emit metadata so caches respect segmentation. We created an &ldquo;experiment-safe&rdquo; directive ensuring TTLs align with experiment duration.</p><h2 id="26-developer-education">26. Developer education</h2><p>We ran workshops titled &ldquo;GraphQL Cache Literacy.&rdquo; Engineers practiced annotating schemas, analyzing traces, and debugging misses. We published a playbook with recipes: caching lists, nested resolvers, trending lists, personalization overlays. A dedicated Slack channel paired developers with caching experts for rapid feedback.</p><h2 id="27-business-outcomes">27. Business outcomes</h2><p>Post-rollout metrics:</p><ul><li>95th percentile latency for mobile product queries dropped from 620 ms to 210 ms.</li><li>CDN egress decreased by 33%, saving costs.</li><li>Origin cluster CPU utilization reduced by 48% during peak shopping season.</li><li>Cache correctness incidents fell below 0.2 per month after initial shakedown.</li></ul><p>Customer satisfaction surveys mentioned faster load times. Teams adopted caching for 70% of new queries within six months.</p><h2 id="28-future-evolution">28. Future evolution</h2><p>We&rsquo;re experimenting with edge compute that can execute lightweight GraphQL resolvers near users, further reducing origin dependency. We&rsquo;re also exploring signed exchange formats so caches can pre-validate responses. Another frontier is &ldquo;privacy-aware caching&rdquo; that integrates consent states into cache decisions to avoid storing responses for users opting out of personalization.</p><h2 id="29-toolchain-sampler">29. Toolchain sampler</h2><ul><li><strong>Schema Registry UI</strong> – browse persisted queries, inspect directives, and monitor TTL usage per field. Ships with diff views for schema changes.</li><li><strong>Cache Inspector CLI</strong> – run <code>cache-inspector trace &lt;hash></code> to visualize dependency graphs and cache decisions. Supports exporting mermaid diagrams for docs.</li><li><strong>Invalidation Simulator</strong> – replay mutation streams against staging caches to measure eviction accuracy before production rollouts.</li><li><strong>Edge Dev Sandbox</strong> – local Docker compose environment emulating edge Lua runtime, enabling developers to test logic without deploying globally.</li><li><strong>Directive Linter</strong> – ESLint plugin ensuring React components reference persisted queries with correct cache hints.</li></ul><p>We maintain playbooks for each tool and host monthly office hours where teams share scripts that automate repetitive cache tasks.</p><h2 id="30-community-and-continued-learning">30. Community and continued learning</h2><p>We contribute to upstream projects like Apollo and GraphQL Foundation working groups. Our engineers present lessons at meetups under the banner &ldquo;Caching the Uncacheable.&rdquo; Favorite resources include:</p><ul><li><strong>&ldquo;Caching GraphQL at Scale&rdquo; (GraphQL Conf 2022 talk)</strong> – compares multiple industry approaches.</li><li><strong>Apollo Router documentation</strong> – rich examples for persisted queries and cache control.</li><li><strong>&ldquo;Stitching Edge and Origin&rdquo; (CDN Summit 2023)</strong> – explores edge compute patterns for GraphQL.</li><li><strong>OpenTelemetry instrumentation recipes</strong> – invaluable for embedding cache metadata into traces.</li></ul><p>Sharing progress publicly keeps us accountable and attracts collaborators who push the ecosystem forward.</p><h2 id="31-conclusion">31. Conclusion</h2><p>GraphQL and caching need not be enemies. By embracing declarative metadata, disciplined workflows, and robust invalidation, we transformed a dynamic API into a cache-friendly platform. The payoff was faster experiences and happier engineers. Teaching GraphQL to cache required patience, storytelling, and relentless measurement—but the lesson stuck. When teams now design queries, their first question is &ldquo;how will this cache?"—proof that culture follows architecture.</p><h3 id="further-reading">Further reading</h3><ul><li><strong>&ldquo;Cache Control for GraphQL&rdquo; (Apollo blog)</strong> – deep dive into schema directives and caching semantics.</li><li><strong>&ldquo;Designing Distributed Cache Invalidation&rdquo; (USENIX ATC 2021)</strong> – research perspective on dependency graphs.</li><li><strong>&ldquo;Edge Compute Patterns&rdquo; (Cloudflare Developer Docs)</strong> – practical recipes for executing logic at the edge.</li><li><strong>&ldquo;Experimentation with Cached APIs&rdquo; (Shopify Engineering)</strong> – lessons on keeping A/B tests statistically sound under caching.</li><li><strong>GraphQL Foundation Working Groups</strong> – community forums discussing standardization of cache metadata.</li></ul><h3 id="acknowledgements">Acknowledgements</h3><p>Edge SREs, frontend engineers, and the schema governance crew co-authored these practices; their persistence turned skepticism into muscle memory.</p></div><footer class="ce1a612 c6dfb1e c3ecea6"><div class="c364589">Categories:
<a href=/categories/Engineering/>Engineering</a></div><div>Tags:
<a href=/tags/graphql/>#graphql</a>, <a href=/tags/edge/>#edge</a>, <a href=/tags/performance/>#performance</a>, <a href=/tags/caching/>#caching</a>, <a href=/tags/frontend/>#frontend</a></div></footer></article></main><footer class="ccdf0e8" role=contentinfo aria-label=Footer><div class="cfdda01 c133889 c5df473 c0eecc8 c69618a c6942b3 c03620d c2a9f27 c7c11d8 c82c52d c14527b"><div class="c6dfb1e c3ecea6 c39ef11 c88ae6f">&copy; 2025 Leonardo Benicio. All rights
reserved.</div><div class="c6942b3 c7c11d8 cd1fd22"><a href=https://github.com/lbenicio target=_blank rel="noopener noreferrer" aria-label=GitHub class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.5-.67 1.08-.82 1.7s-.2 1.27-.18 1.9V22"/></svg>
<span class="cba5854">GitHub</span>
</a><a href=https://www.linkedin.com/in/leonardo-benicio target=_blank rel="noopener noreferrer" aria-label=LinkedIn class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452H17.21V14.86c0-1.333-.027-3.046-1.858-3.046-1.86.0-2.145 1.45-2.145 2.948v5.69H9.069V9h3.112v1.561h.044c.434-.82 1.494-1.686 3.074-1.686 3.29.0 3.897 2.165 3.897 4.983v6.594zM5.337 7.433a1.805 1.805.0 11-.002-3.61 1.805 1.805.0 01.002 3.61zM6.763 20.452H3.911V9h2.852v11.452z"/></svg>
<span class="cba5854">LinkedIn</span>
</a><a href=https://twitter.com/lbenicio_ target=_blank rel="noopener noreferrer" aria-label=Twitter class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M19.633 7.997c.013.177.013.354.013.53.0 5.386-4.099 11.599-11.6 11.599-2.31.0-4.457-.676-6.265-1.842.324.038.636.05.972.05 1.91.0 3.67-.65 5.07-1.755a4.099 4.099.0 01-3.827-2.84c.25.039.5.064.763.064.363.0.726-.051 1.065-.139A4.091 4.091.0 012.542 9.649v-.051c.538.3 1.162.482 1.824.507A4.082 4.082.0 012.54 6.7c0-.751.2-1.435.551-2.034a11.63 11.63.0 008.44 4.281 4.615 4.615.0 01-.101-.938 4.091 4.091.0 017.078-2.799 8.1 8.1.0 002.595-.988 4.112 4.112.0 01-1.8 2.261 8.2 8.2.0 002.357-.638A8.824 8.824.0 0119.613 7.96z"/></svg>
<span class="cba5854">Twitter</span></a></div></div></footer></body></html>