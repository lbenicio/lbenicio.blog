<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no"><title>Lock-Free Data Structures: Concurrency Without the Wait · Leonardo Benicio</title><meta name=description content="Explore how lock-free algorithms achieve thread-safe data access without traditional locks. Learn the theory behind compare-and-swap, the ABA problem, memory ordering, and practical implementations that power high-performance systems."><link rel=alternate type=application/rss+xml title=RSS href=https://lbenicio.dev/index.xml><link rel=canonical href=https://blog.lbenicio.dev/blog/lock-free-data-structures-concurrency-without-the-wait/><link rel=preload href=/static/fonts/OpenSans-Regular.ttf as=font type=font/ttf crossorigin><link rel="stylesheet" href="/assets/css/fonts.min.40e2054b739ac45a0f9c940f4b44ec00c3b372356ebf61440a413c0337c5512e.css" crossorigin="anonymous" integrity="sha256-QOIFS3OaxFoPnJQPS0TsAMOzcjVuv2FECkE8AzfFUS4="><link rel="shortcut icon" href=/static/assets/favicon/favicon.ico><link rel=icon type=image/x-icon href=/static/assets/favicon/favicon.ico><link rel=icon href=/static/assets/favicon/favicon.svg type=image/svg+xml><link rel=icon href=/static/assets/favicon/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=/static/assets/favicon/favicon-16x16.png sizes=16x16 type=image/png><link rel=apple-touch-icon href=/static/assets/favicon/apple-touch-icon.png><link rel=manifest href=/static/assets/favicon/site.webmanifest><link rel=mask-icon href=/static/assets/favicon/safari-pinned-tab.svg color=#209cee><meta name=msapplication-TileColor content="#209cee"><meta name=msapplication-config content="/static/assets/favicon/browserconfig.xml"><meta name=theme-color content="#d2e9f8"><meta property="og:title" content="Lock-Free Data Structures: Concurrency Without the Wait · Leonardo Benicio"><meta property="og:description" content="Explore how lock-free algorithms achieve thread-safe data access without traditional locks. Learn the theory behind compare-and-swap, the ABA problem, memory ordering, and practical implementations that power high-performance systems."><meta property="og:url" content="https://blog.lbenicio.dev/blog/lock-free-data-structures-concurrency-without-the-wait/"><meta property="og:type" content="article"><meta property="og:image" content="https://blog.lbenicio.dev/static/assets/images/blog/lock-free-data-structures-concurrency.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Lock-Free Data Structures: Concurrency Without the Wait · Leonardo Benicio"><meta name=twitter:description content="Explore how lock-free algorithms achieve thread-safe data access without traditional locks. Learn the theory behind compare-and-swap, the ABA problem, memory ordering, and practical implementations that power high-performance systems."><meta name=twitter:site content="@lbenicio_"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","name":"About Leonardo Benicio","url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Person","name":"Leonardo Benicio","sameAs":["https://github.com/lbenicio","https://www.linkedin.com/in/leonardo-benicio","https://twitter.com/lbenicio_"],"url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Home","position":1},{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Blog","position":2},{"@type":"ListItem","item":"https://blog.lbenicio.dev/blog/lock-free-data-structures-concurrency-without-the-wait/","name":"Lock Free Data Structures Concurrency Without the Wait","position":3}]}</script><link rel="stylesheet" href="/assets/css/main.min.1e8a566ac8bc3f0664d0db4ec8a015b07421c33fa11d336a6b914522a9cabf30.css" crossorigin="anonymous" integrity="sha256-6lhUOpwCHMSMROmggsVSp3AHKud6gBrIFGTzl3GV4BY="></head><body class="c6942b3 c03620d cf3bd2e"><script>(function(){try{document.addEventListener("gesturestart",function(e){e.preventDefault()}),document.addEventListener("touchstart",function(e){e.touches&&e.touches.length>1&&e.preventDefault()},{passive:!1});var e=0;document.addEventListener("touchend",function(t){var n=Date.now();n-e<=300&&t.preventDefault(),e=n},{passive:!1})}catch{}})()</script><a href=#content class="cba5854 c21e770 caffa6e cc5f604 cf2c31d cdd44dd c10dda9 c43876e c787e9b cddc2d2 cf55a7b c6dfb1e c9391e2">Skip to content</a>
<script>(function(){try{const e=localStorage.getItem("theme");e==="dark"&&document.documentElement.classList.add("dark");const t=document.querySelector('button[aria-label="Toggle theme"]');t&&t.setAttribute("aria-pressed",String(e==="dark"))}catch{}})();function toggleTheme(e){const s=document.documentElement,t=s.classList.toggle("dark");try{localStorage.setItem("theme",t?"dark":"light")}catch{}try{var n=e&&e.nodeType===1?e:document.querySelector('button[aria-label="Toggle theme"]');n&&n.setAttribute("aria-pressed",String(!!t))}catch{}}(function(){function e(){try{return document.documentElement.classList.contains("dark")?"dark":"light"}catch{return"light"}}function n(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(0)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!1,s.style.display="block"}catch{}o.setAttribute("aria-expanded","true"),n.setAttribute("aria-hidden","false");try{document.body.classList.add("c150bbe")}catch{}const i=document.getElementById("i190984");i&&i.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_open",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function t(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(100%)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!0,s.style.display="none"}catch{}o.setAttribute("aria-expanded","false"),n.setAttribute("aria-hidden","true");try{document.body.classList.remove("c150bbe")}catch{}o.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_close",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function s(e){e.key==="Escape"&&t("escape")}window.__openMobileMenu=n,window.__closeMobileMenu=t;try{window.addEventListener("keydown",s,!0)}catch{}})()</script><header class="cd019ba c98dfae cdd44dd cfdda01 c9ee25d ce2dc7a cd72dd7 cc0dc37" role=banner><div class="cfdda01 c6942b3 ccf47f4 c7c11d8"><a href=/ class="c87e2b0 c6942b3 c7c11d8 c1838fa cb594e4" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=32 height=32 class="c3de71a c4d5191">
<span class="cf8f011 c4d1253 cbd72bc cd7e69e">Leonardo Benicio</span></a><div class="c6942b3 c85cbd4 c7c11d8 ca798da c1838fa c7a0580"><nav class="cc1689c cd9b445 c75065d c04bab1" aria-label=Main><a href=/ class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Home</a>
<a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">About</a>
<a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Timeline</a>
<a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Reading</a>
<a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Publications</a>
<a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Contact</a></nav><button id="i1d73d4" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 c097fa1 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" onclick=toggleTheme(this) aria-label="Toggle theme" aria-pressed=false title="Toggle theme">
<svg class="cb26e41 c50ceea cb69a5c c4f45c8 c8c2c40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="cb26e41 c8fca2b cb69a5c c4f45c8 cc1689c c9c27ff" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><circle cx="12" cy="12" r="4"/><path d="M12 2v4"/><path d="M12 18v4"/><path d="M2 12h4"/><path d="M18 12h4"/><path d="M4.93 4.93l2.83 2.83"/><path d="M16.24 16.24l2.83 2.83"/><path d="M6.34 17.66l2.83-2.83"/><path d="M14.83 9.17l2.83-2.83"/></svg>
<span class="cba5854">Toggle theme</span></button><div class="c658bcf c097fa1"><button id="i975fb5" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" aria-label="Open menu" aria-controls="i98aca2" aria-expanded=false onclick='window.__openMobileMenu("button")' data-d38f920=mobile_menu_open_click>
<svg class="c20e4eb cb58471" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
<span class="cba5854">Open menu</span></button></div></div></div></header><div id="iad2af0" class="caffa6e ce4b5f4 c14639a" style=background-color:hsl(var(--background)) hidden onclick='window.__closeMobileMenu("overlay")' data-d38f920=mobile_menu_overlay_click></div><aside id="i98aca2" class="caffa6e c9efbc5 c437fa9 c49e97e c6c6936 c7cacca c7b34a4 c787e9b c88daee cad071a c6942b3 c03620d" role=dialog aria-modal=true aria-hidden=true aria-label="Mobile navigation" style="transform:translateX(100%);transition:transform 200ms ease-out;will-change:transform"><div class="c6942b3 c7c11d8 c82c52d c5df473 ccf47f4 c9ee25d"><a href=/ class="c6942b3 c7c11d8 c1838fa" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=24 height=24 class="c20e4eb cb58471">
<span class="c62aaf0 c7c1b66 cbd72bc">Leonardo Benicio</span>
</a><button id="i190984" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c514027 c286dd7 c2bd687 cfdce1d" aria-label="Close menu" onclick='window.__closeMobileMenu("button")' data-d38f920=mobile_menu_close_click>
<svg class="c16e528 c61f467" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 6 6 18"/><path d="m6 6 12 12"/></svg>
<span class="cba5854">Close</span></button></div><nav class="c85cbd4 ca0eaa4 c5df473 c6689b9"><ul class="cd69733"><li><a href=/ class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Home</a></li><li><a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>About</a></li><li><a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Timeline</a></li><li><a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Reading</a></li><li><a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Publications</a></li><li><a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Contact</a></li></ul></nav><div class="c60a4cc ccdf0e8 c277478 c13044e"><p>&copy; 2026 Leonardo Benicio</p></div></aside><div class="caffa6e c437fa9 ce9aced c97bba6 c15da2a c975cba" role=complementary aria-label="GitHub repository"><div class="c9d056d c252f85 ca22532 ca88a1a c876315"><div class="c6942b3 c7c11d8 c1d0018 cd1fd22 c6066e4 c43876e ce3d5b6 caa20d2 c3ecea6 c0cd2e2 cddc2d2 c3ed5c9 cd4074c c876315"><a href=https://github.com/lbenicio/aboutme target=_blank rel="noopener noreferrer" class="c6942b3 c7c11d8 cd1fd22 c71bae8 cfac1ac c19ee42 c25dc7c cb40739 cbbda39 cf55a7b" aria-label="View source on GitHub"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="cb26e41 c41bcd4 cf17690 cfa4e34 c78d562" aria-hidden="true"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></svg>
<span class="cb5c327 cd7e69e">Fork me</span></a></div></div></div><main id="i7eccc0" class="cfdda01 c5df473 c0eecc8 c85cbd4" role=main aria-label=Content><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Lock Free Data Structures Concurrency Without the Wait</span></li></ol></nav><article class="c461ba0 c1c203f cfb6084 c995404 c6ca165"><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Lock Free Data Structures Concurrency Without the Wait</span></li></ol></nav><header class="c8aedc7"><h1 class="cf304bc c6fb0fe cf8f011 cc484e1">Lock-Free Data Structures: Concurrency Without the Wait</h1><div class="c277478 c3ecea6 c8fb24a">2024-07-18
· Leonardo Benicio</div><div class="c1a1a3f c8124f2"><img src=/static/assets/images/blog/lock-free-data-structures-concurrency.png alt class="cfdda01 c524300 c677556"></div><p class="lead c3ecea6">Explore how lock-free algorithms achieve thread-safe data access without traditional locks. Learn the theory behind compare-and-swap, the ABA problem, memory ordering, and practical implementations that power high-performance systems.</p></header><div class="content"><p>Traditional locks have served concurrent programming for decades, but they come with costs: contention, priority inversion, and the ever-present risk of deadlock. Lock-free data structures offer an alternative—algorithms that guarantee system-wide progress even when individual threads stall. This post explores the theory, challenges, and practical implementations of lock-free programming.</p><h2 id="1-why-lock-free">1. Why Lock-Free?</h2><p>Consider a simple counter shared among threads. With a mutex:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>pthread_mutex_lock</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>mutex);
</span></span><span style=display:flex><span>counter<span style=color:#ff7b72;font-weight:700>++</span>;
</span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>pthread_mutex_unlock</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>mutex);
</span></span></code></pre></div><p>This works, but has problems:</p><ul><li><strong>Contention:</strong> Threads block waiting for the lock, wasting CPU cycles</li><li><strong>Priority inversion:</strong> A high-priority thread waits for a low-priority thread holding the lock</li><li><strong>Deadlock risk:</strong> Multiple locks acquired in different orders can deadlock</li><li><strong>Fault tolerance:</strong> If a thread holding a lock crashes, the system may hang</li></ul><p>Lock-free algorithms address these issues by ensuring that at least one thread always makes progress, regardless of what other threads do—including if they&rsquo;re suspended, killed, or running slowly.</p><h3 id="11-progress-guarantees">1.1 Progress Guarantees</h3><p>Concurrent algorithms are classified by their progress guarantees:</p><p><strong>Blocking (lock-based):</strong> A thread can be prevented from making progress indefinitely by other threads. If a thread holding a lock is suspended, all waiters block.</p><p><strong>Obstruction-free:</strong> A thread makes progress if it runs in isolation (no other threads are active). The weakest non-blocking guarantee.</p><p><strong>Lock-free:</strong> At least one thread makes progress in a finite number of steps, regardless of what other threads do. Individual threads might starve, but the system never deadlocks.</p><p><strong>Wait-free:</strong> Every thread makes progress in a bounded number of steps. The strongest guarantee—no thread ever starves.</p><p>Most practical &ldquo;lock-free&rdquo; implementations are technically lock-free (not wait-free), as wait-free algorithms are often complex and slower.</p><h3 id="12-the-performance-argument">1.2 The Performance Argument</h3><p>Lock-free isn&rsquo;t always faster than lock-based code:</p><ul><li>Under low contention, locks are fast (uncontended lock acquisition is ~25 nanoseconds on modern CPUs)</li><li>Lock-free operations involve expensive atomic instructions and memory barriers</li><li>Lock-free algorithms are harder to reason about and optimize</li></ul><p>Lock-free shines when:</p><ul><li>Contention is high (many threads competing for access)</li><li>Latency variance matters (locks cause unpredictable wait times)</li><li>Fault isolation is critical (a stalled thread shouldn&rsquo;t block others)</li><li>Real-time constraints exist (bounded progress is required)</li></ul><h2 id="2-the-building-block-compare-and-swap">2. The Building Block: Compare-and-Swap</h2><p>Lock-free algorithms are built on atomic hardware primitives. The most important is Compare-and-Swap (CAS):</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>bool</span> <span style=color:#d2a8ff;font-weight:700>CAS</span>(<span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>*</span> addr, <span style=color:#ff7b72>int</span> expected, <span style=color:#ff7b72>int</span> new_value) {
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Atomically:
</span></span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (<span style=color:#ff7b72;font-weight:700>*</span>addr <span style=color:#ff7b72;font-weight:700>==</span> expected) {
</span></span><span style=display:flex><span>        <span style=color:#ff7b72;font-weight:700>*</span>addr <span style=color:#ff7b72;font-weight:700>=</span> new_value;
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>return</span> true;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>return</span> false;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>CAS reads the value at an address, compares it to an expected value, and if they match, writes a new value—all atomically. If the comparison fails, the operation fails, and the caller typically retries.</p><h3 id="21-hardware-support">2.1 Hardware Support</h3><p>Modern CPUs provide CAS as a single instruction:</p><ul><li><strong>x86/x64:</strong> <code>CMPXCHG</code> (compare and exchange)</li><li><strong>ARM:</strong> <code>LDXR</code>/<code>STXR</code> (load-exclusive/store-exclusive)</li><li><strong>RISC-V:</strong> <code>LR</code>/<code>SC</code> (load-reserved/store-conditional)</li></ul><p>These instructions coordinate with the cache coherence protocol to ensure atomicity across cores.</p><h3 id="22-cas-based-counter">2.2 CAS-Based Counter</h3><p>Here&rsquo;s a lock-free counter using CAS:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>increment</span>(atomic_int<span style=color:#ff7b72;font-weight:700>*</span> counter) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>int</span> old_val, new_val;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>do</span> {
</span></span><span style=display:flex><span>        old_val <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>atomic_load</span>(counter);
</span></span><span style=display:flex><span>        new_val <span style=color:#ff7b72;font-weight:700>=</span> old_val <span style=color:#ff7b72;font-weight:700>+</span> <span style=color:#a5d6ff>1</span>;
</span></span><span style=display:flex><span>    } <span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span><span style=color:#d2a8ff;font-weight:700>atomic_compare_exchange_weak</span>(counter, <span style=color:#ff7b72;font-weight:700>&amp;</span>old_val, new_val));
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The loop retries if another thread modified the counter between the load and the CAS. This &ldquo;read-modify-write&rdquo; pattern is fundamental to lock-free programming.</p><h3 id="23-other-atomic-primitives">2.3 Other Atomic Primitives</h3><p>Beyond CAS, useful atomics include:</p><ul><li><strong>Fetch-and-add (FAA):</strong> Atomically increment and return the old value. Faster than CAS for counters.</li><li><strong>Fetch-and-or/and:</strong> Atomically set/clear bits.</li><li><strong>Exchange:</strong> Atomically swap values.</li><li><strong>Load-link/Store-conditional (LL/SC):</strong> More flexible than CAS on some architectures; detects any intervening write.</li></ul><p>Modern languages expose these through <code>std::atomic</code> (C++), <code>java.util.concurrent.atomic</code> (Java), <code>sync/atomic</code> (Go), and <code>Atomic*</code> types (Rust).</p><h2 id="3-memory-ordering-the-hidden-complexity">3. Memory Ordering: The Hidden Complexity</h2><p>CAS guarantees atomicity of a single operation, but programs execute multiple operations. Without additional constraints, the CPU and compiler may reorder operations, breaking algorithms.</p><h3 id="31-the-problem">3.1 The Problem</h3><p>Consider a flag-based synchronization:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Thread 1
</span></span></span><span style=display:flex><span>data <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>42</span>;
</span></span><span style=display:flex><span>ready <span style=color:#ff7b72;font-weight:700>=</span> true;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Thread 2
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span>ready);
</span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>print</span>(data);  <span style=color:#8b949e;font-style:italic>// Might print garbage, not 42!
</span></span></span></code></pre></div><p>Even without compiler optimizations, CPUs may reorder stores. Thread 2 might see <code>ready = true</code> before <code>data = 42</code> is visible.</p><h3 id="32-memory-ordering-options">3.2 Memory Ordering Options</h3><p>Memory orderings specify how operations are ordered relative to each other:</p><p><strong>Relaxed (<code>memory_order_relaxed</code>):</strong> No ordering guarantees. Only atomicity is ensured. Fast but dangerous.</p><p><strong>Acquire (<code>memory_order_acquire</code>):</strong> No reads or writes in the current thread can be reordered before this load. Used when &ldquo;acquiring&rdquo; access to shared data.</p><p><strong>Release (<code>memory_order_release</code>):</strong> No reads or writes in the current thread can be reordered after this store. Used when &ldquo;releasing&rdquo; data for others to see.</p><p><strong>Acquire-release (<code>memory_order_acq_rel</code>):</strong> Combines acquire and release. Used for read-modify-write operations.</p><p><strong>Sequential consistency (<code>memory_order_seq_cst</code>):</strong> The strongest ordering. All seq_cst operations appear to execute in a single total order. Simplest to reason about but slowest.</p><h3 id="33-correct-synchronization">3.3 Correct Synchronization</h3><p>The flag example, fixed:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Thread 1
</span></span></span><span style=display:flex><span>data <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>42</span>;
</span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>atomic_store_explicit</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>ready, true, memory_order_release);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Thread 2
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span><span style=color:#d2a8ff;font-weight:700>atomic_load_explicit</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>ready, memory_order_acquire));
</span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>print</span>(data);  <span style=color:#8b949e;font-style:italic>// Guaranteed to print 42
</span></span></span></code></pre></div><p>The release-acquire pair establishes a &ldquo;happens-before&rdquo; relationship: Thread 1&rsquo;s writes before the release are visible to Thread 2&rsquo;s reads after the acquire.</p><h3 id="34-fences">3.4 Fences</h3><p>Memory fences (barriers) provide ordering without associated data:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>atomic_thread_fence</span>(memory_order_release);  <span style=color:#8b949e;font-style:italic>// All prior writes complete
</span></span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>atomic_thread_fence</span>(memory_order_acquire);  <span style=color:#8b949e;font-style:italic>// All subsequent reads see prior writes
</span></span></span></code></pre></div><p>Fences are a blunt instrument—they order all operations, not just specific ones. Prefer atomic operations with appropriate orderings when possible.</p><h2 id="4-the-aba-problem">4. The ABA Problem</h2><p>CAS checks if a value is the same as expected, but &ldquo;the same&rdquo; isn&rsquo;t always good enough.</p><h3 id="41-the-problem-illustrated">4.1 The Problem Illustrated</h3><p>Consider a lock-free stack using CAS to update the top pointer:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Pop operation
</span></span></span><span style=display:flex><span>Node<span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#d2a8ff;font-weight:700>pop</span>() {
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> old_top;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>do</span> {
</span></span><span style=display:flex><span>        old_top <span style=color:#ff7b72;font-weight:700>=</span> top;
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (old_top <span style=color:#ff7b72;font-weight:700>==</span> NULL) <span style=color:#ff7b72>return</span> NULL;
</span></span><span style=display:flex><span>    } <span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span><span style=color:#d2a8ff;font-weight:700>CAS</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>top, old_top, old_top<span style=color:#ff7b72;font-weight:700>-&gt;</span>next));
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>return</span> old_top;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Now imagine:</p><ol><li>Thread 1 reads <code>top = A</code>, prepares to CAS to <code>A->next</code> (B)</li><li>Thread 1 is suspended</li><li>Thread 2 pops A, pops B, pushes C, pushes A back (same address, reused!)</li><li>Thread 1 resumes, CAS succeeds (top is A), sets <code>top = B</code></li><li>But B was already popped! Stack is corrupted.</li></ol><p>Thread 1&rsquo;s CAS succeeded because <code>top</code> was <code>A</code> before and after—but the stack&rsquo;s structure changed in between.</p><h3 id="42-solutions">4.2 Solutions</h3><p><strong>Version counters / tagged pointers:</strong></p><p>Pack a version counter with the pointer. Increment the counter on every modification:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> TaggedPointer {
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> ptr;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>uint64_t</span> tag;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>CAS on the entire 128-bit structure (using <code>CMPXCHG16B</code> on x64). The tag changes even if the pointer value repeats.</p><p><strong>Hazard pointers:</strong></p><p>Each thread publishes the pointers it&rsquo;s currently using. Memory is only reclaimed when no thread has it as a hazard pointer. Prevents reuse of actively-accessed memory.</p><p><strong>Epoch-based reclamation (EBR):</strong></p><p>Divide time into epochs. Memory freed in epoch N can only be reused after all threads have passed through epoch N+1. Lighter weight than hazard pointers.</p><p><strong>Reference counting:</strong></p><p>Maintain a reference count with the pointer. Memory is freed only when the count reaches zero. Requires atomic double-width operations or split reference counts.</p><h2 id="5-lock-free-stack">5. Lock-Free Stack</h2><p>Let&rsquo;s build a complete lock-free stack with proper memory reclamation using hazard pointers.</p><h3 id="51-basic-structure">5.1 Basic Structure</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> Node {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>int</span> data;
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> next;
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>struct</span> LockFreeStack {
</span></span><span style=display:flex><span>    atomic<span style=color:#ff7b72;font-weight:700>&lt;</span>Node<span style=color:#ff7b72;font-weight:700>*&gt;</span> top;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><h3 id="52-push-operation">5.2 Push Operation</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>push</span>(LockFreeStack<span style=color:#ff7b72;font-weight:700>*</span> stack, <span style=color:#ff7b72>int</span> value) {
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> new_node <span style=color:#ff7b72;font-weight:700>=</span> new Node{value, nullptr};
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> old_top;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>do</span> {
</span></span><span style=display:flex><span>        old_top <span style=color:#ff7b72;font-weight:700>=</span> stack<span style=color:#ff7b72;font-weight:700>-&gt;</span>top.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_relaxed);
</span></span><span style=display:flex><span>        new_node<span style=color:#ff7b72;font-weight:700>-&gt;</span>next <span style=color:#ff7b72;font-weight:700>=</span> old_top;
</span></span><span style=display:flex><span>    } <span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span>stack<span style=color:#ff7b72;font-weight:700>-&gt;</span>top.<span style=color:#d2a8ff;font-weight:700>compare_exchange_weak</span>(
</span></span><span style=display:flex><span>        old_top, new_node,
</span></span><span style=display:flex><span>        memory_order_release,  <span style=color:#8b949e;font-style:italic>// Success: release new node
</span></span></span><span style=display:flex><span>        memory_order_relaxed   <span style=color:#8b949e;font-style:italic>// Failure: no ordering needed
</span></span></span><span style=display:flex><span>    ));
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The release ordering ensures the new node&rsquo;s initialization is visible before it becomes reachable via <code>top</code>.</p><h3 id="53-pop-operation-with-hazard-pointers">5.3 Pop Operation with Hazard Pointers</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span>Node<span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#d2a8ff;font-weight:700>pop</span>(LockFreeStack<span style=color:#ff7b72;font-weight:700>*</span> stack, HazardPointer<span style=color:#ff7b72;font-weight:700>*</span> hp) {
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> old_top;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>do</span> {
</span></span><span style=display:flex><span>        old_top <span style=color:#ff7b72;font-weight:700>=</span> stack<span style=color:#ff7b72;font-weight:700>-&gt;</span>top.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (old_top <span style=color:#ff7b72;font-weight:700>==</span> nullptr) <span style=color:#ff7b72>return</span> nullptr;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#8b949e;font-style:italic>// Protect this pointer from reclamation
</span></span></span><span style=display:flex><span>        hp<span style=color:#ff7b72;font-weight:700>-&gt;</span><span style=color:#d2a8ff;font-weight:700>set</span>(old_top);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#8b949e;font-style:italic>// Re-check after publishing hazard pointer
</span></span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (stack<span style=color:#ff7b72;font-weight:700>-&gt;</span>top.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire) <span style=color:#ff7b72;font-weight:700>!=</span> old_top) {
</span></span><span style=display:flex><span>            <span style=color:#ff7b72>continue</span>;  <span style=color:#8b949e;font-style:italic>// Pointer changed, retry
</span></span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    } <span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span>stack<span style=color:#ff7b72;font-weight:700>-&gt;</span>top.<span style=color:#d2a8ff;font-weight:700>compare_exchange_weak</span>(
</span></span><span style=display:flex><span>        old_top, old_top<span style=color:#ff7b72;font-weight:700>-&gt;</span>next,
</span></span><span style=display:flex><span>        memory_order_relaxed,
</span></span><span style=display:flex><span>        memory_order_relaxed
</span></span><span style=display:flex><span>    ));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    hp<span style=color:#ff7b72;font-weight:700>-&gt;</span><span style=color:#d2a8ff;font-weight:700>clear</span>();
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Defer deletion: retire(old_top)
</span></span></span><span style=display:flex><span>    <span style=color:#ff7b72>return</span> old_top;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The hazard pointer ensures <code>old_top</code> isn&rsquo;t freed while we&rsquo;re accessing <code>old_top->next</code>. The re-check after setting the hazard pointer handles the race where the node is freed between our load and our hazard pointer publication.</p><h3 id="54-memory-reclamation">5.4 Memory Reclamation</h3><p>Hazard pointer memory management:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>retire</span>(Node<span style=color:#ff7b72;font-weight:700>*</span> node) {
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Add to thread-local retired list
</span></span></span><span style=display:flex><span>    retired_list.<span style=color:#d2a8ff;font-weight:700>push</span>(node);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Periodically scan and free safe nodes
</span></span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (retired_list.<span style=color:#d2a8ff;font-weight:700>size</span>() <span style=color:#ff7b72;font-weight:700>&gt;</span> threshold) {
</span></span><span style=display:flex><span>        <span style=color:#d2a8ff;font-weight:700>scan_and_free</span>();
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>scan_and_free</span>() {
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Collect all active hazard pointers
</span></span></span><span style=display:flex><span>    set<span style=color:#ff7b72;font-weight:700>&lt;</span>Node<span style=color:#ff7b72;font-weight:700>*&gt;</span> hazards <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>collect_all_hazard_pointers</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Free nodes not in hazard set
</span></span></span><span style=display:flex><span>    <span style=color:#ff7b72>for</span> (Node<span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#79c0ff;font-weight:700>node</span> : retired_list) {
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (hazards.<span style=color:#d2a8ff;font-weight:700>find</span>(node) <span style=color:#ff7b72;font-weight:700>==</span> hazards.<span style=color:#d2a8ff;font-weight:700>end</span>()) {
</span></span><span style=display:flex><span>            delete node;
</span></span><span style=display:flex><span>        } <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>            still_retired.<span style=color:#d2a8ff;font-weight:700>push</span>(node);  <span style=color:#8b949e;font-style:italic>// Keep for later
</span></span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    retired_list <span style=color:#ff7b72;font-weight:700>=</span> still_retired;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id="6-lock-free-queue">6. Lock-Free Queue</h2><p>Queues are trickier than stacks because they have two ends (head and tail) that can be modified concurrently.</p><h3 id="61-michael-scott-queue">6.1 Michael-Scott Queue</h3><p>The classic lock-free queue by Michael and Scott (1996):</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> Node {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>int</span> data;
</span></span><span style=display:flex><span>    atomic<span style=color:#ff7b72;font-weight:700>&lt;</span>Node<span style=color:#ff7b72;font-weight:700>*&gt;</span> next;
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff7b72>struct</span> MSQueue {
</span></span><span style=display:flex><span>    atomic<span style=color:#ff7b72;font-weight:700>&lt;</span>Node<span style=color:#ff7b72;font-weight:700>*&gt;</span> head;
</span></span><span style=display:flex><span>    atomic<span style=color:#ff7b72;font-weight:700>&lt;</span>Node<span style=color:#ff7b72;font-weight:700>*&gt;</span> tail;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>Key insight: use a &ldquo;dummy&rdquo; node so the queue is never truly empty (head and tail always point to something).</p><h3 id="62-enqueue-operation">6.2 Enqueue Operation</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>enqueue</span>(MSQueue<span style=color:#ff7b72;font-weight:700>*</span> q, <span style=color:#ff7b72>int</span> value) {
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> new_node <span style=color:#ff7b72;font-weight:700>=</span> new Node{value, nullptr};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>while</span> (true) {
</span></span><span style=display:flex><span>        Node<span style=color:#ff7b72;font-weight:700>*</span> tail <span style=color:#ff7b72;font-weight:700>=</span> q<span style=color:#ff7b72;font-weight:700>-&gt;</span>tail.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>        Node<span style=color:#ff7b72;font-weight:700>*</span> next <span style=color:#ff7b72;font-weight:700>=</span> tail<span style=color:#ff7b72;font-weight:700>-&gt;</span>next.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#8b949e;font-style:italic>// Check tail hasn&#39;t moved
</span></span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (tail <span style=color:#ff7b72;font-weight:700>!=</span> q<span style=color:#ff7b72;font-weight:700>-&gt;</span>tail.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire)) <span style=color:#ff7b72>continue</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (next <span style=color:#ff7b72;font-weight:700>==</span> nullptr) {
</span></span><span style=display:flex><span>            <span style=color:#8b949e;font-style:italic>// tail-&gt;next is null, try to link new node
</span></span></span><span style=display:flex><span>            <span style=color:#ff7b72>if</span> (tail<span style=color:#ff7b72;font-weight:700>-&gt;</span>next.<span style=color:#d2a8ff;font-weight:700>compare_exchange_weak</span>(
</span></span><span style=display:flex><span>                    next, new_node, memory_order_release)) {
</span></span><span style=display:flex><span>                <span style=color:#8b949e;font-style:italic>// Success! Try to advance tail (optional)
</span></span></span><span style=display:flex><span>                q<span style=color:#ff7b72;font-weight:700>-&gt;</span>tail.<span style=color:#d2a8ff;font-weight:700>compare_exchange_strong</span>(
</span></span><span style=display:flex><span>                    tail, new_node, memory_order_release);
</span></span><span style=display:flex><span>                <span style=color:#ff7b72>return</span>;
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        } <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>            <span style=color:#8b949e;font-style:italic>// tail-&gt;next is not null, tail is lagging
</span></span></span><span style=display:flex><span>            <span style=color:#8b949e;font-style:italic>// Help advance tail
</span></span></span><span style=display:flex><span>            q<span style=color:#ff7b72;font-weight:700>-&gt;</span>tail.<span style=color:#d2a8ff;font-weight:700>compare_exchange_weak</span>(
</span></span><span style=display:flex><span>                tail, next, memory_order_release);
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The &ldquo;help advance tail&rdquo; step is crucial: even if one thread stalls after linking a node but before updating tail, other threads will move tail forward.</p><h3 id="63-dequeue-operation">6.3 Dequeue Operation</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>int</span> <span style=color:#d2a8ff;font-weight:700>dequeue</span>(MSQueue<span style=color:#ff7b72;font-weight:700>*</span> q, <span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>*</span> result) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>while</span> (true) {
</span></span><span style=display:flex><span>        Node<span style=color:#ff7b72;font-weight:700>*</span> head <span style=color:#ff7b72;font-weight:700>=</span> q<span style=color:#ff7b72;font-weight:700>-&gt;</span>head.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>        Node<span style=color:#ff7b72;font-weight:700>*</span> tail <span style=color:#ff7b72;font-weight:700>=</span> q<span style=color:#ff7b72;font-weight:700>-&gt;</span>tail.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>        Node<span style=color:#ff7b72;font-weight:700>*</span> next <span style=color:#ff7b72;font-weight:700>=</span> head<span style=color:#ff7b72;font-weight:700>-&gt;</span>next.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#8b949e;font-style:italic>// Check head hasn&#39;t moved
</span></span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (head <span style=color:#ff7b72;font-weight:700>!=</span> q<span style=color:#ff7b72;font-weight:700>-&gt;</span>head.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire)) <span style=color:#ff7b72>continue</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (head <span style=color:#ff7b72;font-weight:700>==</span> tail) {
</span></span><span style=display:flex><span>            <span style=color:#8b949e;font-style:italic>// Queue empty or tail lagging
</span></span></span><span style=display:flex><span>            <span style=color:#ff7b72>if</span> (next <span style=color:#ff7b72;font-weight:700>==</span> nullptr) {
</span></span><span style=display:flex><span>                <span style=color:#ff7b72>return</span> false;  <span style=color:#8b949e;font-style:italic>// Queue is empty
</span></span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            <span style=color:#8b949e;font-style:italic>// Tail lagging, help advance it
</span></span></span><span style=display:flex><span>            q<span style=color:#ff7b72;font-weight:700>-&gt;</span>tail.<span style=color:#d2a8ff;font-weight:700>compare_exchange_weak</span>(
</span></span><span style=display:flex><span>                tail, next, memory_order_release);
</span></span><span style=display:flex><span>        } <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>            <span style=color:#8b949e;font-style:italic>// Read data before CAS (might lose the node after CAS)
</span></span></span><span style=display:flex><span>            <span style=color:#ff7b72;font-weight:700>*</span>result <span style=color:#ff7b72;font-weight:700>=</span> next<span style=color:#ff7b72;font-weight:700>-&gt;</span>data;
</span></span><span style=display:flex><span>            <span style=color:#ff7b72>if</span> (q<span style=color:#ff7b72;font-weight:700>-&gt;</span>head.<span style=color:#d2a8ff;font-weight:700>compare_exchange_weak</span>(
</span></span><span style=display:flex><span>                    head, next, memory_order_release)) {
</span></span><span style=display:flex><span>                <span style=color:#8b949e;font-style:italic>// Successfully dequeued, retire old head (dummy)
</span></span></span><span style=display:flex><span>                <span style=color:#d2a8ff;font-weight:700>retire</span>(head);
</span></span><span style=display:flex><span>                <span style=color:#ff7b72>return</span> true;
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id="64-analysis">6.4 Analysis</h3><p>The Michael-Scott queue is elegant but has performance issues:</p><ul><li><strong>Cache line bouncing:</strong> Head and tail are on different cache lines, but high contention still causes coherence traffic</li><li><strong>Memory reclamation:</strong> Requires hazard pointers or similar; adds overhead</li><li><strong>FIFO guarantee:</strong> True FIFO even under contention, but at the cost of serialization</li></ul><p>Modern variations address these issues with techniques like combining (batch operations) and elimination (concurrent push/pop cancel out).</p><h2 id="7-lock-free-hash-map">7. Lock-Free Hash Map</h2><p>Hash maps combine multiple lock-free challenges: dynamic resizing, multiple buckets, and linked structure management.</p><h3 id="71-split-ordered-lists">7.1 Split-Ordered Lists</h3><p>The split-ordered list (Shalev and Shavit, 2006) provides a lock-free hash map with dynamic resizing:</p><ul><li>Items are stored in a single lock-free linked list, sorted by a &ldquo;split-order&rdquo; key</li><li>The hash table is an array of pointers into this list</li><li>Resizing only adds new pointers; no items move</li></ul><p>The split-order key is derived from the hash by bit-reversal, ensuring that when a bucket splits, items naturally divide between the new buckets based on their position in the list.</p><h3 id="72-simplified-lock-free-hash-map">7.2 Simplified Lock-Free Hash Map</h3><p>A simpler approach uses per-bucket lock-free lists:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> HashMap {
</span></span><span style=display:flex><span>    atomic<span style=color:#ff7b72;font-weight:700>&lt;</span>Node<span style=color:#ff7b72;font-weight:700>*&gt;*</span> buckets;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>size_t</span> num_buckets;
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Node<span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#d2a8ff;font-weight:700>find</span>(HashMap<span style=color:#ff7b72;font-weight:700>*</span> map, <span style=color:#ff7b72>int</span> key) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>size_t</span> bucket <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>hash</span>(key) <span style=color:#ff7b72;font-weight:700>%</span> map<span style=color:#ff7b72;font-weight:700>-&gt;</span>num_buckets;
</span></span><span style=display:flex><span>    Node<span style=color:#ff7b72;font-weight:700>*</span> curr <span style=color:#ff7b72;font-weight:700>=</span> map<span style=color:#ff7b72;font-weight:700>-&gt;</span>buckets[bucket].<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>while</span> (curr <span style=color:#ff7b72;font-weight:700>!=</span> nullptr) {
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (curr<span style=color:#ff7b72;font-weight:700>-&gt;</span>key <span style=color:#ff7b72;font-weight:700>==</span> key) <span style=color:#ff7b72>return</span> curr;
</span></span><span style=display:flex><span>        curr <span style=color:#ff7b72;font-weight:700>=</span> curr<span style=color:#ff7b72;font-weight:700>-&gt;</span>next.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_acquire);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>return</span> nullptr;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Insert and delete follow the lock-free list pattern, operating on a single bucket.</p><h3 id="73-concurrent-resizing">7.3 Concurrent Resizing</h3><p>Resizing a lock-free hash map is complex:</p><ol><li>Allocate new bucket array</li><li>Redirect lookups to check both old and new arrays</li><li>Gradually migrate items from old to new buckets</li><li>Once migration complete, free old array</li></ol><p>Each step requires careful synchronization. Some implementations simply use a read-write lock for resizing (hybrid approach), accepting brief blocking during the infrequent resize operation.</p><h2 id="8-read-copy-update-rcu">8. Read-Copy-Update (RCU)</h2><p>RCU is a synchronization mechanism optimized for read-heavy workloads. It&rsquo;s widely used in the Linux kernel.</p><h3 id="81-the-concept">8.1 The Concept</h3><p>RCU splits updates into phases:</p><ol><li><strong>Copy:</strong> Create a new version of the data structure</li><li><strong>Update:</strong> Atomically swing a pointer to the new version</li><li><strong>Wait:</strong> Wait until no reader can have a reference to the old version</li><li><strong>Reclaim:</strong> Free the old version</li></ol><p>Readers access data without any synchronization—they simply read the pointer and follow it. Writers bear all the synchronization cost.</p><h3 id="82-grace-periods">8.2 Grace Periods</h3><p>The key innovation is the &ldquo;grace period&rdquo; concept. A grace period is a time interval after which all pre-existing readers have completed. RCU ensures:</p><ul><li>Readers are in well-defined &ldquo;RCU read-side critical sections&rdquo;</li><li>A grace period elapses when every CPU has passed through a quiescent state (context switch, idle, user mode)</li><li>After a grace period, old data can be safely freed</li></ul><h3 id="83-api-example">8.3 API Example</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Reader
</span></span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>rcu_read_lock</span>();
</span></span><span style=display:flex><span>Node<span style=color:#ff7b72;font-weight:700>*</span> node <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>rcu_dereference</span>(global_ptr);  <span style=color:#8b949e;font-style:italic>// Safe access
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>int</span> val <span style=color:#ff7b72;font-weight:700>=</span> node<span style=color:#ff7b72;font-weight:700>-&gt;</span>data;
</span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>rcu_read_unlock</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Writer
</span></span></span><span style=display:flex><span>Node<span style=color:#ff7b72;font-weight:700>*</span> new_node <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>kmalloc</span>(...);  <span style=color:#8b949e;font-style:italic>// Allocate new
</span></span></span><span style=display:flex><span>new_node<span style=color:#ff7b72;font-weight:700>-&gt;</span>data <span style=color:#ff7b72;font-weight:700>=</span> new_value;
</span></span><span style=display:flex><span>old <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>rcu_assign_pointer</span>(global_ptr, new_node);  <span style=color:#8b949e;font-style:italic>// Publish
</span></span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>synchronize_rcu</span>();  <span style=color:#8b949e;font-style:italic>// Wait for grace period
</span></span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>kfree</span>(old);  <span style=color:#8b949e;font-style:italic>// Now safe to free
</span></span></span></code></pre></div><h3 id="84-rcu-variants">8.4 RCU Variants</h3><ul><li><strong>Classic RCU:</strong> Grace period detection via quiescent states</li><li><strong>SRCU (Sleepable RCU):</strong> Readers can sleep in critical sections</li><li><strong>QRCU:</strong> Optimized for quick grace periods</li><li><strong>User-space RCU (URCU):</strong> Library implementation for user-space programs</li></ul><p>RCU is extremely fast for readers (often zero overhead) but requires careful design: updates create new versions rather than modifying in place.</p><h2 id="9-performance-considerations">9. Performance Considerations</h2><h3 id="91-false-sharing">9.1 False Sharing</h3><p>When multiple atomics share a cache line, updates cause the line to bounce between cores:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> BadCounters {
</span></span><span style=display:flex><span>    atomic<span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>&gt;</span> counter1;  <span style=color:#8b949e;font-style:italic>// Same cache line!
</span></span></span><span style=display:flex><span>    atomic<span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>&gt;</span> counter2;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>Fix with padding:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> GoodCounters {
</span></span><span style=display:flex><span>    <span style=color:#d2a8ff;font-weight:700>alignas</span>(<span style=color:#a5d6ff>64</span>) atomic<span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>&gt;</span> counter1;
</span></span><span style=display:flex><span>    <span style=color:#d2a8ff;font-weight:700>alignas</span>(<span style=color:#a5d6ff>64</span>) atomic<span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>&gt;</span> counter2;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><h3 id="92-contention-and-backoff">9.2 Contention and Backoff</h3><p>High contention leads to many CAS failures. Backoff strategies help:</p><ul><li><strong>Exponential backoff:</strong> Wait longer after each failure</li><li><strong>Random backoff:</strong> Add randomness to reduce collision probability</li><li><strong>Adaptive backoff:</strong> Adjust based on observed contention</li></ul><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>push_with_backoff</span>(Stack<span style=color:#ff7b72;font-weight:700>*</span> s, <span style=color:#ff7b72>int</span> val) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>int</span> backoff <span style=color:#ff7b72;font-weight:700>=</span> MIN_BACKOFF;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span><span style=color:#d2a8ff;font-weight:700>try_push</span>(s, val)) {
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> backoff; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>            <span style=color:#d2a8ff;font-weight:700>cpu_relax</span>();  <span style=color:#8b949e;font-style:italic>// Pause instruction
</span></span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        backoff <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>min</span>(backoff <span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#a5d6ff>2</span>, MAX_BACKOFF);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id="93-helping-vs-waiting">9.3 Helping vs. Waiting</h3><p>Lock-free algorithms often have threads &ldquo;help&rdquo; each other complete operations. This ensures progress but can cause redundant work. The trade-off:</p><ul><li>More helping = better progress guarantees but more cache traffic</li><li>Less helping = better throughput under low contention but worse tail latency</li></ul><h3 id="94-numa-considerations">9.4 NUMA Considerations</h3><p>Non-Uniform Memory Access (NUMA) architectures add complexity:</p><ul><li>Atomics on remote memory are slower (cross-socket traffic)</li><li>Consider NUMA-aware data structure placement</li><li>Thread-local structures with occasional synchronization may outperform global lock-free structures</li></ul><h2 id="10-testing-and-verification">10. Testing and Verification</h2><p>Lock-free code is notoriously hard to test. Bugs may manifest only under specific timing conditions.</p><h3 id="101-stress-testing">10.1 Stress Testing</h3><p>Run many threads performing random operations for extended periods:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>stress_test</span>(Stack<span style=color:#ff7b72;font-weight:700>*</span> s) {
</span></span><span style=display:flex><span>    <span style=color:#d2a8ff;font-weight:700>parallel_for</span>(num_threads, [<span style=color:#ff7b72;font-weight:700>&amp;</span>](<span style=color:#ff7b72>int</span> tid) {
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> iterations; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>            <span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>rand</span>() <span style=color:#ff7b72;font-weight:700>%</span> <span style=color:#a5d6ff>2</span>) {
</span></span><span style=display:flex><span>                <span style=color:#d2a8ff;font-weight:700>push</span>(s, tid <span style=color:#ff7b72;font-weight:700>*</span> iterations <span style=color:#ff7b72;font-weight:700>+</span> i);
</span></span><span style=display:flex><span>            } <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>                <span style=color:#d2a8ff;font-weight:700>pop</span>(s);
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Check invariants after the test: correct item count, no duplicates, no lost items.</p><h3 id="102-threadsanitizer-tsan">10.2 ThreadSanitizer (TSan)</h3><p>Compiler-based tools detect data races:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-bash" data-lang=bash><span style=display:flex><span>clang++ -fsanitize<span style=color:#ff7b72;font-weight:700>=</span>thread -g -O1 my_code.cpp
</span></span><span style=display:flex><span>./a.out  <span style=color:#8b949e;font-style:italic># Reports races</span>
</span></span></code></pre></div><p>TSan instruments memory accesses and tracks happens-before relationships. False negatives are possible, but it catches many real bugs.</p><h3 id="103-model-checking">10.3 Model Checking</h3><p>Tools like CDSChecker and GenMC explore all possible interleavings:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Test with CDSChecker
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>test_stack</span>() {
</span></span><span style=display:flex><span>    Stack s;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>thread</span> <span style=color:#d2a8ff;font-weight:700>t1</span>([<span style=color:#ff7b72;font-weight:700>&amp;</span>]{ <span style=color:#d2a8ff;font-weight:700>push</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>s, <span style=color:#a5d6ff>1</span>); });
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>thread</span> <span style=color:#d2a8ff;font-weight:700>t2</span>([<span style=color:#ff7b72;font-weight:700>&amp;</span>]{ <span style=color:#d2a8ff;font-weight:700>push</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>s, <span style=color:#a5d6ff>2</span>); });
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>thread</span> <span style=color:#d2a8ff;font-weight:700>t3</span>([<span style=color:#ff7b72;font-weight:700>&amp;</span>]{ <span style=color:#d2a8ff;font-weight:700>pop</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>s); });
</span></span><span style=display:flex><span>    t1.<span style=color:#d2a8ff;font-weight:700>join</span>(); t2.<span style=color:#d2a8ff;font-weight:700>join</span>(); t3.<span style=color:#d2a8ff;font-weight:700>join</span>();
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// CDSChecker tries all interleavings
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Model checkers find subtle bugs but have exponential state space; they work best on small code fragments.</p><h3 id="104-formal-verification">10.4 Formal Verification</h3><p>For critical code, prove correctness mathematically:</p><ul><li><strong>TLA+:</strong> Specify and model-check concurrent algorithms</li><li><strong>Coq/Iris:</strong> Full formal proofs of lock-free data structures</li><li><strong>SPIN:</strong> Model checker for protocol verification</li></ul><p>Major lock-free data structures (Michael-Scott queue, Harris list) have been formally verified.</p><h2 id="11-real-world-implementations">11. Real-World Implementations</h2><h3 id="111-java-concurrentlinkedqueue">11.1 Java ConcurrentLinkedQueue</h3><p>Java&rsquo;s <code>ConcurrentLinkedQueue</code> implements a variation of the Michael-Scott queue:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-java" data-lang=java><span style=display:flex><span>ConcurrentLinkedQueue<span style=color:#ff7b72;font-weight:700>&lt;</span>Integer<span style=color:#ff7b72;font-weight:700>&gt;</span><span style=color:#6e7681> </span>queue<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span><span style=color:#ff7b72>new</span><span style=color:#6e7681> </span>ConcurrentLinkedQueue<span style=color:#ff7b72;font-weight:700>&lt;&gt;</span>();<span style=color:#6e7681>
</span></span></span><span style=display:flex><span>queue.offer(1);<span style=color:#6e7681>  </span><span style=color:#8b949e;font-style:italic>// Lock-free enqueue</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span>Integer<span style=color:#6e7681> </span>val<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span>queue.poll();<span style=color:#6e7681>  </span><span style=color:#8b949e;font-style:italic>// Lock-free dequeue</span><span style=color:#6e7681>
</span></span></span></code></pre></div><p>Java&rsquo;s garbage collector handles memory reclamation, simplifying the implementation significantly.</p><h3 id="112-crossbeam-rust">11.2 Crossbeam (Rust)</h3><p>Rust&rsquo;s crossbeam crate provides lock-free data structures with safe memory reclamation:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-rust" data-lang=rust><span style=display:flex><span><span style=color:#ff7b72>use</span><span style=color:#6e7681> </span>crossbeam::queue::SegQueue;<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>let</span><span style=color:#6e7681> </span>queue: <span style=color:#f0883e;font-weight:700>SegQueue</span><span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#ff7b72>i32</span><span style=color:#ff7b72;font-weight:700>&gt;</span><span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span>SegQueue::new();<span style=color:#6e7681>
</span></span></span><span style=display:flex><span>queue.push(<span style=color:#a5d6ff>1</span>);<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>let</span><span style=color:#6e7681> </span>val<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span>queue.pop();<span style=color:#6e7681>
</span></span></span></code></pre></div><p>Crossbeam uses epoch-based reclamation, integrated with Rust&rsquo;s ownership system.</p><h3 id="113-intel-tbb">11.3 Intel TBB</h3><p>Intel&rsquo;s Threading Building Blocks includes lock-free containers:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-cpp" data-lang=cpp><span style=display:flex><span>tbb<span style=color:#ff7b72;font-weight:700>::</span>concurrent_queue<span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>&gt;</span> queue;
</span></span><span style=display:flex><span>queue.push(<span style=color:#a5d6ff>1</span>);
</span></span><span style=display:flex><span><span style=color:#ff7b72>int</span> val;
</span></span><span style=display:flex><span><span style=color:#ff7b72>bool</span> success <span style=color:#ff7b72;font-weight:700>=</span> queue.try_pop(val);
</span></span></code></pre></div><p>TBB&rsquo;s containers are highly optimized for Intel architectures.</p><h3 id="114-folly-facebook">11.4 Folly (Facebook)</h3><p>Facebook&rsquo;s Folly library includes production-grade lock-free structures:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-cpp" data-lang=cpp><span style=display:flex><span>folly<span style=color:#ff7b72;font-weight:700>::</span>MPMCQueue<span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>&gt;</span> queue(<span style=color:#a5d6ff>1024</span>);  <span style=color:#8b949e;font-style:italic>// Multi-producer multi-consumer
</span></span></span><span style=display:flex><span>queue.write(<span style=color:#a5d6ff>42</span>);
</span></span><span style=display:flex><span><span style=color:#ff7b72>int</span> val;
</span></span><span style=display:flex><span>queue.read(val);
</span></span></code></pre></div><p>Folly&rsquo;s implementations emphasize practical performance over theoretical elegance.</p><h2 id="12-when-to-use-lock-free">12. When to Use Lock-Free</h2><h3 id="121-good-use-cases">12.1 Good Use Cases</h3><ul><li><strong>High-contention scenarios:</strong> Many threads competing for the same data</li><li><strong>Real-time systems:</strong> Bounded progress guarantees matter</li><li><strong>Interrupt/signal handlers:</strong> Can&rsquo;t safely acquire locks</li><li><strong>Heterogeneous timing:</strong> Some threads much faster than others</li><li><strong>Kernel code:</strong> Locks are expensive; RCU is often used instead</li></ul><h3 id="122-avoid-when">12.2 Avoid When</h3><ul><li><strong>Low contention:</strong> Locks are simpler and often faster</li><li><strong>Complex operations:</strong> Multi-word updates are hard to make lock-free</li><li><strong>Debugging priority:</strong> Lock-free bugs are extremely hard to diagnose</li><li><strong>Memory-constrained:</strong> Lock-free often requires extra memory (versions, pointers)</li><li><strong>Team expertise:</strong> Lock-free code requires specialized knowledge to maintain</li></ul><h3 id="123-hybrid-approaches">12.3 Hybrid Approaches</h3><p>Many systems use hybrid approaches:</p><ul><li>Lock-free fast path, lock-based slow path</li><li>Read-mostly data with RCU; occasional locked updates</li><li>Per-thread lock-free structures with locked synchronization between threads</li><li>Lock-free for hot operations, locks for complex/rare operations</li></ul><h2 id="13-common-pitfalls">13. Common Pitfalls</h2><h3 id="131-memory-ordering-mistakes">13.1 Memory Ordering Mistakes</h3><p>Using <code>memory_order_relaxed</code> everywhere is tempting but wrong:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// BUG: No synchronization
</span></span></span><span style=display:flex><span>data <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>42</span>;
</span></span><span style=display:flex><span>flag.<span style=color:#d2a8ff;font-weight:700>store</span>(true, memory_order_relaxed);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Other thread
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span>flag.<span style=color:#d2a8ff;font-weight:700>load</span>(memory_order_relaxed));
</span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>print</span>(data);  <span style=color:#8b949e;font-style:italic>// Might not see 42!
</span></span></span></code></pre></div><p>Always think carefully about what orderings are required.</p><h3 id="132-aba-blindness">13.2 ABA Blindness</h3><p>Assuming pointer comparison is sufficient:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// BUG: ABA problem
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>CAS</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>head, old_head, old_head<span style=color:#ff7b72;font-weight:700>-&gt;</span>next)) {
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// old_head might have been freed and reused!
</span></span></span><span style=display:flex><span>    <span style=color:#d2a8ff;font-weight:700>free</span>(old_head);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Use tagged pointers, hazard pointers, or other ABA prevention.</p><h3 id="133-forgetting-memory-reclamation">13.3 Forgetting Memory Reclamation</h3><p>Lock-free doesn&rsquo;t mean garbage collection:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// BUG: When can we free removed nodes?
</span></span></span><span style=display:flex><span>Node<span style=color:#ff7b72;font-weight:700>*</span> removed <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>pop</span>();
</span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>free</span>(removed);  <span style=color:#8b949e;font-style:italic>// Might still be accessed by other threads!
</span></span></span></code></pre></div><p>Always have a reclamation strategy (hazard pointers, epochs, RCU).</p><h3 id="134-over-optimization">13.4 Over-Optimization</h3><p>Optimizing memory orderings prematurely:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Premature optimization: hard to reason about
</span></span></span><span style=display:flex><span>x.<span style=color:#d2a8ff;font-weight:700>store</span>(<span style=color:#a5d6ff>1</span>, memory_order_release);
</span></span><span style=display:flex><span>y.<span style=color:#d2a8ff;font-weight:700>store</span>(<span style=color:#a5d6ff>2</span>, memory_order_relaxed);  <span style=color:#8b949e;font-style:italic>// Is this safe?
</span></span></span></code></pre></div><p>Start with sequential consistency, measure, then optimize with extreme care.</p><h3 id="135-ignoring-contention-effects">13.5 Ignoring Contention Effects</h3><p>A &ldquo;lock-free&rdquo; structure under extreme contention can perform worse than a simple lock:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Many threads CASing the same location = high failure rate
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>!</span><span style=color:#d2a8ff;font-weight:700>CAS</span>(<span style=color:#ff7b72;font-weight:700>&amp;</span>counter, old, old <span style=color:#ff7b72;font-weight:700>+</span> <span style=color:#a5d6ff>1</span>)) {
</span></span><span style=display:flex><span>    old <span style=color:#ff7b72;font-weight:700>=</span> counter;  <span style=color:#8b949e;font-style:italic>// Retry loop, high cache traffic
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Consider per-thread aggregation or combining techniques.</p><h2 id="14-advanced-topics">14. Advanced Topics</h2><h3 id="141-universal-constructions">14.1 Universal Constructions</h3><p>Any sequential data structure can be made lock-free using a &ldquo;universal construction&rdquo;:</p><ol><li>Represent operations as a log of commands</li><li>Use consensus to order commands</li><li>Apply commands to derive current state</li></ol><p>This is theoretically interesting but impractical—purpose-built lock-free structures are much faster.</p><h3 id="142-combining">14.2 Combining</h3><p>Under high contention, have threads combine their operations:</p><ol><li>Thread A wants to increment</li><li>Thread B also wants to increment</li><li>Thread B gives its operation to A (combining)</li><li>A performs both increments in one CAS</li><li>A returns results to B</li></ol><p>Flat-combining and the combining tree exploit this idea for high throughput.</p><h3 id="143-elimination">14.3 Elimination</h3><p>Some operations cancel out:</p><ol><li>Thread A is pushing X</li><li>Thread B is popping</li><li>Instead of both hitting the stack, exchange directly: A gives X to B</li></ol><p>Elimination backoff stacks use this to scale under high push/pop contention.</p><h3 id="144-transactional-memory">14.4 Transactional Memory</h3><p>Hardware transactional memory (HTM) provides an alternative:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>_xbegin</span>();  <span style=color:#8b949e;font-style:italic>// Start transaction
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Multiple reads/writes—all atomic
</span></span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>_xend</span>();    <span style=color:#8b949e;font-style:italic>// Commit transaction
</span></span></span></code></pre></div><p>HTM is available on recent Intel (TSX) and IBM POWER CPUs. It simplifies lock-free programming but has limitations (transaction size, abort handling).</p><h2 id="15-future-directions">15. Future Directions</h2><h3 id="151-persistent-lock-free-structures">15.1 Persistent Lock-Free Structures</h3><p>With non-volatile memory (NVM), lock-free structures need crash consistency:</p><ul><li>Flush cache lines in the right order</li><li>Handle partial writes on crash</li><li>Recovery protocols for lock-free algorithms</li></ul><p>This is an active research area with libraries like PMDK providing primitives.</p><h3 id="152-lock-free-in-managed-languages">15.2 Lock-Free in Managed Languages</h3><p>Languages with garbage collection simplify lock-free programming (no manual reclamation), but introduce new challenges:</p><ul><li>GC pauses can delay threads, affecting progress</li><li>Compiler reorderings need careful annotation</li><li>Reference counting overhead</li></ul><p>Research continues on GC-aware lock-free designs.</p><h3 id="153-formal-methods-integration">15.3 Formal Methods Integration</h3><p>As lock-free code becomes more common, better tooling is needed:</p><ul><li>Automated verification of memory ordering correctness</li><li>Synthesis of lock-free implementations from specifications</li><li>Testing frameworks aware of weak memory models</li></ul><h2 id="16-real-world-case-studies">16. Real-World Case Studies</h2><p>Understanding theory is valuable, but seeing how lock-free techniques solve real problems cements the knowledge. Let&rsquo;s examine several case studies from production systems.</p><h3 id="161-facebooks-folly-library">16.1 Facebook&rsquo;s Folly Library</h3><p>Facebook&rsquo;s Folly library provides battle-tested lock-free data structures. Their <code>AtomicHashMap</code> is particularly instructive. Rather than trying to make a general-purpose hash map lock-free (which is extremely complex), they made specific trade-offs:</p><ul><li>The map can grow but never shrink</li><li>Deletions mark entries as tombstones rather than actually removing them</li><li>Inserts are lock-free; the map uses a technique called &ldquo;linear probing with quadratic reprobe&rdquo;</li></ul><p>This design accepts memory overhead in exchange for lock-free reads and writes. For Facebook&rsquo;s use case—high-read workloads with infrequent deletions—this trade-off makes sense. The map achieves millions of operations per second on modern hardware.</p><h3 id="162-disruptor-pattern-in-trading">16.2 Disruptor Pattern in Trading</h3><p>LMAX Exchange developed the Disruptor pattern for their trading platform. At its core is a lock-free ring buffer that achieves remarkable throughput—over 6 million transactions per second on a single thread.</p><p>The key insight is eliminating the need for locks by carefully partitioning responsibilities:</p><ul><li>A single producer writes to the buffer, updating a sequence counter atomically</li><li>Multiple consumers each maintain their own sequence number</li><li>Consumers can read any entry up to the producer&rsquo;s sequence minus a buffer length</li><li>Memory barriers ensure visibility without locks</li></ul><p>The Disruptor achieves performance by keeping data in cache lines, avoiding false sharing, and using memory-mapped files for persistence. It demonstrates that sometimes the best lock-free design is one that avoids contention entirely through careful architecture.</p><h3 id="163-linux-kernels-lockless-page-cache">16.3 Linux Kernel&rsquo;s Lockless Page Cache</h3><p>The Linux kernel&rsquo;s page cache uses a clever lock-free technique called SLAB_TYPESAFE_BY_RCU. Objects in the page cache can be freed and reallocated while readers are still accessing them. This sounds dangerous, but RCU&rsquo;s rules make it safe:</p><ul><li>Readers hold an RCU read-side lock (which is just a preempt-disable on non-preemptible kernels)</li><li>Writers must wait for all readers to finish before truly freeing an object</li><li>Objects are always valid memory, even if they&rsquo;ve been repurposed</li></ul><p>This allows the page cache to achieve remarkable scalability. On a 128-core system, the page cache can handle millions of lookups per second without any lock contention.</p><h3 id="164-concurrentskiplistmap-in-java">16.4 ConcurrentSkipListMap in Java</h3><p>Java&rsquo;s <code>ConcurrentSkipListMap</code> implements a lock-free sorted map using skip lists. Skip lists are particularly amenable to lock-free implementation because their probabilistic structure means most operations only touch a small number of nodes.</p><p>The implementation uses CAS to atomically update forward pointers. A key technique is the use of marker nodes during deletion:</p><ol><li>To delete a node, first CAS a marker node in after it</li><li>Other threads see the marker and help complete the deletion</li><li>Finally, CAS the predecessor&rsquo;s pointer to skip both the deleted node and marker</li></ol><p>This &ldquo;helping&rdquo; protocol is common in lock-free algorithms. When a thread detects an in-progress operation by another thread, it helps complete that operation before proceeding. This ensures progress even if the original thread stalls.</p><h2 id="17-debugging-lock-free-code-in-production">17. Debugging Lock-Free Code in Production</h2><p>When lock-free code misbehaves in production, standard debugging techniques often fail. Here&rsquo;s a practical guide to debugging these subtle issues.</p><h3 id="171-gathering-evidence">17.1 Gathering Evidence</h3><p>Lock-free bugs often manifest as:</p><ul><li>Memory corruption detected far from the cause</li><li>ABA-related issues that appear as impossible states</li><li>Performance degradation under specific load patterns</li><li>Rare crashes that never reproduce in testing</li></ul><p>Start by gathering statistics:</p><ul><li>Count CAS failures per operation type</li><li>Track retry loop iterations</li><li>Measure latency percentiles, not just averages</li><li>Log &ldquo;impossible&rdquo; states before asserting</li></ul><h3 id="172-using-core-dumps-effectively">17.2 Using Core Dumps Effectively</h3><p>When a lock-free algorithm corrupts memory, the crash site rarely indicates the root cause. Effective debugging requires:</p><ol><li>Capture enough state: Include atomic counters, version tags, and recent operations</li><li>Add sentinel values: Fill unused memory with recognizable patterns (0xDEADBEEF)</li><li>Implement operation logging: A lock-free ring buffer of recent operations helps reconstruction</li></ol><h3 id="173-production-tracing">17.3 Production Tracing</h3><p>For bugs that don&rsquo;t crash, distributed tracing can help. Instrument your lock-free operations with:</p><ul><li>Operation start/end timestamps</li><li>Thread IDs and processor affinity</li><li>Memory addresses being accessed</li><li>CAS expected vs. actual values</li></ul><p>Tools like eBPF on Linux allow adding this instrumentation without rebuilding your application.</p><h3 id="174-canary-deployments">17.4 Canary Deployments</h3><p>Given the difficulty of reproducing lock-free bugs, canary deployments are essential:</p><ul><li>Deploy to a small percentage of production traffic</li><li>Monitor closely for anomalies</li><li>Have automatic rollback triggers</li><li>Gradually increase deployment percentage</li></ul><h2 id="18-building-your-lock-free-intuition">18. Building Your Lock-Free Intuition</h2><p>Developing intuition for lock-free programming takes time. Here are exercises and mental models that help.</p><h3 id="181-mental-models">18.1 Mental Models</h3><p><strong>The Time-Slice Model:</strong> Imagine every line of code can be paused and another thread can execute arbitrary code before resuming. If your algorithm is correct under this model, it handles interleaving correctly.</p><p><strong>The Reordering Model:</strong> Imagine a malicious compiler and CPU that reorder every operation that the memory model allows. Use memory barriers and proper orderings to constrain what&rsquo;s possible.</p><p><strong>The Visibility Model:</strong> Imagine each CPU has its own copy of memory that synchronizes with others only through explicit synchronization. This models store buffers and cache coherency.</p><h3 id="182-practice-exercises">18.2 Practice Exercises</h3><ol><li><p><strong>Lock-free counter:</strong> Implement a counter that supports increment, decrement, and read. Verify it never produces a value outside the range of values it&rsquo;s had.</p></li><li><p><strong>SPSC queue:</strong> Implement a single-producer, single-consumer queue. This is the simplest lock-free queue and builds foundation.</p></li><li><p><strong>Lock-free set:</strong> Implement a set supporting add, remove, and contains. Handle the deletion problem carefully.</p></li><li><p><strong>Reproduce the ABA bug:</strong> Write code that demonstrates the ABA problem, then fix it with version counters.</p></li></ol><h3 id="183-code-review-checklist">18.3 Code Review Checklist</h3><p>When reviewing lock-free code, check:</p><ul><li><input disabled type=checkbox> Is every atomic operation using the correct memory ordering?</li><li><input disabled type=checkbox> Are all pointer manipulations protected against ABA?</li><li><input disabled type=checkbox> Is memory reclamation handled safely?</li><li><input disabled type=checkbox> Can a thread see a partially-constructed object?</li><li><input disabled type=checkbox> What happens if a thread dies mid-operation?</li><li><input disabled type=checkbox> Have spin loops been tested for livelock?</li><li><input disabled type=checkbox> Is the algorithm formally verified or well-tested?</li></ul><h2 id="19-summary">19. Summary</h2><p>Lock-free data structures eliminate blocking, providing progress guarantees that traditional locks cannot. The key concepts:</p><ul><li><strong>CAS is the foundation:</strong> Compare-and-swap enables atomic updates without locks</li><li><strong>Memory ordering matters:</strong> Atomicity alone isn&rsquo;t enough; proper fences and orderings prevent subtle bugs</li><li><strong>ABA is real:</strong> Detect or prevent the ABA problem in any lock-free pointer manipulation</li><li><strong>Memory reclamation is hard:</strong> Hazard pointers, epoch-based reclamation, or RCU are essential</li><li><strong>Test rigorously:</strong> Lock-free bugs are timing-dependent; use stress testing, sanitizers, and model checkers</li></ul><p>Lock-free programming is a powerful tool, but not a silver bullet. Use it when the benefits—latency consistency, fault tolerance, progress guarantees—outweigh the complexity costs. For most applications, well-implemented locks remain the right choice. But for the systems that need them, lock-free data structures enable performance and reliability that locks simply cannot match.</p><p>The journey from understanding basic CAS operations to implementing production-ready lock-free data structures is long. Start with simple algorithms, build intuition through practice, and always verify your implementations thoroughly. The complexity is real, but so are the rewards: systems that are faster, more predictable, and more resilient than their lock-based counterparts.</p><p>Whether you&rsquo;re building a high-frequency trading system, an operating system kernel, or a distributed database, understanding lock-free techniques adds an essential tool to your concurrency toolkit. The field continues to evolve with new hardware capabilities, new reclamation techniques, and better verification tools. Master the fundamentals presented here, and you&rsquo;ll be well-prepared to tackle the next generation of concurrent systems.</p></div><footer class="ce1a612 c6dfb1e c3ecea6"><div class="c364589">Categories:
<a href=/categories/systems/>systems</a>, <a href=/categories/performance/>performance</a></div><div>Tags:
<a href=/tags/concurrency/>#concurrency</a>, <a href=/tags/lock-free/>#lock-free</a>, <a href=/tags/atomics/>#atomics</a>, <a href=/tags/cas/>#cas</a>, <a href=/tags/data-structures/>#data-structures</a>, <a href=/tags/performance/>#performance</a>, <a href=/tags/multithreading/>#multithreading</a></div></footer></article></main><footer class="ccdf0e8" role=contentinfo aria-label=Footer><div class="cfdda01 c133889 c5df473 c0eecc8 c69618a c6942b3 c03620d c2a9f27 c7c11d8 c82c52d c14527b"><div class="c6dfb1e c3ecea6 c39ef11 c88ae6f">&copy; 2026 Leonardo Benicio. All rights
reserved.</div><div class="c6942b3 c7c11d8 cd1fd22"><a href=https://github.com/lbenicio target=_blank rel="noopener noreferrer" aria-label=GitHub class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.5-.67 1.08-.82 1.7s-.2 1.27-.18 1.9V22"/></svg>
<span class="cba5854">GitHub</span>
</a><a href=https://www.linkedin.com/in/leonardo-benicio target=_blank rel="noopener noreferrer" aria-label=LinkedIn class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452H17.21V14.86c0-1.333-.027-3.046-1.858-3.046-1.86.0-2.145 1.45-2.145 2.948v5.69H9.069V9h3.112v1.561h.044c.434-.82 1.494-1.686 3.074-1.686 3.29.0 3.897 2.165 3.897 4.983v6.594zM5.337 7.433a1.805 1.805.0 11-.002-3.61 1.805 1.805.0 01.002 3.61zM6.763 20.452H3.911V9h2.852v11.452z"/></svg>
<span class="cba5854">LinkedIn</span>
</a><a href=https://twitter.com/lbenicio_ target=_blank rel="noopener noreferrer" aria-label=Twitter class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M19.633 7.997c.013.177.013.354.013.53.0 5.386-4.099 11.599-11.6 11.599-2.31.0-4.457-.676-6.265-1.842.324.038.636.05.972.05 1.91.0 3.67-.65 5.07-1.755a4.099 4.099.0 01-3.827-2.84c.25.039.5.064.763.064.363.0.726-.051 1.065-.139A4.091 4.091.0 012.542 9.649v-.051c.538.3 1.162.482 1.824.507A4.082 4.082.0 012.54 6.7c0-.751.2-1.435.551-2.034a11.63 11.63.0 008.44 4.281 4.615 4.615.0 01-.101-.938 4.091 4.091.0 017.078-2.799 8.1 8.1.0 002.595-.988 4.112 4.112.0 01-1.8 2.261 8.2 8.2.0 002.357-.638A8.824 8.824.0 0119.613 7.96z"/></svg>
<span class="cba5854">Twitter</span></a></div></div></footer></body></html>