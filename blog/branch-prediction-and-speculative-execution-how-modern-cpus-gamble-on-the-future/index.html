<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no"><title>Branch Prediction and Speculative Execution: How Modern CPUs Gamble on the Future · Leonardo Benicio</title><meta name=description content="Explore how modern processors predict branch outcomes and execute instructions speculatively, the algorithms behind branch predictors, the performance implications for your code, and the security vulnerabilities like Spectre that emerged from these optimizations."><link rel=alternate type=application/rss+xml title=RSS href=https://lbenicio.dev/index.xml><link rel=canonical href=https://blog.lbenicio.dev/blog/branch-prediction-and-speculative-execution-how-modern-cpus-gamble-on-the-future/><link rel=preload href=/static/fonts/OpenSans-Regular.ttf as=font type=font/ttf crossorigin><link rel="stylesheet" href="/assets/css/fonts.min.40e2054b739ac45a0f9c940f4b44ec00c3b372356ebf61440a413c0337c5512e.css" crossorigin="anonymous" integrity="sha256-QOIFS3OaxFoPnJQPS0TsAMOzcjVuv2FECkE8AzfFUS4="><link rel="shortcut icon" href=/static/assets/favicon/favicon.ico><link rel=icon type=image/x-icon href=/static/assets/favicon/favicon.ico><link rel=icon href=/static/assets/favicon/favicon.svg type=image/svg+xml><link rel=icon href=/static/assets/favicon/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=/static/assets/favicon/favicon-16x16.png sizes=16x16 type=image/png><link rel=apple-touch-icon href=/static/assets/favicon/apple-touch-icon.png><link rel=manifest href=/static/assets/favicon/site.webmanifest><link rel=mask-icon href=/static/assets/favicon/safari-pinned-tab.svg color=#209cee><meta name=msapplication-TileColor content="#209cee"><meta name=msapplication-config content="/static/assets/favicon/browserconfig.xml"><meta name=theme-color content="#d2e9f8"><meta property="og:title" content="Branch Prediction and Speculative Execution: How Modern CPUs Gamble on the Future · Leonardo Benicio"><meta property="og:description" content="Explore how modern processors predict branch outcomes and execute instructions speculatively, the algorithms behind branch predictors, the performance implications for your code, and the security vulnerabilities like Spectre that emerged from these optimizations."><meta property="og:url" content="https://blog.lbenicio.dev/blog/branch-prediction-and-speculative-execution-how-modern-cpus-gamble-on-the-future/"><meta property="og:type" content="article"><meta property="og:image" content="https://blog.lbenicio.dev/static/assets/images/blog/branch-prediction-speculative-execution-modern-cpus.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Branch Prediction and Speculative Execution: How Modern CPUs Gamble on the Future · Leonardo Benicio"><meta name=twitter:description content="Explore how modern processors predict branch outcomes and execute instructions speculatively, the algorithms behind branch predictors, the performance implications for your code, and the security vulnerabilities like Spectre that emerged from these optimizations."><meta name=twitter:site content="@lbenicio_"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","name":"About Leonardo Benicio","url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Person","name":"Leonardo Benicio","sameAs":["https://github.com/lbenicio","https://www.linkedin.com/in/leonardo-benicio","https://twitter.com/lbenicio_"],"url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Home","position":1},{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Blog","position":2},{"@type":"ListItem","item":"https://blog.lbenicio.dev/blog/branch-prediction-and-speculative-execution-how-modern-cpus-gamble-on-the-future/","name":"Branch Prediction and Speculative Execution How Modern Cpus Gamble on the Future","position":3}]}</script><link rel="stylesheet" href="/assets/css/main.min.1e8a566ac8bc3f0664d0db4ec8a015b07421c33fa11d336a6b914522a9cabf30.css" crossorigin="anonymous" integrity="sha256-6lhUOpwCHMSMROmggsVSp3AHKud6gBrIFGTzl3GV4BY="></head><body class="c6942b3 c03620d cf3bd2e"><script>(function(){try{document.addEventListener("gesturestart",function(e){e.preventDefault()}),document.addEventListener("touchstart",function(e){e.touches&&e.touches.length>1&&e.preventDefault()},{passive:!1});var e=0;document.addEventListener("touchend",function(t){var n=Date.now();n-e<=300&&t.preventDefault(),e=n},{passive:!1})}catch{}})()</script><a href=#content class="cba5854 c21e770 caffa6e cc5f604 cf2c31d cdd44dd c10dda9 c43876e c787e9b cddc2d2 cf55a7b c6dfb1e c9391e2">Skip to content</a>
<script>(function(){try{const e=localStorage.getItem("theme");e==="dark"&&document.documentElement.classList.add("dark");const t=document.querySelector('button[aria-label="Toggle theme"]');t&&t.setAttribute("aria-pressed",String(e==="dark"))}catch{}})();function toggleTheme(e){const s=document.documentElement,t=s.classList.toggle("dark");try{localStorage.setItem("theme",t?"dark":"light")}catch{}try{var n=e&&e.nodeType===1?e:document.querySelector('button[aria-label="Toggle theme"]');n&&n.setAttribute("aria-pressed",String(!!t))}catch{}}(function(){function e(){try{return document.documentElement.classList.contains("dark")?"dark":"light"}catch{return"light"}}function n(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(0)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!1,s.style.display="block"}catch{}o.setAttribute("aria-expanded","true"),n.setAttribute("aria-hidden","false");try{document.body.classList.add("c150bbe")}catch{}const i=document.getElementById("i190984");i&&i.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_open",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function t(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(100%)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!0,s.style.display="none"}catch{}o.setAttribute("aria-expanded","false"),n.setAttribute("aria-hidden","true");try{document.body.classList.remove("c150bbe")}catch{}o.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_close",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function s(e){e.key==="Escape"&&t("escape")}window.__openMobileMenu=n,window.__closeMobileMenu=t;try{window.addEventListener("keydown",s,!0)}catch{}})()</script><header class="cd019ba c98dfae cdd44dd cfdda01 c9ee25d ce2dc7a cd72dd7 cc0dc37" role=banner><div class="cfdda01 c6942b3 ccf47f4 c7c11d8"><a href=/ class="c87e2b0 c6942b3 c7c11d8 c1838fa cb594e4" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=32 height=32 class="c3de71a c4d5191">
<span class="cf8f011 c4d1253 cbd72bc cd7e69e">Leonardo Benicio</span></a><div class="c6942b3 c85cbd4 c7c11d8 ca798da c1838fa c7a0580"><nav class="cc1689c cd9b445 c75065d c04bab1" aria-label=Main><a href=/ class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Home</a>
<a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">About</a>
<a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Timeline</a>
<a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Reading</a>
<a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Publications</a>
<a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Contact</a></nav><button id="i1d73d4" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 c097fa1 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" onclick=toggleTheme(this) aria-label="Toggle theme" aria-pressed=false title="Toggle theme">
<svg class="cb26e41 c50ceea cb69a5c c4f45c8 c8c2c40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="cb26e41 c8fca2b cb69a5c c4f45c8 cc1689c c9c27ff" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><circle cx="12" cy="12" r="4"/><path d="M12 2v4"/><path d="M12 18v4"/><path d="M2 12h4"/><path d="M18 12h4"/><path d="M4.93 4.93l2.83 2.83"/><path d="M16.24 16.24l2.83 2.83"/><path d="M6.34 17.66l2.83-2.83"/><path d="M14.83 9.17l2.83-2.83"/></svg>
<span class="cba5854">Toggle theme</span></button><div class="c658bcf c097fa1"><button id="i975fb5" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" aria-label="Open menu" aria-controls="i98aca2" aria-expanded=false onclick='window.__openMobileMenu("button")' data-d38f920=mobile_menu_open_click>
<svg class="c20e4eb cb58471" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
<span class="cba5854">Open menu</span></button></div></div></div></header><div id="iad2af0" class="caffa6e ce4b5f4 c14639a" style=background-color:hsl(var(--background)) hidden onclick='window.__closeMobileMenu("overlay")' data-d38f920=mobile_menu_overlay_click></div><aside id="i98aca2" class="caffa6e c9efbc5 c437fa9 c49e97e c6c6936 c7cacca c7b34a4 c787e9b c88daee cad071a c6942b3 c03620d" role=dialog aria-modal=true aria-hidden=true aria-label="Mobile navigation" style="transform:translateX(100%);transition:transform 200ms ease-out;will-change:transform"><div class="c6942b3 c7c11d8 c82c52d c5df473 ccf47f4 c9ee25d"><a href=/ class="c6942b3 c7c11d8 c1838fa" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=24 height=24 class="c20e4eb cb58471">
<span class="c62aaf0 c7c1b66 cbd72bc">Leonardo Benicio</span>
</a><button id="i190984" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c514027 c286dd7 c2bd687 cfdce1d" aria-label="Close menu" onclick='window.__closeMobileMenu("button")' data-d38f920=mobile_menu_close_click>
<svg class="c16e528 c61f467" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 6 6 18"/><path d="m6 6 12 12"/></svg>
<span class="cba5854">Close</span></button></div><nav class="c85cbd4 ca0eaa4 c5df473 c6689b9"><ul class="cd69733"><li><a href=/ class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Home</a></li><li><a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>About</a></li><li><a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Timeline</a></li><li><a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Reading</a></li><li><a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Publications</a></li><li><a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Contact</a></li></ul></nav><div class="c60a4cc ccdf0e8 c277478 c13044e"><p>&copy; 2026 Leonardo Benicio</p></div></aside><div class="caffa6e c437fa9 ce9aced c97bba6 c15da2a c975cba" role=complementary aria-label="GitHub repository"><div class="c9d056d c252f85 ca22532 ca88a1a c876315"><div class="c6942b3 c7c11d8 c1d0018 cd1fd22 c6066e4 c43876e ce3d5b6 caa20d2 c3ecea6 c0cd2e2 cddc2d2 c3ed5c9 cd4074c c876315"><a href=https://github.com/lbenicio/aboutme target=_blank rel="noopener noreferrer" class="c6942b3 c7c11d8 cd1fd22 c71bae8 cfac1ac c19ee42 c25dc7c cb40739 cbbda39 cf55a7b" aria-label="View source on GitHub"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="cb26e41 c41bcd4 cf17690 cfa4e34 c78d562" aria-hidden="true"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></svg>
<span class="cb5c327 cd7e69e">Fork me</span></a></div></div></div><main id="i7eccc0" class="cfdda01 c5df473 c0eecc8 c85cbd4" role=main aria-label=Content><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Branch Prediction and Speculative Execution How Modern Cpus Gamble on the Future</span></li></ol></nav><article class="c461ba0 c1c203f cfb6084 c995404 c6ca165"><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Branch Prediction and Speculative Execution How Modern Cpus Gamble on the Future</span></li></ol></nav><header class="c8aedc7"><h1 class="cf304bc c6fb0fe cf8f011 cc484e1">Branch Prediction and Speculative Execution: How Modern CPUs Gamble on the Future</h1><div class="c277478 c3ecea6 c8fb24a">2021-08-15
· Leonardo Benicio</div><div class="c1a1a3f c8124f2"><img src=/static/assets/images/blog/branch-prediction-speculative-execution-modern-cpus.png alt class="cfdda01 c524300 c677556"></div><p class="lead c3ecea6">Explore how modern processors predict branch outcomes and execute instructions speculatively, the algorithms behind branch predictors, the performance implications for your code, and the security vulnerabilities like Spectre that emerged from these optimizations.</p></header><div class="content"><p>Modern CPUs are marvels of prediction. Every time your code branches—every if statement, every loop iteration, every function call—the processor makes a bet on what happens next. Get it right, and execution flows at full speed. Get it wrong, and the pipeline stalls while work is thrown away. Understanding branch prediction transforms how you think about code performance. This post explores the algorithms, trade-offs, and real-world implications of one of computing&rsquo;s most important optimizations.</p><h2 id="1-why-prediction-matters">1. Why Prediction Matters</h2><p>Consider a simple loop:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> <span style=color:#a5d6ff>1000000</span>; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    sum <span style=color:#ff7b72;font-weight:700>+=</span> array[i];
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>At the machine level, this becomes a branch instruction that checks <code>i &lt; 1000000</code>. A modern CPU might take 15-20 cycles to determine the branch outcome (waiting for the comparison to complete). With a 3 GHz processor, that&rsquo;s 5-7 nanoseconds per iteration—just for the branch.</p><p>But the processor doesn&rsquo;t wait. It predicts the branch will be taken (loop continues) and keeps fetching instructions. One million correct predictions mean the branch overhead is nearly eliminated. The final iteration mispredicts (loop exits), costing ~15 cycles—a trivial price for eliminating millions of stalls.</p><h3 id="11-the-pipeline-problem">1.1 The Pipeline Problem</h3><p>Modern CPUs use deep pipelines to maximize throughput:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Instruction Pipeline (simplified):
</span></span><span style=display:flex><span>┌──────┬──────┬──────┬──────┬──────┬──────┬──────┐
</span></span><span style=display:flex><span>│Fetch │Decode│Rename│Issue │Execute│Memory│Retire│
</span></span><span style=display:flex><span>└──────┴──────┴──────┴──────┴──────┴──────┴──────┘
</span></span><span style=display:flex><span>   │      │      │      │       │      │      │
</span></span><span style=display:flex><span>Cycle 1   2      3      4       5      6      7
</span></span></code></pre></div><p>While instruction N is executing, the CPU is already fetching N+1, N+2, N+3, and so on. But what if N is a branch? The CPU doesn&rsquo;t know which instructions come next until the branch resolves.</p><p><strong>Without prediction:</strong> Stop fetching until the branch resolves. The pipeline drains, wasting cycles equal to the pipeline depth (15-20+ stages on modern CPUs).</p><p><strong>With prediction:</strong> Guess the branch outcome, keep fetching instructions from the predicted path. If correct, no cycles lost. If wrong, flush the speculative work and restart.</p><h3 id="12-the-cost-of-misprediction">1.2 The Cost of Misprediction</h3><p>When a branch mispredicts:</p><ol><li>All speculatively executed instructions are discarded</li><li>The pipeline is flushed</li><li>Fetch restarts from the correct path</li><li>The pipeline must refill before useful work resumes</li></ol><p><strong>Misprediction penalty:</strong> 10-25 cycles on modern CPUs, depending on how deep the speculation went.</p><p>A branch that mispredicts 10% of the time with a 20-cycle penalty:</p><ul><li>Average cost: 0.10 × 20 = 2 cycles per branch</li><li>For a tight loop with one branch per iteration, this is significant!</li></ul><h2 id="2-static-branch-prediction">2. Static Branch Prediction</h2><p>Early processors used simple, static rules.</p><h3 id="21-backward-taken-forward-not-taken-btfnt">2.1 Backward Taken, Forward Not Taken (BTFNT)</h3><p>The simplest heuristic:</p><ul><li><strong>Backward branches</strong> (target address &lt; current address): Predict taken. These are usually loops.</li><li><strong>Forward branches</strong> (target address > current address): Predict not taken. These are usually early exits.</li></ul><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Backward branch - usually loops, predict taken
</span></span></span><span style=display:flex><span><span style=color:#79c0ff;font-weight:700>loop</span>:
</span></span><span style=display:flex><span>    ...
</span></span><span style=display:flex><span>    jnz loop    <span style=color:#8b949e;font-style:italic>// Predict: taken
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Forward branch - usually ifs, predict not taken
</span></span></span><span style=display:flex><span>    test eax, eax
</span></span><span style=display:flex><span>    jz skip     <span style=color:#8b949e;font-style:italic>// Predict: not taken
</span></span></span><span style=display:flex><span>    ...
</span></span><span style=display:flex><span><span style=color:#79c0ff;font-weight:700>skip</span>:
</span></span></code></pre></div><p>BTFNT achieves ~65% accuracy on typical code—better than random, but far from ideal.</p><h3 id="22-compiler-hints">2.2 Compiler Hints</h3><p>Some ISAs allow the compiler to provide hints:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// GCC built-in for branch hints
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>__builtin_expect</span>(error_condition, <span style=color:#a5d6ff>0</span>)) {
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Unlikely path
</span></span></span><span style=display:flex><span>    <span style=color:#d2a8ff;font-weight:700>handle_error</span>();
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Linux kernel macros
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>likely</span>(condition)) { ... }
</span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>unlikely</span>(condition)) { ... }
</span></span></code></pre></div><p>These hints can influence:</p><ul><li>Static prediction (on CPUs that use hints)</li><li>Code layout (likely path falls through, unlikely path jumps)</li><li>Instruction scheduling around the branch</li></ul><h3 id="23-limitations-of-static-prediction">2.3 Limitations of Static Prediction</h3><p>Static prediction can&rsquo;t adapt to:</p><ul><li>Runtime data patterns</li><li>Phase behavior (different behavior at different times)</li><li>Input-dependent branches</li></ul><p>Modern CPUs use dynamic prediction that learns from runtime behavior.</p><h2 id="3-dynamic-branch-prediction">3. Dynamic Branch Prediction</h2><p>Dynamic predictors observe branch behavior and learn patterns.</p><h3 id="31-one-bit-predictor">3.1 One-Bit Predictor</h3><p>The simplest dynamic predictor: remember the last outcome.</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>State: Last outcome (Taken or Not Taken)
</span></span><span style=display:flex><span>Prediction: Same as last outcome
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Branch history:  T T T T T T T N T T T T
</span></span><span style=display:flex><span>Predictions:     ? T T T T T T T N T T T
</span></span><span style=display:flex><span>Correct:         - ✓ ✓ ✓ ✓ ✓ ✓ ✗ ✗ ✓ ✓ ✓
</span></span></code></pre></div><p><strong>Problem:</strong> A loop that executes N times will mispredict twice per invocation:</p><ul><li>First iteration: May mispredict if loop wasn&rsquo;t taken last time</li><li>Last iteration: Always mispredicts (predicts taken, but loop exits)</li></ul><p>For a loop executed millions of times, two mispredictions per invocation is fine. For a loop executed 5 times inside an outer loop of millions, that&rsquo;s 2 million mispredictions!</p><h3 id="32-two-bit-saturating-counter">3.2 Two-Bit Saturating Counter</h3><p>Add hysteresis: don&rsquo;t change prediction on a single wrong outcome.</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>States:
</span></span><span style=display:flex><span>  00: Strongly Not Taken (predict NT)
</span></span><span style=display:flex><span>  01: Weakly Not Taken (predict NT)
</span></span><span style=display:flex><span>  10: Weakly Taken (predict T)
</span></span><span style=display:flex><span>  11: Strongly Taken (predict T)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Transitions:
</span></span><span style=display:flex><span>  On Taken outcome: Increment (max 11)
</span></span><span style=display:flex><span>  On Not Taken outcome: Decrement (min 00)
</span></span></code></pre></div><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>State diagram:
</span></span><span style=display:flex><span>              Taken             Taken
</span></span><span style=display:flex><span>          ┌──────────┐      ┌──────────┐
</span></span><span style=display:flex><span>          ▼          │      ▼          │
</span></span><span style=display:flex><span>     ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐
</span></span><span style=display:flex><span>     │   00   │──│   01   │──│   10   │──│   11   │
</span></span><span style=display:flex><span>     │Strong NT│  │Weak NT │  │Weak T  │  │Strong T│
</span></span><span style=display:flex><span>     └────────┘  └────────┘  └────────┘  └────────┘
</span></span><span style=display:flex><span>          │          ▲      │          ▲
</span></span><span style=display:flex><span>          └──────────┘      └──────────┘
</span></span><span style=display:flex><span>            Not Taken         Not Taken
</span></span></code></pre></div><p><strong>Benefit:</strong> A single anomaly doesn&rsquo;t flip the prediction. The inner loop problem is greatly reduced:</p><ul><li>Loop entry: May be weak, but strong after first execution</li><li>Loop exit: Mispredicts, but stays &ldquo;weakly taken&rdquo; for next invocation</li><li>Next invocation: Correctly predicts taken on first iteration!</li></ul><h3 id="33-branch-target-buffer-btb">3.3 Branch Target Buffer (BTB)</h3><p>Prediction isn&rsquo;t just about direction (taken/not taken). For taken branches, we need the target address.</p><p><strong>Branch Target Buffer:</strong> A cache mapping branch addresses to target addresses.</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>┌─────────────────┬────────────────────┬──────────────┐
</span></span><span style=display:flex><span>│  Branch PC Tag  │  Target Address    │  Prediction  │
</span></span><span style=display:flex><span>├─────────────────┼────────────────────┼──────────────┤
</span></span><span style=display:flex><span>│  0x4000_1234    │  0x4000_5678       │  11 (Strong T)│
</span></span><span style=display:flex><span>│  0x4000_2000    │  0x4000_2100       │  01 (Weak NT) │
</span></span><span style=display:flex><span>│  ...            │  ...               │  ...          │
</span></span><span style=display:flex><span>└─────────────────┴────────────────────┴──────────────┘
</span></span></code></pre></div><p>When a branch is fetched:</p><ol><li>Look up branch PC in BTB</li><li>If hit: Use stored target and prediction</li><li>If miss: Use static prediction, compute target when branch executes</li></ol><p>BTB entries are limited, so not all branches can be tracked. Working set size matters!</p><h2 id="4-correlating-predictors">4. Correlating Predictors</h2><p>Some branches correlate with other branches or with global execution history.</p><h3 id="41-local-history">4.1 Local History</h3><p>A branch may have a pattern based on its own history:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (i <span style=color:#ff7b72;font-weight:700>%</span> <span style=color:#a5d6ff>2</span> <span style=color:#ff7b72;font-weight:700>==</span> <span style=color:#a5d6ff>0</span>) {
</span></span><span style=display:flex><span>        <span style=color:#d2a8ff;font-weight:700>even_work</span>();
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This branch alternates: T, N, T, N, T, N&mldr;</p><p>A local history predictor tracks recent outcomes for each branch:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Local History Table:
</span></span><span style=display:flex><span>┌─────────────────┬────────────────┬──────────────┐
</span></span><span style=display:flex><span>│  Branch PC      │  History (4b)  │  Prediction  │
</span></span><span style=display:flex><span>├─────────────────┼────────────────┼──────────────┤
</span></span><span style=display:flex><span>│  0x4000_1234    │  1010          │  Pattern: alt│
</span></span><span style=display:flex><span>│  0x4000_2000    │  1111          │  Pattern: T  │
</span></span><span style=display:flex><span>└─────────────────┴────────────────┴──────────────┘
</span></span></code></pre></div><p>The history bits index into a Pattern History Table (PHT) of 2-bit counters:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Pattern History Table for branch 0x4000_1234:
</span></span><span style=display:flex><span>History │ Counter │ Prediction
</span></span><span style=display:flex><span>────────┼─────────┼───────────
</span></span><span style=display:flex><span>  0000  │   01    │    NT
</span></span><span style=display:flex><span>  0001  │   11    │    T
</span></span><span style=display:flex><span>  0010  │   10    │    T
</span></span><span style=display:flex><span>  ...   │   ...   │   ...
</span></span><span style=display:flex><span>  1010  │   01    │    NT  ← Current history predicts NT
</span></span></code></pre></div><p>This captures repeating patterns within a single branch.</p><h3 id="42-global-history">4.2 Global History</h3><p>Branches often correlate with each other:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>if</span> (x <span style=color:#ff7b72;font-weight:700>&lt;</span> <span style=color:#a5d6ff>0</span>) {
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// ...
</span></span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Later:
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (x <span style=color:#ff7b72;font-weight:700>&lt;</span> <span style=color:#a5d6ff>0</span>) {  <span style=color:#8b949e;font-style:italic>// Same condition - perfectly correlated!
</span></span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// ...
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Or more subtly:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>if</span> (ptr <span style=color:#ff7b72;font-weight:700>!=</span> NULL) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (ptr<span style=color:#ff7b72;font-weight:700>-&gt;</span>valid) {  <span style=color:#8b949e;font-style:italic>// Very likely taken if first branch was taken
</span></span></span><span style=display:flex><span>        <span style=color:#8b949e;font-style:italic>// ...
</span></span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><strong>Global History Register (GHR):</strong> A shift register tracking the outcomes of recent branches (not just this branch).</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>GHR after sequence T, N, T, T, N, T:
</span></span><span style=display:flex><span>┌───┬───┬───┬───┬───┬───┐
</span></span><span style=display:flex><span>│ T │ N │ T │ T │ N │ T │
</span></span><span style=display:flex><span>└───┴───┴───┴───┴───┴───┘
</span></span><span style=display:flex><span>  ↑
</span></span><span style=display:flex><span>Most recent
</span></span></code></pre></div><p>The GHR indexes into a global Pattern History Table:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Prediction for current branch = PHT[hash(BranchPC, GHR)]
</span></span></code></pre></div><h3 id="43-gshare-predictor">4.3 gshare Predictor</h3><p>The gshare predictor XORs the branch PC with the GHR to index the PHT:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>              Branch PC
</span></span><span style=display:flex><span>                 │
</span></span><span style=display:flex><span>                 ▼
</span></span><span style=display:flex><span>              ┌─────────┐
</span></span><span style=display:flex><span>              │  XOR    │◄──── Global History Register
</span></span><span style=display:flex><span>              └────┬────┘
</span></span><span style=display:flex><span>                   │
</span></span><span style=display:flex><span>                   ▼
</span></span><span style=display:flex><span>         ┌─────────────────────┐
</span></span><span style=display:flex><span>         │  Pattern History    │
</span></span><span style=display:flex><span>         │  Table (2-bit       │
</span></span><span style=display:flex><span>         │  counters)          │
</span></span><span style=display:flex><span>         └─────────────────────┘
</span></span><span style=display:flex><span>                   │
</span></span><span style=display:flex><span>                   ▼
</span></span><span style=display:flex><span>              Prediction
</span></span></code></pre></div><p>gshare captures both:</p><ul><li>Branch-specific patterns (from PC bits)</li><li>Global correlation (from GHR bits)</li></ul><p>It&rsquo;s simple, effective, and widely used as a baseline.</p><h3 id="44-tournament-predictors">4.4 Tournament Predictors</h3><p>Different predictors excel at different branch types. A tournament predictor uses multiple predictors and learns which is best for each branch:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>                    ┌──────────────┐
</span></span><span style=display:flex><span>         ┌─────────│ Local Pred.  │─────────┐
</span></span><span style=display:flex><span>         │         └──────────────┘         │
</span></span><span style=display:flex><span>         │                                  │
</span></span><span style=display:flex><span>         │         ┌──────────────┐         ▼
</span></span><span style=display:flex><span>Branch ──┼────────│ Global Pred. │────────►MUX ──► Prediction
</span></span><span style=display:flex><span>         │         └──────────────┘         ▲
</span></span><span style=display:flex><span>         │                                  │
</span></span><span style=display:flex><span>         │         ┌──────────────┐         │
</span></span><span style=display:flex><span>         └─────────│   Chooser    │─────────┘
</span></span><span style=display:flex><span>                   └──────────────┘
</span></span></code></pre></div><p>The chooser table tracks which predictor was more accurate for each branch (or branch pattern). Alpha 21264 used this design, achieving ~95% accuracy.</p><h2 id="5-modern-branch-predictors">5. Modern Branch Predictors</h2><p>Contemporary CPUs use highly sophisticated predictors with multiple levels.</p><h3 id="51-tage-tagged-geometric-history-length">5.1 TAGE: Tagged Geometric History Length</h3><p>TAGE (TAgged GEometric) is the dominant predictor design in modern CPUs.</p><p>Key insight: Different branches need different history lengths. Loop counters need short history. Complex control flow needs long history.</p><p>TAGE uses multiple tables with geometrically increasing history lengths:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>                      Tagged Tables
</span></span><span style=display:flex><span>             ┌──────┬──────┬──────┬──────┐
</span></span><span style=display:flex><span>             │ T1   │ T2   │ T3   │ T4   │
</span></span><span style=display:flex><span>             │ 4-bit│ 8-bit│16-bit│64-bit│
</span></span><span style=display:flex><span>             │ hist │ hist │ hist │ hist │
</span></span><span style=display:flex><span>             └──────┴──────┴──────┴──────┘
</span></span><span style=display:flex><span>                │      │      │      │
</span></span><span style=display:flex><span>                ▼      ▼      ▼      ▼
</span></span><span style=display:flex><span>             ┌───────────────────────────┐
</span></span><span style=display:flex><span>             │       Provider Select     │
</span></span><span style=display:flex><span>             │   (longest match wins)    │
</span></span><span style=display:flex><span>             └───────────────────────────┘
</span></span><span style=display:flex><span>                          │
</span></span><span style=display:flex><span>                          ▼
</span></span><span style=display:flex><span>                     Prediction
</span></span></code></pre></div><p>Each table entry has:</p><ul><li>Tag (partial PC + history hash)</li><li>Prediction counter (2-3 bits)</li><li>Useful counter (for replacement)</li></ul><p>The table with the longest matching history provides the prediction. TAGE achieves ~97% accuracy on typical workloads.</p><h3 id="52-perceptron-predictors">5.2 Perceptron Predictors</h3><p>Neural-inspired predictors learn weights for history bits:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Prediction = sign(w₀ + Σ(wᵢ × hᵢ))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Where:
</span></span><span style=display:flex><span>  w₀ = bias weight
</span></span><span style=display:flex><span>  wᵢ = weight for history bit i
</span></span><span style=display:flex><span>  hᵢ = history bit i (+1 for taken, -1 for not taken)
</span></span></code></pre></div><p>Training is simple: if mispredicted, adjust weights toward the correct outcome.</p><p>Perceptrons can capture complex correlations that table-based predictors miss. AMD&rsquo;s Zen architecture uses perceptron-based predictors.</p><h3 id="53-loop-predictors">5.3 Loop Predictors</h3><p>Loops have predictable iteration counts. Dedicated loop predictors detect and track loops:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Loop Predictor Entry:
</span></span><span style=display:flex><span>┌─────────────┬───────────┬───────────┬──────────┐
</span></span><span style=display:flex><span>│  Branch PC  │  Limit    │  Count    │ Confident│
</span></span><span style=display:flex><span>├─────────────┼───────────┼───────────┼──────────┤
</span></span><span style=display:flex><span>│ 0x4000_1234 │    100    │    57     │   Yes    │
</span></span><span style=display:flex><span>└─────────────┴───────────┴───────────┴──────────┘
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Prediction: Taken until Count reaches Limit
</span></span></code></pre></div><p>When a loop is detected (repeated back-edge), the predictor:</p><ol><li>Learns the iteration count</li><li>Predicts taken until count reached</li><li>Predicts not taken on final iteration</li></ol><p>This eliminates the &ldquo;last iteration&rdquo; misprediction that plagues other predictors.</p><h3 id="54-return-address-stack">5.4 Return Address Stack</h3><p>Function returns are indirect branches (target varies). But they follow a pattern: return to the instruction after the call.</p><p><strong>Return Address Stack (RAS):</strong> A small stack that tracks call sites.</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Call site 0x1000 ──► Push 0x1004
</span></span><span style=display:flex><span>Call site 0x2000 ──► Push 0x2004
</span></span><span style=display:flex><span>Call site 0x3000 ──► Push 0x3004
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Return ──► Pop 0x3004 (predict return to 0x3004)
</span></span><span style=display:flex><span>Return ──► Pop 0x2004 (predict return to 0x2004)
</span></span><span style=display:flex><span>Return ──► Pop 0x1000 (predict return to 0x1004)
</span></span></code></pre></div><p>RAS handles returns with near-perfect accuracy for normal call/return patterns. Problems arise with:</p><ul><li>Exceptions (unwind stack without returns)</li><li>Tail calls (return address isn&rsquo;t pushed)</li><li>Speculation (speculative calls corrupt RAS)</li></ul><p>Modern CPUs use techniques like checkpointing to recover RAS on misprediction.</p><h2 id="6-indirect-branch-prediction">6. Indirect Branch Prediction</h2><p>Most branches have a fixed target (direct branches). But some have variable targets:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Virtual function call
</span></span></span><span style=display:flex><span>obj<span style=color:#ff7b72;font-weight:700>-&gt;</span><span style=color:#d2a8ff;font-weight:700>method</span>();  <span style=color:#8b949e;font-style:italic>// Target depends on object&#39;s vtable
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Switch statement (jump table)
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>switch</span> (x) { ... }  <span style=color:#8b949e;font-style:italic>// Target depends on x
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Function pointer
</span></span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>callback</span>(data);  <span style=color:#8b949e;font-style:italic>// Target is the function pointer value
</span></span></span></code></pre></div><h3 id="61-indirect-target-array-ita">6.1 Indirect Target Array (ITA)</h3><p>Simple approach: cache recently seen targets.</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>┌─────────────────┬────────────────────┐
</span></span><span style=display:flex><span>│  Branch PC      │  Recent Targets    │
</span></span><span style=display:flex><span>├─────────────────┼────────────────────┤
</span></span><span style=display:flex><span>│  0x4000_1234    │  0x5000, 0x6000    │
</span></span><span style=display:flex><span>│  0x4000_2000    │  0x7000            │
</span></span><span style=display:flex><span>└─────────────────┴────────────────────┘
</span></span></code></pre></div><p>Predict the most recently seen target. Works well for monomorphic call sites (one target) but poorly for polymorphic calls.</p><h3 id="62-indirect-target-predictor-with-history">6.2 Indirect Target Predictor with History</h3><p>Like branch direction, indirect targets can correlate with history:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>switch</span> (state) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>case</span> <span style=color:#79c0ff;font-weight:700>A</span>: next_state <span style=color:#ff7b72;font-weight:700>=</span> B; <span style=color:#ff7b72>break</span>;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>case</span> <span style=color:#79c0ff;font-weight:700>B</span>: next_state <span style=color:#ff7b72;font-weight:700>=</span> C; <span style=color:#ff7b72>break</span>;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>case</span> <span style=color:#79c0ff;font-weight:700>C</span>: next_state <span style=color:#ff7b72;font-weight:700>=</span> A; <span style=color:#ff7b72>break</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Repeating pattern: A→B→C→A→B→C...
</span></span></span></code></pre></div><p>Modern indirect predictors use history to predict targets:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Prediction = TargetTable[hash(BranchPC, GHR)]
</span></span></code></pre></div><h3 id="63-virtual-call-optimization">6.3 Virtual Call Optimization</h3><p>Virtual calls are common in OOP code. Techniques to help prediction:</p><p><strong>Devirtualization:</strong> Compiler converts virtual calls to direct calls when the type is known.</p><p><strong>Polymorphic inline caches:</strong> At runtime, cache recent receiver types and inline the predicted path.</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Polymorphic inline cache (pseudocode)
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (obj<span style=color:#ff7b72;font-weight:700>-&gt;</span>type <span style=color:#ff7b72;font-weight:700>==</span> cached_type) {
</span></span><span style=display:flex><span>    <span style=color:#d2a8ff;font-weight:700>cached_method</span>(obj);  <span style=color:#8b949e;font-style:italic>// Fast path, direct call
</span></span></span><span style=display:flex><span>} <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>    obj<span style=color:#ff7b72;font-weight:700>-&gt;</span>vtable[method_index](obj);  <span style=color:#8b949e;font-style:italic>// Slow path
</span></span></span><span style=display:flex><span>    cached_type <span style=color:#ff7b72;font-weight:700>=</span> obj<span style=color:#ff7b72;font-weight:700>-&gt;</span>type;  <span style=color:#8b949e;font-style:italic>// Update cache
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id="7-speculative-execution">7. Speculative Execution</h2><p>Branch prediction enables speculation—executing instructions before knowing if they should execute.</p><h3 id="71-how-speculation-works">7.1 How Speculation Works</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Time ──────────────────────────────────────────────►
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Instruction stream: A, B, BRANCH, C, D, E...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Pipeline:
</span></span><span style=display:flex><span>Cycle 1: Fetch A
</span></span><span style=display:flex><span>Cycle 2: Fetch B, Decode A
</span></span><span style=display:flex><span>Cycle 3: Fetch BRANCH, Decode B, Execute A
</span></span><span style=display:flex><span>Cycle 4: Fetch C (speculative!), Decode BRANCH, Execute B
</span></span><span style=display:flex><span>Cycle 5: Fetch D (speculative!), Decode C, Execute BRANCH
</span></span><span style=display:flex><span>         └─► Branch resolves: prediction was CORRECT
</span></span><span style=display:flex><span>Cycle 6: Fetch E, Decode D, Execute C  (all valid!)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>If prediction was WRONG:
</span></span><span style=display:flex><span>Cycle 5: Branch resolves wrong
</span></span><span style=display:flex><span>         Flush C, D from pipeline
</span></span><span style=display:flex><span>         Restart fetch from correct path
</span></span></code></pre></div><h3 id="72-speculative-state-management">7.2 Speculative State Management</h3><p>Speculative instructions can&rsquo;t modify permanent state until the branch is confirmed. CPUs use:</p><p><strong>Reorder Buffer (ROB):</strong> Instructions complete out-of-order but retire (commit) in order. Speculative instructions wait in the ROB until the branch commits.</p><p><strong>Physical Register File:</strong> Results are written to physical registers. Architectural registers are updated only on retirement.</p><p><strong>Store Buffer:</strong> Stores wait in a buffer until retirement, then write to cache.</p><h3 id="73-memory-ordering-and-speculation">7.3 Memory Ordering and Speculation</h3><p>Speculative loads are tricky:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>if</span> (x <span style=color:#ff7b72;font-weight:700>&lt;</span> array_size) {      <span style=color:#8b949e;font-style:italic>// Mispredicted as taken
</span></span></span><span style=display:flex><span>    value <span style=color:#ff7b72;font-weight:700>=</span> array[x];       <span style=color:#8b949e;font-style:italic>// Speculative load (x might be out of bounds!)
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The load executes speculatively, potentially accessing invalid memory. Modern CPUs:</p><ul><li>Allow speculative loads (for performance)</li><li>Check bounds when the load retires</li><li>Squash if the load was invalid</li></ul><p>But the load still affects microarchitectural state (caches, TLBs), leading to security issues&mldr;</p><h2 id="8-security-spectre-and-friends">8. Security: Spectre and Friends</h2><p>Speculative execution vulnerabilities shocked the industry in 2018. They exploit the side effects of mispredicted speculation.</p><h3 id="81-spectre-variant-1-bounds-check-bypass">8.1 Spectre Variant 1: Bounds Check Bypass</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>if</span> (x <span style=color:#ff7b72;font-weight:700>&lt;</span> array1_size) {           <span style=color:#8b949e;font-style:italic>// Can be mispredicted!
</span></span></span><span style=display:flex><span>    y <span style=color:#ff7b72;font-weight:700>=</span> array2[array1[x] <span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#a5d6ff>256</span>]; <span style=color:#8b949e;font-style:italic>// Speculatively executed with bad x
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Attack:</p><ol><li>Train predictor to expect branch taken</li><li>Call with <code>x</code> out of bounds</li><li>Speculative execution reads <code>array1[x]</code> (secret data)</li><li>Uses secret as index into <code>array2</code>, loading a cache line</li><li>Branch misprediction detected, execution rolled back</li><li><strong>But:</strong> Cache state persists! The loaded cache line reveals the secret</li></ol><p>This leaks arbitrary memory through cache timing side channels.</p><h3 id="82-spectre-variant-2-branch-target-injection">8.2 Spectre Variant 2: Branch Target Injection</h3><p>Indirect branch prediction can be poisoned:</p><ol><li>Attacker trains BTB with malicious target</li><li>Victim process executes indirect branch</li><li>Speculation jumps to attacker-chosen &ldquo;gadget&rdquo;</li><li>Gadget leaks secrets via cache side channel</li><li>Speculation rolled back, but cache side effects remain</li></ol><p>This allows cross-process and cross-privilege attacks.</p><h3 id="83-mitigations">8.3 Mitigations</h3><p><strong>Software mitigations:</strong></p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Speculation barrier
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (x <span style=color:#ff7b72;font-weight:700>&lt;</span> array_size) {
</span></span><span style=display:flex><span>    __asm__ <span style=color:#ff7b72>volatile</span>(<span style=color:#a5d6ff>&#34;lfence&#34;</span>);  <span style=color:#8b949e;font-style:italic>// Block speculation
</span></span></span><span style=display:flex><span>    y <span style=color:#ff7b72;font-weight:700>=</span> array[x];
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Array index masking
</span></span></span><span style=display:flex><span>x <span style=color:#ff7b72;font-weight:700>&amp;=</span> <span style=color:#ff7b72;font-weight:700>~</span>(<span style=color:#ff7b72;font-weight:700>-</span>(x <span style=color:#ff7b72;font-weight:700>&gt;=</span> array_size));  <span style=color:#8b949e;font-style:italic>// Clamp x to valid range
</span></span></span></code></pre></div><p><strong>Hardware mitigations:</strong></p><ul><li>IBRS/IBPB: Indirect Branch Restricted/Prediction Barrier</li><li>STIBP: Single Thread Indirect Branch Predictor</li><li>Enhanced IBRS: Hardware mode that isolates prediction</li><li>Microcode updates: Various fixes for specific variants</li></ul><p><strong>Performance impact:</strong> Mitigations can cost 2-30% performance depending on workload and mitigation level.</p><h3 id="84-the-fundamental-problem">8.4 The Fundamental Problem</h3><p>Speculation side channels exist because:</p><ol><li>Prediction affects what instructions execute (even speculatively)</li><li>Speculative execution affects microarchitectural state</li><li>Microarchitectural state is observable through timing</li></ol><p>Fixing this fundamentally would require either:</p><ul><li>Never speculate (massive performance loss)</li><li>Isolate all microarchitectural state (extremely difficult)</li><li>Eliminate timing side channels (practically impossible)</li></ul><p>Modern CPUs continue to balance security and performance with targeted mitigations.</p><h2 id="9-writing-branch-prediction-friendly-code">9. Writing Branch-Prediction-Friendly Code</h2><p>Understanding prediction helps you write faster code.</p><h3 id="91-make-branches-predictable">9.1 Make Branches Predictable</h3><p>Sort data when possible:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Unpredictable: random true/false
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (data[i] <span style=color:#ff7b72;font-weight:700>&gt;=</span> <span style=color:#a5d6ff>128</span>) {  <span style=color:#8b949e;font-style:italic>// ~50% taken if random
</span></span></span><span style=display:flex><span>        sum <span style=color:#ff7b72;font-weight:700>+=</span> data[i];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Better: sort first, then all false followed by all true
</span></span></span><span style=display:flex><span>std<span style=color:#ff7b72;font-weight:700>::</span><span style=color:#d2a8ff;font-weight:700>sort</span>(data, data <span style=color:#ff7b72;font-weight:700>+</span> n);
</span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (data[i] <span style=color:#ff7b72;font-weight:700>&gt;=</span> <span style=color:#a5d6ff>128</span>) {  <span style=color:#8b949e;font-style:italic>// First N iterations false, rest true
</span></span></span><span style=display:flex><span>        sum <span style=color:#ff7b72;font-weight:700>+=</span> data[i];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The sorted version can be 3-5x faster due to better prediction!</p><h3 id="92-use-conditional-moves">9.2 Use Conditional Moves</h3><p>Replace branches with conditional moves when possible:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Branchy version
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (a <span style=color:#ff7b72;font-weight:700>&gt;</span> b) {
</span></span><span style=display:flex><span>    max <span style=color:#ff7b72;font-weight:700>=</span> a;
</span></span><span style=display:flex><span>} <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>    max <span style=color:#ff7b72;font-weight:700>=</span> b;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Branchless version (compiler may generate CMOV)
</span></span></span><span style=display:flex><span>max <span style=color:#ff7b72;font-weight:700>=</span> (a <span style=color:#ff7b72;font-weight:700>&gt;</span> b) <span style=color:#ff7b72;font-weight:700>?</span> <span style=color:#79c0ff;font-weight:700>a</span> : b;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Explicitly branchless
</span></span></span><span style=display:flex><span>max <span style=color:#ff7b72;font-weight:700>=</span> b <span style=color:#ff7b72;font-weight:700>^</span> ((a <span style=color:#ff7b72;font-weight:700>^</span> b) <span style=color:#ff7b72;font-weight:700>&amp;</span> <span style=color:#ff7b72;font-weight:700>-</span>(a <span style=color:#ff7b72;font-weight:700>&gt;</span> b));
</span></span></code></pre></div><p>Conditional moves have fixed latency (~1-2 cycles) regardless of data patterns. Useful when:</p><ul><li>Branch is unpredictable (near 50/50)</li><li>Both paths are simple (cheap to compute both)</li></ul><p><strong>Warning:</strong> Don&rsquo;t use branchless code blindly! If the branch is predictable, branches are faster because they can speculate ahead.</p><h3 id="93-loop-unrolling">9.3 Loop Unrolling</h3><p>Reduce branch overhead by processing multiple elements per iteration:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Original: 1 branch per element
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    sum <span style=color:#ff7b72;font-weight:700>+=</span> a[i];
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Unrolled: 1 branch per 4 elements
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i <span style=color:#ff7b72;font-weight:700>+=</span> <span style=color:#a5d6ff>4</span>) {
</span></span><span style=display:flex><span>    sum <span style=color:#ff7b72;font-weight:700>+=</span> a[i] <span style=color:#ff7b72;font-weight:700>+</span> a[i<span style=color:#ff7b72;font-weight:700>+</span><span style=color:#a5d6ff>1</span>] <span style=color:#ff7b72;font-weight:700>+</span> a[i<span style=color:#ff7b72;font-weight:700>+</span><span style=color:#a5d6ff>2</span>] <span style=color:#ff7b72;font-weight:700>+</span> a[i<span style=color:#ff7b72;font-weight:700>+</span><span style=color:#a5d6ff>3</span>];
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Fewer branches = fewer opportunities for misprediction.</p><h3 id="94-profile-guided-optimization-pgo">9.4 Profile-Guided Optimization (PGO)</h3><p>Let the compiler learn branch behavior:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-bash" data-lang=bash><span style=display:flex><span><span style=color:#8b949e;font-style:italic># Step 1: Build instrumented binary</span>
</span></span><span style=display:flex><span>gcc -fprofile-generate -O2 program.c -o program
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic># Step 2: Run with representative workload</span>
</span></span><span style=display:flex><span>./program typical_input.txt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic># Step 3: Rebuild with profile data</span>
</span></span><span style=display:flex><span>gcc -fprofile-use -O2 program.c -o program
</span></span></code></pre></div><p>PGO enables:</p><ul><li>Better branch prediction hints</li><li>Hot path optimization</li><li>Cold path outlining</li><li>Better inlining decisions</li></ul><p>PGO can improve performance by 10-30% for branch-heavy code.</p><h3 id="95-avoid-unpredictable-indirect-branches">9.5 Avoid Unpredictable Indirect Branches</h3><p>Virtual calls and function pointers are indirect branches:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c++" data-lang=c++><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Hard to predict: polymorphic
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (Shape<span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#79c0ff;font-weight:700>s</span> : shapes) {
</span></span><span style=display:flex><span>    s<span style=color:#ff7b72;font-weight:700>-&gt;</span>draw();  <span style=color:#8b949e;font-style:italic>// Different target each time
</span></span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Easier to predict: monomorphic or sorted
</span></span></span><span style=display:flex><span>std<span style=color:#ff7b72;font-weight:700>::</span>sort(shapes.begin(), shapes.end(),
</span></span><span style=display:flex><span>          [](<span style=color:#ff7b72>auto</span> a, <span style=color:#ff7b72>auto</span> b) { <span style=color:#ff7b72>return</span> <span style=color:#d2a8ff;font-weight:700>typeid</span>(<span style=color:#ff7b72;font-weight:700>*</span>a).name() <span style=color:#ff7b72;font-weight:700>&lt;</span> <span style=color:#ff7b72>typeid</span>(<span style=color:#ff7b72;font-weight:700>*</span>b).name(); });
</span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (Shape<span style=color:#ff7b72;font-weight:700>*</span> <span style=color:#79c0ff;font-weight:700>s</span> : shapes) {
</span></span><span style=display:flex><span>    s<span style=color:#ff7b72;font-weight:700>-&gt;</span>draw();  <span style=color:#8b949e;font-style:italic>// Targets cluster together
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id="10-measuring-branch-performance">10. Measuring Branch Performance</h2><h3 id="101-performance-counters">10.1 Performance Counters</h3><p>Modern CPUs provide hardware counters for branch events:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-bash" data-lang=bash><span style=display:flex><span><span style=color:#8b949e;font-style:italic># Linux perf</span>
</span></span><span style=display:flex><span>perf stat -e branches,branch-misses ./program
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic># Example output:</span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>#  1,234,567,890  branches</span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>#     12,345,678  branch-misses  # 1.00% of all branches</span>
</span></span></code></pre></div><p>Key metrics:</p><ul><li><strong>Branch misprediction rate:</strong> Aim for &lt; 2% on hot paths</li><li><strong>Instructions per branch:</strong> Lower means more control flow</li><li><strong>Branch MPKI:</strong> Mispredictions per kilo-instructions</li></ul><h3 id="102-microbenchmarking">10.2 Microbenchmarking</h3><p>Isolate branch prediction effects:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Predictable pattern
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> N; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (i <span style=color:#ff7b72;font-weight:700>%</span> <span style=color:#a5d6ff>2</span> <span style=color:#ff7b72;font-weight:700>==</span> <span style=color:#a5d6ff>0</span>) sum<span style=color:#ff7b72;font-weight:700>++</span>;  <span style=color:#8b949e;font-style:italic>// Alternating: TNTNTN...
</span></span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Unpredictable pattern
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> N; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>rand</span>() <span style=color:#ff7b72;font-weight:700>%</span> <span style=color:#a5d6ff>2</span> <span style=color:#ff7b72;font-weight:700>==</span> <span style=color:#a5d6ff>0</span>) sum<span style=color:#ff7b72;font-weight:700>++</span>;  <span style=color:#8b949e;font-style:italic>// Random: ???
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Compare performance to quantify prediction impact.</p><h3 id="103-cpu-specific-analysis">10.3 CPU-Specific Analysis</h3><p>Intel VTune and AMD uProf provide detailed branch analysis:</p><ul><li>Per-branch misprediction rates</li><li>BTB hit/miss rates</li><li>Indirect branch target patterns</li><li>Speculation efficiency</li></ul><h2 id="11-branch-prediction-across-architectures">11. Branch Prediction Across Architectures</h2><h3 id="111-x86-intelamd">11.1 x86 (Intel/AMD)</h3><p>Intel Haswell and later use TAGE-like predictors with:</p><ul><li>Multiple prediction tables</li><li>Loop predictors</li><li>Return address stack (16-32 entries)</li><li>Indirect target predictors</li></ul><p>AMD Zen uses perceptron-based predictors with:</p><ul><li>TAGE backup</li><li>Large history lengths</li><li>Sophisticated indirect prediction</li></ul><p>Both achieve ~97% accuracy on typical workloads.</p><h3 id="112-arm">11.2 ARM</h3><p>ARM cores vary widely:</p><ul><li><strong>Cortex-A55 (efficiency):</strong> Simple bimodal predictor, ~85% accuracy</li><li><strong>Cortex-A78 (performance):</strong> TAGE-like, ~95% accuracy</li><li><strong>Apple M-series:</strong> Highly sophisticated, possibly perceptron-based</li></ul><p>ARM&rsquo;s big.LITTLE design means prediction quality varies between cores.</p><h3 id="113-risc-v">11.3 RISC-V</h3><p>RISC-V is an ISA, not an implementation. Predictors vary by vendor:</p><ul><li>SiFive U74: gshare-based, moderate accuracy</li><li>Alibaba XuanTie: TAGE-based, high accuracy</li><li>Research implementations: Testing novel predictor designs</li></ul><h3 id="114-gpu-prediction">11.4 GPU &ldquo;Prediction&rdquo;</h3><p>GPUs handle branches differently:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>SIMD Execution:
</span></span><span style=display:flex><span>Thread 0:  if (true)  { A } else { B }
</span></span><span style=display:flex><span>Thread 1:  if (true)  { A } else { B }
</span></span><span style=display:flex><span>Thread 2:  if (false) { A } else { B }
</span></span><span style=display:flex><span>Thread 3:  if (true)  { A } else { B }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Execution:
</span></span><span style=display:flex><span>1. All threads execute A (thread 2 masked)
</span></span><span style=display:flex><span>2. All threads execute B (threads 0,1,3 masked)
</span></span></code></pre></div><p>GPUs don&rsquo;t predict; they execute both paths with masking. This is called <strong>divergence</strong> and is why GPU code should minimize branches.</p><h2 id="12-advanced-topics">12. Advanced Topics</h2><h3 id="121-branch-prediction-and-smt">12.1 Branch Prediction and SMT</h3><p>Simultaneous Multithreading (Hyper-Threading) shares prediction resources:</p><ul><li>BTB entries are shared or partitioned</li><li>GHR may be per-thread or shared</li><li>Prediction tables compete for space</li></ul><p>Competing threads can cause prediction interference. Some CPUs partition resources for security (prevent cross-thread Spectre attacks).</p><h3 id="122-speculative-memory-disambiguation">12.2 Speculative Memory Disambiguation</h3><p>Modern CPUs speculate on memory dependencies:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span>store [A], value1
</span></span><span style=display:flex><span>load  [B]  <span style=color:#8b949e;font-style:italic>// Does B alias A?
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// CPU speculates &#34;no alias&#34;, executes load early
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// If wrong, replay the load after the store completes
</span></span></span></code></pre></div><p>This is called memory disambiguation prediction. Misprediction causes pipeline flushes similar to branch misprediction.</p><h3 id="123-value-prediction">12.3 Value Prediction</h3><p>Why stop at predicting branches? We could predict values:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span>x <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>load_from_memory</span>();  <span style=color:#8b949e;font-style:italic>// Predict x = 42
</span></span></span><span style=display:flex><span>y <span style=color:#ff7b72;font-weight:700>=</span> x <span style=color:#ff7b72;font-weight:700>+</span> <span style=color:#a5d6ff>1</span>;               <span style=color:#8b949e;font-style:italic>// Speculatively compute y = 43
</span></span></span></code></pre></div><p>Value prediction has been researched for decades but isn&rsquo;t in mainstream CPUs due to:</p><ul><li>Complexity of recovery on misprediction</li><li>Limited accuracy for most values</li><li>Area/power costs</li></ul><p>Some specialized uses exist (stride predictors for addresses).</p><h3 id="124-machine-learning-predictors">12.4 Machine Learning Predictors</h3><p>Research explores ML for prediction:</p><ul><li>Neural networks for branch prediction</li><li>Reinforcement learning for predictor training</li><li>Learned index structures for BTB</li></ul><p>Challenge: ML inference must complete in &lt; 1 cycle, limiting model complexity.</p><h2 id="13-historical-perspective">13. Historical Perspective</h2><h3 id="131-early-predictors-1980s">13.1 Early Predictors (1980s)</h3><ul><li>Simple static prediction</li><li>One-bit dynamic predictors</li><li>Small BTBs</li></ul><p>Accuracy: ~70-80%</p><h3 id="132-two-level-predictors-1990s">13.2 Two-Level Predictors (1990s)</h3><ul><li>Local and global history</li><li>gshare, gselect</li><li>Tournament predictors</li></ul><p>Accuracy: ~90-95%</p><h3 id="133-modern-predictors-2000s-present">13.3 Modern Predictors (2000s-present)</h3><ul><li>TAGE and variants</li><li>Perceptron predictors</li><li>Sophisticated loop/return prediction</li></ul><p>Accuracy: ~97%+</p><ul><li>Sophisticated loop/return prediction</li></ul><p>Accuracy: ~97%+</p><h3 id="134-the-accuracy-wall">13.4 The Accuracy Wall</h3><p>Prediction accuracy has plateaued:</p><ul><li>Easy branches are already perfect</li><li>Hard branches are fundamentally unpredictable</li><li>Diminishing returns from predictor complexity</li></ul><p>Future gains likely come from:</p><ul><li>Reducing misprediction penalty</li><li>Better speculative execution management</li><li>Compiler assistance</li></ul><h2 id="14-real-world-case-studies">14. Real-World Case Studies</h2><p>Understanding branch prediction theory is valuable, but seeing real performance impacts cements the knowledge.</p><h3 id="141-the-sorted-array-benchmark">14.1 The Sorted Array Benchmark</h3><p>The famous Stack Overflow question &ldquo;Why is processing a sorted array faster than an unsorted array?&rdquo; demonstrates branch prediction perfectly:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-cpp" data-lang=cpp><span style=display:flex><span><span style=color:#ff7b72>int</span> <span style=color:#d2a8ff;font-weight:700>main</span>() {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>const</span> <span style=color:#ff7b72>int</span> arraySize <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>32768</span>;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>int</span> data[arraySize];
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Fill with random values 0-255
</span></span></span><span style=display:flex><span>    <span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> c <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; c <span style=color:#ff7b72;font-weight:700>&lt;</span> arraySize; <span style=color:#ff7b72;font-weight:700>++</span>c)
</span></span><span style=display:flex><span>        data[c] <span style=color:#ff7b72;font-weight:700>=</span> std<span style=color:#ff7b72;font-weight:700>::</span>rand() <span style=color:#ff7b72;font-weight:700>%</span> <span style=color:#a5d6ff>256</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Optionally sort
</span></span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// std::sort(data, data + arraySize);
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>long</span> <span style=color:#ff7b72>long</span> sum <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> <span style=color:#a5d6ff>100000</span>; <span style=color:#ff7b72;font-weight:700>++</span>i) {
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> c <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; c <span style=color:#ff7b72;font-weight:700>&lt;</span> arraySize; <span style=color:#ff7b72;font-weight:700>++</span>c) {
</span></span><span style=display:flex><span>            <span style=color:#ff7b72>if</span> (data[c] <span style=color:#ff7b72;font-weight:700>&gt;=</span> <span style=color:#a5d6ff>128</span>)
</span></span><span style=display:flex><span>                sum <span style=color:#ff7b72;font-weight:700>+=</span> data[c];
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Results:</p><ul><li><strong>Unsorted:</strong> ~10 seconds</li><li><strong>Sorted:</strong> ~2 seconds</li></ul><p>The sorted version is 5x faster because the branch becomes predictable. First half: all not-taken. Second half: all taken.</p><h3 id="142-json-parsing-branches">14.2 JSON Parsing Branches</h3><p>JSON parsers are branch-heavy, checking character types continuously:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>while</span> (<span style=color:#ff7b72;font-weight:700>*</span>p) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (<span style=color:#ff7b72;font-weight:700>*</span>p <span style=color:#ff7b72;font-weight:700>==</span> <span style=color:#a5d6ff>&#39;&#34;&#39;</span>) <span style=color:#d2a8ff;font-weight:700>parse_string</span>();
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>else</span> <span style=color:#d2a8ff;font-weight:700>if</span> (<span style=color:#ff7b72;font-weight:700>*</span>p <span style=color:#ff7b72;font-weight:700>==</span> <span style=color:#a5d6ff>&#39;{&#39;</span>) <span style=color:#d2a8ff;font-weight:700>parse_object</span>();
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>else</span> <span style=color:#d2a8ff;font-weight:700>if</span> (<span style=color:#ff7b72;font-weight:700>*</span>p <span style=color:#ff7b72;font-weight:700>==</span> <span style=color:#a5d6ff>&#39;[&#39;</span>) <span style=color:#d2a8ff;font-weight:700>parse_array</span>();
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>else</span> <span style=color:#d2a8ff;font-weight:700>if</span> (<span style=color:#d2a8ff;font-weight:700>isdigit</span>(<span style=color:#ff7b72;font-weight:700>*</span>p)) <span style=color:#d2a8ff;font-weight:700>parse_number</span>();
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// ...
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Optimized parsers like simdjson use:</p><ul><li>SIMD to classify multiple characters at once</li><li>Branchless state machines</li><li>Data-parallel parsing</li></ul><p>simdjson achieves 2-4GB/s versus ~200MB/s for traditional parsers, largely by eliminating unpredictable branches.</p><h3 id="143-game-engine-physics">14.3 Game Engine Physics</h3><p>Physics engines often process many objects:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-cpp" data-lang=cpp><span style=display:flex><span><span style=color:#ff7b72>for</span> (Entity<span style=color:#ff7b72;font-weight:700>&amp;</span> <span style=color:#79c0ff;font-weight:700>e</span> : entities) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (e.hasPhysics) {
</span></span><span style=display:flex><span>        <span style=color:#ff7b72>if</span> (e.isAwake) {
</span></span><span style=display:flex><span>            <span style=color:#ff7b72>if</span> (e.collisionEnabled) {
</span></span><span style=display:flex><span>                <span style=color:#8b949e;font-style:italic>// Process physics
</span></span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Optimizations:</p><ul><li>Sort entities by type (all physics entities together)</li><li>Use data-oriented design (separate arrays for different properties)</li><li>Process in batches of similar entities</li></ul><p>Modern engines achieve 10-100x improvements through branch-friendly data organization.</p><h3 id="144-database-query-processing">14.4 Database Query Processing</h3><p>Database queries involve many branches:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Filter predicate
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (Row<span style=color:#ff7b72;font-weight:700>&amp;</span> <span style=color:#79c0ff;font-weight:700>row</span> : table) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (row.age <span style=color:#ff7b72;font-weight:700>&gt;</span> <span style=color:#a5d6ff>30</span> <span style=color:#ff7b72;font-weight:700>&amp;&amp;</span> row.salary <span style=color:#ff7b72;font-weight:700>&gt;</span> <span style=color:#a5d6ff>50000</span> <span style=color:#ff7b72;font-weight:700>&amp;&amp;</span> row.dept <span style=color:#ff7b72;font-weight:700>==</span> <span style=color:#a5d6ff>&#34;ENG&#34;</span>) {
</span></span><span style=display:flex><span>        results.<span style=color:#d2a8ff;font-weight:700>push_back</span>(row);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Database optimizations:</p><ul><li>Vectorized execution (process columns in batches)</li><li>Predicate reordering (most selective first)</li><li>Compiled queries (eliminate interpretation overhead)</li></ul><p>Vectorized databases like DuckDB, ClickHouse achieve order-of-magnitude improvements.</p><h2 id="15-compiler-optimizations-for-branches">15. Compiler Optimizations for Branches</h2><p>Compilers employ sophisticated techniques to improve branch behavior.</p><h3 id="151-if-conversion">15.1 If-Conversion</h3><p>Convert branches to conditional moves:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Original
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (condition) {
</span></span><span style=display:flex><span>    x <span style=color:#ff7b72;font-weight:700>=</span> a;
</span></span><span style=display:flex><span>} <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>    x <span style=color:#ff7b72;font-weight:700>=</span> b;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// If-converted (compiler generates CMOV)
</span></span></span><span style=display:flex><span>x <span style=color:#ff7b72;font-weight:700>=</span> condition <span style=color:#ff7b72;font-weight:700>?</span> <span style=color:#79c0ff;font-weight:700>a</span> : b;
</span></span></code></pre></div><p>Compilers apply if-conversion when:</p><ul><li>Both paths are simple</li><li>Branch is likely unpredictable</li><li>Architecture supports conditional moves</li></ul><h3 id="152-branch-probability-propagation">15.2 Branch Probability Propagation</h3><p>Compilers track branch probabilities through the code:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>error_check</span>()) {  <span style=color:#8b949e;font-style:italic>// Rare: 0.01%
</span></span></span><span style=display:flex><span>    <span style=color:#d2a8ff;font-weight:700>handle_error</span>();   <span style=color:#8b949e;font-style:italic>// Also rare
</span></span></span><span style=display:flex><span>    <span style=color:#ff7b72>return</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Normal path: 99.99%
</span></span></span><span style=display:flex><span><span style=color:#d2a8ff;font-weight:700>do_work</span>();
</span></span></code></pre></div><p>Probabilities inform:</p><ul><li>Code layout (hot path falls through)</li><li>Inlining decisions (inline hot paths)</li><li>Register allocation (optimize for hot path)</li></ul><h3 id="153-hotcold-splitting">15.3 Hot/Cold Splitting</h3><p>Move unlikely code out of hot paths:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Before
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>process</span>() {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>unlikely</span>(error)) {
</span></span><span style=display:flex><span>        <span style=color:#8b949e;font-style:italic>// 100 lines of error handling
</span></span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Hot path
</span></span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// After (compiler splits)
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>void</span> <span style=color:#d2a8ff;font-weight:700>process</span>() {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (<span style=color:#d2a8ff;font-weight:700>unlikely</span>(error)) {
</span></span><span style=display:flex><span>        <span style=color:#d2a8ff;font-weight:700>handle_error_cold</span>();  <span style=color:#8b949e;font-style:italic>// Outlined to separate function
</span></span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>// Hot path (better instruction cache)
</span></span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Cold code outlining improves instruction cache utilization for hot paths.</p><h3 id="154-loop-unswitching">15.4 Loop Unswitching</h3><p>Hoist loop-invariant conditions:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Before
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (flag) {  <span style=color:#8b949e;font-style:italic>// Loop-invariant!
</span></span></span><span style=display:flex><span>        <span style=color:#d2a8ff;font-weight:700>work_a</span>(i);
</span></span><span style=display:flex><span>    } <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>        <span style=color:#d2a8ff;font-weight:700>work_b</span>(i);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// After unswitching
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (flag) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#d2a8ff;font-weight:700>work_a</span>(i);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>} <span style=color:#ff7b72>else</span> {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> n; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#d2a8ff;font-weight:700>work_b</span>(i);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Eliminates n-1 branches, improving prediction and enabling further optimizations.</p><h3 id="155-speculative-compilation">15.5 Speculative Compilation</h3><p>JIT compilers can optimize based on runtime behavior:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-java" data-lang=java><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// HotSpot JVM</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span><span style=color:#6e7681> </span>(obj<span style=color:#6e7681> </span><span style=color:#ff7b72>instanceof</span><span style=color:#6e7681> </span>Dog)<span style=color:#6e7681> </span>{<span style=color:#6e7681>  </span><span style=color:#8b949e;font-style:italic>// 99% Dog</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>    </span>((Dog)<span style=color:#6e7681> </span>obj).bark();<span style=color:#6e7681>
</span></span></span><span style=display:flex><span>}<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// JIT generates:</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// if (obj.class="=" Dog.class) {  // Fast path: direct call</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>//     dog_bark(obj);</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// } else {</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>//     slow_path_instanceof(obj);  // Deoptimize if assumption broken</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// }</span><span style=color:#6e7681>
</span></span></span></code></pre></div><p>This &ldquo;speculative optimization&rdquo; bets on observed patterns, with fallback for uncommon cases.</p><h2 id="16-branch-prediction-in-different-domains">16. Branch Prediction in Different Domains</h2><h3 id="161-embedded-systems">16.1 Embedded Systems</h3><p>Resource-constrained embedded systems have simpler predictors:</p><ul><li>Cortex-M series: Static or simple bimodal</li><li>Smaller BTBs (32-128 entries)</li><li>Lower misprediction penalties (shorter pipelines)</li></ul><p>Embedded developers often:</p><ul><li>Avoid complex control flow</li><li>Use lookup tables instead of branches</li><li>Manually unroll critical loops</li></ul><h3 id="162-high-frequency-trading">16.2 High-Frequency Trading</h3><p>HFT systems are extremely latency-sensitive:</p><ul><li>Every nanosecond matters</li><li>Branch mispredictions are critical path</li><li>Custom hardware (FPGAs) avoids branches entirely</li></ul><p>HFT optimizations:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-cpp" data-lang=cpp><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Branchless comparison
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>int</span> cmp <span style=color:#ff7b72;font-weight:700>=</span> (a <span style=color:#ff7b72;font-weight:700>&gt;</span> b) <span style=color:#ff7b72;font-weight:700>-</span> (a <span style=color:#ff7b72;font-weight:700>&lt;</span> b);  <span style=color:#8b949e;font-style:italic>// Returns -1, 0, or 1
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Branchless min/max
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>int</span> min <span style=color:#ff7b72;font-weight:700>=</span> b <span style=color:#ff7b72;font-weight:700>+</span> ((a <span style=color:#ff7b72;font-weight:700>-</span> b) <span style=color:#ff7b72;font-weight:700>&amp;</span> ((a <span style=color:#ff7b72;font-weight:700>-</span> b) <span style=color:#ff7b72;font-weight:700>&gt;&gt;</span> <span style=color:#a5d6ff>31</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Pre-computed decision tables
</span></span></span><span style=display:flex><span>action <span style=color:#ff7b72;font-weight:700>=</span> decision_table[state][event];
</span></span></code></pre></div><h3 id="163-scientific-computing">16.3 Scientific Computing</h3><p>Scientific code is often predictable (regular loops over arrays):</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-fortran" data-lang=fortran><span style=display:flex><span><span style=color:#8b949e;font-style:italic>! Matrix multiplication - highly predictable
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>do</span><span style=color:#6e7681> </span>i<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span><span style=color:#a5d6ff>1</span>,<span style=color:#6e7681> </span>n<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>    </span><span style=color:#ff7b72>do</span><span style=color:#6e7681> </span>j<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span><span style=color:#a5d6ff>1</span>,<span style=color:#6e7681> </span>n<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>        </span><span style=color:#ff7b72>do</span><span style=color:#6e7681> </span>k<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span><span style=color:#a5d6ff>1</span>,<span style=color:#6e7681> </span>n<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>            </span>C(i,j)<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>=</span><span style=color:#6e7681> </span>C(i,j)<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>+</span><span style=color:#6e7681> </span>A(i,k)<span style=color:#6e7681> </span><span style=color:#ff7b72;font-weight:700>*</span><span style=color:#6e7681> </span>B(k,j)<span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>        </span><span style=color:#ff7b72>end</span><span style=color:#6e7681> </span><span style=color:#ff7b72>do</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#6e7681>    </span><span style=color:#ff7b72>end</span><span style=color:#6e7681> </span><span style=color:#ff7b72>do</span><span style=color:#6e7681>
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>end</span><span style=color:#6e7681> </span><span style=color:#ff7b72>do</span><span style=color:#6e7681>
</span></span></span></code></pre></div><p>But irregular data structures cause problems:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// Sparse matrix - unpredictable access patterns
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>for</span> (<span style=color:#ff7b72>int</span> i <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; i <span style=color:#ff7b72;font-weight:700>&lt;</span> nnz; i<span style=color:#ff7b72;font-weight:700>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>if</span> (col[i] <span style=color:#ff7b72;font-weight:700>==</span> target_col) {  <span style=color:#8b949e;font-style:italic>// Unpredictable!
</span></span></span><span style=display:flex><span>        sum <span style=color:#ff7b72;font-weight:700>+=</span> val[i];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Scientific libraries optimize sparse operations carefully.</p><h3 id="164-cryptographic-code">16.4 Cryptographic Code</h3><p>Cryptography requires constant-time execution to prevent timing attacks:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// WRONG: Timing depends on secret key bits
</span></span></span><span style=display:flex><span><span style=color:#ff7b72>if</span> (secret_key[i]) {
</span></span><span style=display:flex><span>    result <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>operation_a</span>();
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8b949e;font-style:italic>// RIGHT: Always execute both, select result
</span></span></span><span style=display:flex><span>result_a <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>operation_a</span>();
</span></span><span style=display:flex><span>result_b <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#d2a8ff;font-weight:700>operation_b</span>();
</span></span><span style=display:flex><span>mask <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#ff7b72;font-weight:700>-</span>(secret_key[i] <span style=color:#ff7b72;font-weight:700>&amp;</span> <span style=color:#a5d6ff>1</span>);  <span style=color:#8b949e;font-style:italic>// All 1s or all 0s
</span></span></span><span style=display:flex><span>result <span style=color:#ff7b72;font-weight:700>=</span> (result_a <span style=color:#ff7b72;font-weight:700>&amp;</span> mask) <span style=color:#ff7b72;font-weight:700>|</span> (result_b <span style=color:#ff7b72;font-weight:700>&amp;</span> <span style=color:#ff7b72;font-weight:700>~</span>mask);
</span></span></code></pre></div><p>Constant-time code deliberately avoids prediction-dependent timing.</p><h2 id="17-future-directions">17. Future Directions</h2><h3 id="171-learned-predictors">17.1 Learned Predictors</h3><p>Machine learning for prediction shows promise:</p><ul><li>Neural network-based BTB indexing</li><li>Reinforcement learning for table management</li><li>Transfer learning from similar workloads</li></ul><p>Challenges:</p><ul><li>Inference latency (must be &lt; 1 cycle)</li><li>Training complexity</li><li>Generalization to new workloads</li></ul><h3 id="172-software-hardware-co-design">17.2 Software-Hardware Co-design</h3><p>Better compiler-hardware communication:</p><ul><li>Richer branch hints from compilers</li><li>Hardware profiling feedback to compilers</li><li>Adaptive optimization based on runtime behavior</li></ul><h3 id="173-security-first-predictors">17.3 Security-First Predictors</h3><p>Post-Spectre designs prioritize security:</p><ul><li>Isolated prediction domains per security context</li><li>Speculative execution firewalls</li><li>Prediction state clearing on context switches</li></ul><h3 id="174-heterogeneous-prediction">17.4 Heterogeneous Prediction</h3><p>Different predictors for different branch types:</p><ul><li>Simple predictor for loop branches</li><li>Neural predictor for data-dependent branches</li><li>Table-based for indirect branches</li></ul><p>Dynamic selection based on branch characteristics.</p><h2 id="18-summary">18. Summary</h2><p>Branch prediction is a cornerstone of modern CPU performance:</p><ul><li><strong>Deep pipelines</strong> require prediction to avoid stalls</li><li><strong>Dynamic predictors</strong> learn from runtime behavior</li><li><strong>Modern designs</strong> (TAGE, perceptron) achieve ~97% accuracy</li><li><strong>Speculation</strong> enables out-of-order execution but creates security risks</li><li><strong>Code patterns</strong> dramatically affect prediction accuracy</li></ul><p>Key takeaways for developers:</p><ol><li><strong>Predictable branches are nearly free</strong> (~0 cycles overhead)</li><li><strong>Unpredictable branches are expensive</strong> (10-25 cycles penalty)</li><li><strong>Sorting data</strong> can dramatically improve prediction</li><li><strong>Branchless code</strong> is only faster for unpredictable branches</li><li><strong>Profile your code</strong> to find branch hotspots</li><li><strong>Understand the architecture</strong> to write efficient code</li></ol><p>The branch predictor is the CPU&rsquo;s crystal ball, making educated guesses millions of times per second. Understanding how it works transforms how you think about the true cost of a simple if statement.</p><p>Every branch in your code is a bet. The CPU is gambling on the future, billions of times per second. Understanding these bets helps you write code that wins more often.</p></div><footer class="ce1a612 c6dfb1e c3ecea6"><div class="c364589">Categories:
<a href=/categories/systems/>systems</a>, <a href=/categories/performance/>performance</a></div><div>Tags:
<a href=/tags/cpu/>#cpu</a>, <a href=/tags/branch-prediction/>#branch-prediction</a>, <a href=/tags/performance/>#performance</a>, <a href=/tags/speculative-execution/>#speculative-execution</a>, <a href=/tags/microarchitecture/>#microarchitecture</a>, <a href=/tags/optimization/>#optimization</a>, <a href=/tags/spectre/>#spectre</a></div></footer></article></main><footer class="ccdf0e8" role=contentinfo aria-label=Footer><div class="cfdda01 c133889 c5df473 c0eecc8 c69618a c6942b3 c03620d c2a9f27 c7c11d8 c82c52d c14527b"><div class="c6dfb1e c3ecea6 c39ef11 c88ae6f">&copy; 2026 Leonardo Benicio. All rights
reserved.</div><div class="c6942b3 c7c11d8 cd1fd22"><a href=https://github.com/lbenicio target=_blank rel="noopener noreferrer" aria-label=GitHub class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.5-.67 1.08-.82 1.7s-.2 1.27-.18 1.9V22"/></svg>
<span class="cba5854">GitHub</span>
</a><a href=https://www.linkedin.com/in/leonardo-benicio target=_blank rel="noopener noreferrer" aria-label=LinkedIn class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452H17.21V14.86c0-1.333-.027-3.046-1.858-3.046-1.86.0-2.145 1.45-2.145 2.948v5.69H9.069V9h3.112v1.561h.044c.434-.82 1.494-1.686 3.074-1.686 3.29.0 3.897 2.165 3.897 4.983v6.594zM5.337 7.433a1.805 1.805.0 11-.002-3.61 1.805 1.805.0 01.002 3.61zM6.763 20.452H3.911V9h2.852v11.452z"/></svg>
<span class="cba5854">LinkedIn</span>
</a><a href=https://twitter.com/lbenicio_ target=_blank rel="noopener noreferrer" aria-label=Twitter class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M19.633 7.997c.013.177.013.354.013.53.0 5.386-4.099 11.599-11.6 11.599-2.31.0-4.457-.676-6.265-1.842.324.038.636.05.972.05 1.91.0 3.67-.65 5.07-1.755a4.099 4.099.0 01-3.827-2.84c.25.039.5.064.763.064.363.0.726-.051 1.065-.139A4.091 4.091.0 012.542 9.649v-.051c.538.3 1.162.482 1.824.507A4.082 4.082.0 012.54 6.7c0-.751.2-1.435.551-2.034a11.63 11.63.0 008.44 4.281 4.615 4.615.0 01-.101-.938 4.091 4.091.0 017.078-2.799 8.1 8.1.0 002.595-.988 4.112 4.112.0 01-1.8 2.261 8.2 8.2.0 002.357-.638A8.824 8.824.0 0119.613 7.96z"/></svg>
<span class="cba5854">Twitter</span></a></div></div></footer></body></html>