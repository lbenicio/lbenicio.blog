<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no"><title>Tuning CUDA with the GPU Memory Hierarchy · Leonardo Benicio</title><meta name=description content="Global, shared, and register memory each have distinct latency and bandwidth. Performance comes from the right access pattern."><link rel=alternate type=application/rss+xml title=RSS href=https://lbenicio.dev/index.xml><link rel=canonical href=https://blog.lbenicio.dev/blog/tuning-cuda-with-the-gpu-memory-hierarchy/><link rel=preload href=/static/fonts/OpenSans-Regular.ttf as=font type=font/ttf crossorigin><link rel="stylesheet" href="/assets/css/fonts.min.40e2054b739ac45a0f9c940f4b44ec00c3b372356ebf61440a413c0337c5512e.css" crossorigin="anonymous" integrity="sha256-QOIFS3OaxFoPnJQPS0TsAMOzcjVuv2FECkE8AzfFUS4="><link rel="shortcut icon" href=/static/assets/favicon/favicon.ico><link rel=icon type=image/x-icon href=/static/assets/favicon/favicon.ico><link rel=icon href=/static/assets/favicon/favicon.svg type=image/svg+xml><link rel=icon href=/static/assets/favicon/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=/static/assets/favicon/favicon-16x16.png sizes=16x16 type=image/png><link rel=apple-touch-icon href=/static/assets/favicon/apple-touch-icon.png><link rel=manifest href=/static/assets/favicon/site.webmanifest><link rel=mask-icon href=/static/assets/favicon/safari-pinned-tab.svg color=#209cee><meta name=msapplication-TileColor content="#209cee"><meta name=msapplication-config content="/static/assets/favicon/browserconfig.xml"><meta name=theme-color content="#d2e9f8"><meta property="og:title" content="Tuning CUDA with the GPU Memory Hierarchy · Leonardo Benicio"><meta property="og:description" content="Global, shared, and register memory each have distinct latency and bandwidth. Performance comes from the right access pattern."><meta property="og:url" content="https://blog.lbenicio.dev/blog/tuning-cuda-with-the-gpu-memory-hierarchy/"><meta property="og:type" content="article"><meta property="og:image" content="https://blog.lbenicio.dev/static/assets/images/blog/cuda-memory.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Tuning CUDA with the GPU Memory Hierarchy · Leonardo Benicio"><meta name=twitter:description content="Global, shared, and register memory each have distinct latency and bandwidth. Performance comes from the right access pattern."><meta name=twitter:site content="@lbenicio_"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","name":"About Leonardo Benicio","url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Person","name":"Leonardo Benicio","sameAs":["https://github.com/lbenicio","https://www.linkedin.com/in/leonardo-benicio","https://twitter.com/lbenicio_"],"url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Home","position":1},{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Blog","position":2},{"@type":"ListItem","item":"https://blog.lbenicio.dev/blog/tuning-cuda-with-the-gpu-memory-hierarchy/","name":"Tuning Cuda With the Gpu Memory Hierarchy","position":3}]}</script><link rel="stylesheet" href="/assets/css/main.min.1e8a566ac8bc3f0664d0db4ec8a015b07421c33fa11d336a6b914522a9cabf30.css" crossorigin="anonymous" integrity="sha256-6lhUOpwCHMSMROmggsVSp3AHKud6gBrIFGTzl3GV4BY="></head><body class="c6942b3 c03620d cf3bd2e"><script>(function(){try{document.addEventListener("gesturestart",function(e){e.preventDefault()}),document.addEventListener("touchstart",function(e){e.touches&&e.touches.length>1&&e.preventDefault()},{passive:!1});var e=0;document.addEventListener("touchend",function(t){var n=Date.now();n-e<=300&&t.preventDefault(),e=n},{passive:!1})}catch{}})()</script><a href=#content class="cba5854 c21e770 caffa6e cc5f604 cf2c31d cdd44dd c10dda9 c43876e c787e9b cddc2d2 cf55a7b c6dfb1e c9391e2">Skip to content</a>
<script>(function(){try{const e=localStorage.getItem("theme");e==="dark"&&document.documentElement.classList.add("dark");const t=document.querySelector('button[aria-label="Toggle theme"]');t&&t.setAttribute("aria-pressed",String(e==="dark"))}catch{}})();function toggleTheme(e){const s=document.documentElement,t=s.classList.toggle("dark");try{localStorage.setItem("theme",t?"dark":"light")}catch{}try{var n=e&&e.nodeType===1?e:document.querySelector('button[aria-label="Toggle theme"]');n&&n.setAttribute("aria-pressed",String(!!t))}catch{}}(function(){function e(){try{return document.documentElement.classList.contains("dark")?"dark":"light"}catch{return"light"}}function n(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(0)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!1,s.style.display="block"}catch{}o.setAttribute("aria-expanded","true"),n.setAttribute("aria-hidden","false");try{document.body.classList.add("c150bbe")}catch{}const i=document.getElementById("i190984");i&&i.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_open",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function t(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(100%)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!0,s.style.display="none"}catch{}o.setAttribute("aria-expanded","false"),n.setAttribute("aria-hidden","true");try{document.body.classList.remove("c150bbe")}catch{}o.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_close",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function s(e){e.key==="Escape"&&t("escape")}window.__openMobileMenu=n,window.__closeMobileMenu=t;try{window.addEventListener("keydown",s,!0)}catch{}})()</script><header class="cd019ba c98dfae cdd44dd cfdda01 c9ee25d ce2dc7a cd72dd7 cc0dc37" role=banner><div class="cfdda01 c6942b3 ccf47f4 c7c11d8"><a href=/ class="c87e2b0 c6942b3 c7c11d8 c1838fa cb594e4" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=32 height=32 class="c3de71a c4d5191">
<span class="cf8f011 c4d1253 cbd72bc cd7e69e">Leonardo Benicio</span></a><div class="c6942b3 c85cbd4 c7c11d8 ca798da c1838fa c7a0580"><nav class="cc1689c cd9b445 c75065d c04bab1" aria-label=Main><a href=/ class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Home</a>
<a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">About</a>
<a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Timeline</a>
<a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Reading</a>
<a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Publications</a>
<a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Contact</a></nav><button id="i1d73d4" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 c097fa1 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" onclick=toggleTheme(this) aria-label="Toggle theme" aria-pressed=false title="Toggle theme">
<svg class="cb26e41 c50ceea cb69a5c c4f45c8 c8c2c40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="cb26e41 c8fca2b cb69a5c c4f45c8 cc1689c c9c27ff" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><circle cx="12" cy="12" r="4"/><path d="M12 2v4"/><path d="M12 18v4"/><path d="M2 12h4"/><path d="M18 12h4"/><path d="M4.93 4.93l2.83 2.83"/><path d="M16.24 16.24l2.83 2.83"/><path d="M6.34 17.66l2.83-2.83"/><path d="M14.83 9.17l2.83-2.83"/></svg>
<span class="cba5854">Toggle theme</span></button><div class="c658bcf c097fa1"><button id="i975fb5" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" aria-label="Open menu" aria-controls="i98aca2" aria-expanded=false onclick='window.__openMobileMenu("button")' data-d38f920=mobile_menu_open_click>
<svg class="c20e4eb cb58471" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
<span class="cba5854">Open menu</span></button></div></div></div></header><div id="iad2af0" class="caffa6e ce4b5f4 c14639a" style=background-color:hsl(var(--background)) hidden onclick='window.__closeMobileMenu("overlay")' data-d38f920=mobile_menu_overlay_click></div><aside id="i98aca2" class="caffa6e c9efbc5 c437fa9 c49e97e c6c6936 c7cacca c7b34a4 c787e9b c88daee cad071a c6942b3 c03620d" role=dialog aria-modal=true aria-hidden=true aria-label="Mobile navigation" style="transform:translateX(100%);transition:transform 200ms ease-out;will-change:transform"><div class="c6942b3 c7c11d8 c82c52d c5df473 ccf47f4 c9ee25d"><a href=/ class="c6942b3 c7c11d8 c1838fa" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=24 height=24 class="c20e4eb cb58471">
<span class="c62aaf0 c7c1b66 cbd72bc">Leonardo Benicio</span>
</a><button id="i190984" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c514027 c286dd7 c2bd687 cfdce1d" aria-label="Close menu" onclick='window.__closeMobileMenu("button")' data-d38f920=mobile_menu_close_click>
<svg class="c16e528 c61f467" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 6 6 18"/><path d="m6 6 12 12"/></svg>
<span class="cba5854">Close</span></button></div><nav class="c85cbd4 ca0eaa4 c5df473 c6689b9"><ul class="cd69733"><li><a href=/ class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Home</a></li><li><a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>About</a></li><li><a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Timeline</a></li><li><a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Reading</a></li><li><a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Publications</a></li><li><a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Contact</a></li></ul></nav><div class="c60a4cc ccdf0e8 c277478 c13044e"><p>&copy; 2026 Leonardo Benicio</p></div></aside><div class="caffa6e c437fa9 ce9aced c97bba6 c15da2a c975cba" role=complementary aria-label="GitHub repository"><div class="c9d056d c252f85 ca22532 ca88a1a c876315"><div class="c6942b3 c7c11d8 c1d0018 cd1fd22 c6066e4 c43876e ce3d5b6 caa20d2 c3ecea6 c0cd2e2 cddc2d2 c3ed5c9 cd4074c c876315"><a href=https://github.com/lbenicio/aboutme target=_blank rel="noopener noreferrer" class="c6942b3 c7c11d8 cd1fd22 c71bae8 cfac1ac c19ee42 c25dc7c cb40739 cbbda39 cf55a7b" aria-label="View source on GitHub"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="cb26e41 c41bcd4 cf17690 cfa4e34 c78d562" aria-hidden="true"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></svg>
<span class="cb5c327 cd7e69e">Fork me</span></a></div></div></div><main id="i7eccc0" class="cfdda01 c5df473 c0eecc8 c85cbd4" role=main aria-label=Content><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Tuning Cuda With the Gpu Memory Hierarchy</span></li></ol></nav><article class="c461ba0 c1c203f cfb6084 c995404 c6ca165"><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Tuning Cuda With the Gpu Memory Hierarchy</span></li></ol></nav><header class="c8aedc7"><h1 class="cf304bc c6fb0fe cf8f011 cc484e1">Tuning CUDA with the GPU Memory Hierarchy</h1><div class="c277478 c3ecea6 c8fb24a">2024-11-27
· Leonardo Benicio</div><div class="c1a1a3f c8124f2"><img src=/static/assets/images/blog/cuda-memory.png alt class="cfdda01 c524300 c677556"></div><p class="lead c3ecea6">Global, shared, and register memory each have distinct latency and bandwidth. Performance comes from the right access pattern.</p></header><div class="content"><p>CUDA performance hinges on moving data efficiently through a <em>hierarchy</em> of memories that differ by latency, bandwidth, scope (visibility), and capacity. Raw FLOP throughput is rarely the first limiter—memory behavior, access ordering, and reuse patterns almost always dominate performance envelopes.</p><hr><h2 id="1-the-hierarchy-at-a-glance">1. The Hierarchy at a Glance</h2><table><thead><tr><th>Level</th><th>Scope / Visibility</th><th>Approx Latency (cycles)*</th><th>Bandwidth</th><th>Capacity (per SM / device)</th><th>Notes</th></tr></thead><tbody><tr><td>Registers</td><td>Thread private</td><td>~1</td><td>Extreme</td><td>Tens of k per SM (allocated per thread)</td><td>Allocation affects occupancy; spilling -> local memory</td></tr><tr><td>Shared Memory (SMEM)</td><td>Block (CTA)</td><td>~20–35</td><td>Very high</td><td>48–228 KB configurable (arch dependent)</td><td>Banked; subject to conflicts; optional split w/ L1</td></tr><tr><td>L1 / Texture Cache</td><td>SM</td><td>~30–60</td><td>High</td><td>~128–256 KB (unified)</td><td>Serves global loads; spatial locality & coalescing still matter</td></tr><tr><td>L2 Cache</td><td>Device-wide</td><td>~200–300</td><td>High</td><td>Multi-MB</td><td>Coherent across SMs; crucial for global data reuse</td></tr><tr><td>Global DRAM</td><td>Device-wide</td><td>~400–800</td><td>High (GB/s)</td><td>Many GB</td><td>Long latency—hide with parallelism & coalescing</td></tr><tr><td>Constant Cache</td><td>Device-wide (read-only)</td><td>~ L1 hit if cached</td><td>High (broadcast)</td><td>64 KB</td><td>Broadcast to warp if all threads read same address</td></tr><tr><td>Texture / Read-Only Cache</td><td>Device-wide (cached)</td><td>Similar to L1</td><td>High</td><td>N/A</td><td>Provides specialized spatial filtering & relaxed coalescing</td></tr><tr><td>Local Memory</td><td>Thread (spill/backing)</td><td>DRAM latency</td><td>DRAM</td><td>Per-thread virtual</td><td>“Local” is misnomer if spilled—same as global latency</td></tr></tbody></table><p><em>Indicative ranges; varies by architecture generation (e.g., Turing, Ampere, Hopper). Absolute numbers less important than ratio gaps.</em></p><h3 id="key-principles">Key Principles</h3><ol><li><strong>Reuse closest to compute</strong>: Promote frequently reused data upward (registers > shared > L1 > L2 > DRAM).</li><li><strong>Minimize divergence in memory patterns</strong>: Divergent addresses within a warp break coalescing and add transactions.</li><li><strong>Overlap where possible</strong>: Use asynchronous copies & double buffering to hide DRAM latency behind computation.</li><li><strong>Balance occupancy vs. registers/shared memory usage</strong>: More threads help hide latency until diminishing returns; sometimes <em>fewer</em> threads with better cache/block reuse win.</li></ol><hr><h2 id="2-global-memory-access--coalescing">2. Global Memory Access & Coalescing</h2><p>Warps issue memory instructions collectively. A <em>coalesced</em> load/store ideally maps contiguous 32/64/128-byte segments to the DRAM interface with minimal memory transactions. Poor alignment or strided patterns cause partial transactions and wasted bandwidth.</p><h3 id="alignment--layout">Alignment & Layout</h3><p>Assume a structure:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> Bad { <span style=color:#ff7b72>float</span> x; <span style=color:#ff7b72>int</span> flag; <span style=color:#ff7b72>float</span> y; };
</span></span></code></pre></div><p>Interleaving types can force awkward alignment. A SoA (structure-of-arrays) layout improves contiguous float loads:</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-c" data-lang=c><span style=display:flex><span><span style=color:#ff7b72>struct</span> Good { <span style=color:#ff7b72>float</span><span style=color:#ff7b72;font-weight:700>*</span> __restrict__ x; <span style=color:#ff7b72>float</span><span style=color:#ff7b72;font-weight:700>*</span> __restrict__ y; <span style=color:#ff7b72>int</span><span style=color:#ff7b72;font-weight:700>*</span> __restrict__ flag; };
</span></span></code></pre></div><p>Hybrid: keep hot fields together if always accessed together; otherwise separate.</p><h3 id="stride-pitfall">Stride Pitfall</h3><p>If thread <code>t</code> accesses <code>A[base + t * stride]</code> with <code>stride > 1</code>, each warp touches scattered cache lines. Remediation:</p><ul><li>Tile & transpose into shared memory.</li><li>Use vectorized loads (<code>float4</code>) when alignment permits.</li><li>Reorder loops so <code>t</code> iterates over the innermost contiguous dimension.</li></ul><hr><h2 id="3-shared-memory-smem-deep-dive">3. Shared Memory (SMEM) Deep Dive</h2><p>Shared memory provides a manually managed, programmer-controlled cache. Wins arise from <em>temporal reuse</em> and <em>avoiding redundant DRAM fetches</em>.</p><h3 id="bank-conflicts">Bank Conflicts</h3><p>SMEM is organized into banks (commonly 32). Concurrent accesses by a warp to different addresses in the same bank serialize (except broadcast cases). To avoid conflicts:</p><ol><li>Pad leading dimension: e.g., declare <code>float tile[BLOCK_Y][BLOCK_X+1];</code>.</li><li>Use swizzled indexing (XOR transpose patterns) for complex transforms.</li><li>For matrix multiply tiles (MxK * KxN), pad K dimension if K%32==0 and access pattern causes bank modulo collisions.</li></ol><h3 id="double-buffering">Double Buffering</h3><p>Load tile (stage k), compute on tile (stage k-1). Pattern:</p><ol><li>Asynchronous copy next tile to SMEM (cp.async on newer architectures).</li><li><code>__syncthreads()</code> only when needed (barrier cost ~80–100 cycles but hidden if overlapped).</li><li>Pipeline ensures arithmetic never waits on DRAM after warmup.</li></ol><h3 id="example-2d-convolution-tile-skeleton">Example: 2D Convolution Tile Skeleton</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-gdscript3" data-lang=gdscript3><span style=display:flex><span>template<span style=color:#ff7b72;font-weight:700>&lt;</span><span style=color:#f0883e;font-weight:700>int</span> BLOCK, <span style=color:#f0883e;font-weight:700>int</span> K<span style=color:#ff7b72;font-weight:700>&gt;</span>
</span></span><span style=display:flex><span>__global__ void conv2d(<span style=color:#ff7b72>const</span> <span style=color:#f0883e;font-weight:700>float</span><span style=color:#ff7b72;font-weight:700>*</span> __restrict__ <span style=color:#ff7b72;font-weight:700>in</span>,
</span></span><span style=display:flex><span>                       <span style=color:#ff7b72>const</span> <span style=color:#f0883e;font-weight:700>float</span><span style=color:#ff7b72;font-weight:700>*</span> __restrict__ kernel,
</span></span><span style=display:flex><span>                       <span style=color:#f0883e;font-weight:700>float</span><span style=color:#ff7b72;font-weight:700>*</span> __restrict__ out,
</span></span><span style=display:flex><span>                       <span style=color:#f0883e;font-weight:700>int</span> W, <span style=color:#f0883e;font-weight:700>int</span> H) {
</span></span><span style=display:flex><span>  __shared__ <span style=color:#f0883e;font-weight:700>float</span> tile[BLOCK <span style=color:#ff7b72;font-weight:700>+</span> K <span style=color:#ff7b72;font-weight:700>-</span> <span style=color:#a5d6ff>1</span>][BLOCK <span style=color:#ff7b72;font-weight:700>+</span> K <span style=color:#ff7b72;font-weight:700>-</span> <span style=color:#a5d6ff>1</span>];
</span></span><span style=display:flex><span>  <span style=color:#f0883e;font-weight:700>int</span> tx <span style=color:#ff7b72;font-weight:700>=</span> threadIdx<span style=color:#ff7b72;font-weight:700>.</span>x, ty <span style=color:#ff7b72;font-weight:700>=</span> threadIdx<span style=color:#ff7b72;font-weight:700>.</span>y;
</span></span><span style=display:flex><span>  <span style=color:#f0883e;font-weight:700>int</span> ox <span style=color:#ff7b72;font-weight:700>=</span> blockIdx<span style=color:#ff7b72;font-weight:700>.</span>x <span style=color:#ff7b72;font-weight:700>*</span> BLOCK <span style=color:#ff7b72;font-weight:700>+</span> tx;
</span></span><span style=display:flex><span>  <span style=color:#f0883e;font-weight:700>int</span> oy <span style=color:#ff7b72;font-weight:700>=</span> blockIdx<span style=color:#ff7b72;font-weight:700>.</span>y <span style=color:#ff7b72;font-weight:700>*</span> BLOCK <span style=color:#ff7b72;font-weight:700>+</span> ty;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#ff7b72;font-weight:700>//</span> Load with halo (guard): coalesced rows
</span></span><span style=display:flex><span>  <span style=color:#ff7b72>for</span> (<span style=color:#f0883e;font-weight:700>int</span> dy <span style=color:#ff7b72;font-weight:700>=</span> ty; dy <span style=color:#ff7b72;font-weight:700>&lt;</span> BLOCK <span style=color:#ff7b72;font-weight:700>+</span> K <span style=color:#ff7b72;font-weight:700>-</span> <span style=color:#a5d6ff>1</span>; dy <span style=color:#ff7b72;font-weight:700>+=</span> blockDim<span style=color:#ff7b72;font-weight:700>.</span>y) {
</span></span><span style=display:flex><span>    <span style=color:#f0883e;font-weight:700>int</span> iy <span style=color:#ff7b72;font-weight:700>=</span> blockIdx<span style=color:#ff7b72;font-weight:700>.</span>y <span style=color:#ff7b72;font-weight:700>*</span> BLOCK <span style=color:#ff7b72;font-weight:700>+</span> dy;
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>for</span> (<span style=color:#f0883e;font-weight:700>int</span> dx <span style=color:#ff7b72;font-weight:700>=</span> tx; dx <span style=color:#ff7b72;font-weight:700>&lt;</span> BLOCK <span style=color:#ff7b72;font-weight:700>+</span> K <span style=color:#ff7b72;font-weight:700>-</span> <span style=color:#a5d6ff>1</span>; dx <span style=color:#ff7b72;font-weight:700>+=</span> blockDim<span style=color:#ff7b72;font-weight:700>.</span>x) {
</span></span><span style=display:flex><span>      <span style=color:#f0883e;font-weight:700>int</span> ix <span style=color:#ff7b72;font-weight:700>=</span> blockIdx<span style=color:#ff7b72;font-weight:700>.</span>x <span style=color:#ff7b72;font-weight:700>*</span> BLOCK <span style=color:#ff7b72;font-weight:700>+</span> dx;
</span></span><span style=display:flex><span>      tile[dy][dx] <span style=color:#ff7b72;font-weight:700>=</span> (ix <span style=color:#ff7b72;font-weight:700>&lt;</span> W <span style=color:#ff7b72;font-weight:700>&amp;&amp;</span> iy <span style=color:#ff7b72;font-weight:700>&lt;</span> H) <span style=color:#f85149>?</span> <span style=color:#ff7b72;font-weight:700>in</span>[iy <span style=color:#ff7b72;font-weight:700>*</span> W <span style=color:#ff7b72;font-weight:700>+</span> ix] : <span style=color:#a5d6ff>0.</span>f;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  __syncthreads();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#ff7b72>if</span> (ox <span style=color:#ff7b72;font-weight:700>&lt;</span> W <span style=color:#ff7b72;font-weight:700>&amp;&amp;</span> oy <span style=color:#ff7b72;font-weight:700>&lt;</span> H) {
</span></span><span style=display:flex><span>    <span style=color:#f0883e;font-weight:700>float</span> acc <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0.</span>f;
</span></span><span style=display:flex><span>    <span style=color:#8b949e;font-style:italic>#pragma unroll</span>
</span></span><span style=display:flex><span>    <span style=color:#ff7b72>for</span> (<span style=color:#f0883e;font-weight:700>int</span> ky <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; ky <span style=color:#ff7b72;font-weight:700>&lt;</span> K; <span style=color:#ff7b72;font-weight:700>++</span>ky)
</span></span><span style=display:flex><span>      <span style=color:#8b949e;font-style:italic>#pragma unroll</span>
</span></span><span style=display:flex><span>      <span style=color:#ff7b72>for</span> (<span style=color:#f0883e;font-weight:700>int</span> kx <span style=color:#ff7b72;font-weight:700>=</span> <span style=color:#a5d6ff>0</span>; kx <span style=color:#ff7b72;font-weight:700>&lt;</span> K; <span style=color:#ff7b72;font-weight:700>++</span>kx)
</span></span><span style=display:flex><span>        acc <span style=color:#ff7b72;font-weight:700>+=</span> tile[ty <span style=color:#ff7b72;font-weight:700>+</span> ky][tx <span style=color:#ff7b72;font-weight:700>+</span> kx] <span style=color:#ff7b72;font-weight:700>*</span> kernel[ky <span style=color:#ff7b72;font-weight:700>*</span> K <span style=color:#ff7b72;font-weight:700>+</span> kx];
</span></span><span style=display:flex><span>    out[oy <span style=color:#ff7b72;font-weight:700>*</span> W <span style=color:#ff7b72;font-weight:700>+</span> ox] <span style=color:#ff7b72;font-weight:700>=</span> acc;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Optimizations left: vectorized loads (float4), using cp.async to stage tiles, and fusing activation functions.</p><hr><h2 id="4-registers-spilling--occupancy">4. Registers, Spilling & Occupancy</h2><p>Each thread receives a register allocation at compile time. If requested registers exceed hardware limit per SM (divided among active warps), compiler spills to <em>local memory</em>—which lives in DRAM with L1/L2 caching. Spills turn a compute-bound loop into a bandwidth-bound workload.</p><h3 id="trade-off-model">Trade-Off Model</h3><p>Let:</p><ul><li>R_per_thread = allocated registers.</li><li>R_total_per_SM = physical registers/SM.</li><li>Threads<em>per_block _Blocks_per_SM</em> R_per_thread ≤ R_total_per_SM.</li></ul><p>Raising R_per_thread can improve ILP (fewer re-computations, unrolled loops) but can reduce concurrent warps (occupancy). Empirical approach:</p><ol><li>Compile with different <code>-maxrregcount</code> values.</li><li>Profile achieved occupancy vs. executed instructions per cycle (IPC).</li><li>Pick point where further occupancy doesn’t reduce <em>stall reasons: memory dependency / execution dependency</em>.</li></ol><hr><h2 id="5-l1-l2-and-cache-behavior">5. L1, L2, and Cache Behavior</h2><p>Modern GPUs unify user-configurable shared memory & L1 capacity. Choosing a larger SMEM carve-out may shrink L1, affecting global load hit rate. Balance:</p><ol><li>If your kernel has high explicit tile reuse, favor larger SMEM.</li><li>If access pattern exhibits streaming with little temporal reuse but regular spatial locality, allow a larger L1.</li></ol><p>L2 acts as a global victim cache: multi-kernel pipelines can benefit from reusing results if intermediate data fits. Consider kernel fusion to keep data in registers/SMEM instead of writing & rereading through L2/DRAM.</p><hr><h2 id="6-read-only-constant--texture-paths">6. Read-Only, Constant & Texture Paths</h2><p>Marking pointers with <code>const __restrict__</code> enables read-only cache usage (on older arch via <code>ld.global.nc</code> / <code>ldg</code>). Constant memory excels when a warp broadcasts the <em>same</em> value; random indices kill benefit. Texture caches add hardware filtering & address normalization for 2D spatial access, often improving locality for irregular stencils.</p><hr><h2 id="7-asynchronous-data-movement--latency-hiding">7. Asynchronous Data Movement & Latency Hiding</h2><p>Architectures >= Ampere allow <code>cp.async</code> to stream data from global to shared memory into <em>stages</em> without stalling the warp. Pattern:</p><ol><li>Issue N async copies (filling a stage buffer).</li><li>Commit & wait groups while computing on prior stage.</li><li>Overlap memory fetch for tile k+1 with arithmetic on tile k.</li></ol><p>Add double or triple buffering to cover memory latency plus potential L2 queuing. Nsight Systems timeline helps verify overlap (look for interleaved memcpy/compute ranges).</p><hr><h2 id="8-roofline-perspective">8. Roofline Perspective</h2><p>Compute performance is bounded by either peak FLOP/s or memory bandwidth times operational intensity (OI = FLOPs / bytes). For a kernel:</p><ol><li>Count FLOPs (static or via instruction profiling).</li><li>Measure bytes transferred (global loads/stores * transaction width, plus replays).</li><li>OI = FLOPs / bytes. If OI &lt; (Peak FLOP/s / Peak Bandwidth), you are bandwidth-bound; optimize memory first.</li></ol><p>Raising OI strategies:</p><ul><li>Increase arithmetic reuse per fetched byte (blocking, fused operations).</li><li>Convert data types (FP32 → FP16/BF16) when precision permits to double effective bandwidth.</li><li>Use tensor cores (matrix-multiply-accumulate instructions) for dense GEMM-like subproblems.</li></ul><hr><h2 id="9-warp-specialization--cooperative-groups">9. Warp Specialization & Cooperative Groups</h2><p>Some kernels benefit from dedicating a subset of warps in a block to “producer” roles (prefetch, reduction) while others “consume” (compute). Cooperative groups + warp-level primitives (<code>__shfl_sync</code>) enable low-latency intra-warp reductions, bypassing shared memory and reducing bank pressure.</p><h3 id="example-warp-reduction">Example: Warp Reduction</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-fallback" data-lang=fallback><span style=display:flex><span>__inline__ __device__ float warp_sum(float v) {
</span></span><span style=display:flex><span>  for (int offset = 16; offset &gt; 0; offset &gt;&gt;= 1)
</span></span><span style=display:flex><span>    v += __shfl_down_sync(0xffffffff, v, offset);
</span></span><span style=display:flex><span>  return v;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Use after each thread accumulates partial sums; only lane 0 writes to shared/global memory.</p><hr><h2 id="10-common-performance-pathologies">10. Common Performance Pathologies</h2><table><thead><tr><th>Symptom</th><th>Likely Cause</th><th>Diagnostic</th><th>Remedy</th></tr></thead><tbody><tr><td>High DRAM transactions, low FLOP util</td><td>Uncoalesced loads</td><td>Memory statistics (Nsight Compute)</td><td>Reorder data, vector loads, tiling</td></tr><tr><td>Many shared memory bank conflicts</td><td>Stride hitting same bank</td><td>SMEM bank conflict metric</td><td>Pad leading dimension</td></tr><tr><td>Low occupancy, many stall_memory_dependency</td><td>Register pressure or long DRAM latency</td><td>Achieved occupancy, stall reason breakdown</td><td>Reduce registers, add latency hiding ops</td></tr><tr><td>High local memory loads</td><td>Register spilling</td><td>SASS / metric for local loads</td><td>Reduce inlining, unroll selectively, use <code>-maxrregcount</code></td></tr><tr><td>Cache thrash</td><td>Working set > L1, poor locality</td><td>L1/TEX hit rate</td><td>Increase tile size, restructure loops</td></tr></tbody></table><hr><h2 id="11-benchmarking-methodology">11. Benchmarking Methodology</h2><ol><li>Warm-up runs (clock/power stable, JIT done).</li><li>Collect multiple samples (variance &lt;2%).</li><li>Reset GPU clocks (or lock with persistence mode) for reproducibility.</li><li>Use events (<code>cudaEventRecord</code>) for kernel timing; wall clock for end-to-end.</li><li>Record environment (driver version, GPU model, clock rates) in results.</li></ol><p>Track: achieved occupancy, DRAM throughput (GB/s), L2 hit rate, SM efficiency (% cycles issuing instructions), active warps per cycle, branch efficiency.</p><hr><h2 id="12-putting-it-together-mini-case-study">12. Putting It Together: Mini Case Study</h2><p>Goal: accelerate 2D stencil (7-point) on a modern GPU.</p><p>Baseline kernel: direct global loads, each output reads 7 elements ⇒ OI low. Profiling shows:</p><ul><li>DRAM throughput at 55% of theoretical.</li><li>L2 hit rate 45% (poor reuse).</li><li>Achieved occupancy 100% but stall_memory_dependency dominates.</li></ul><p>Optimizations:</p><ol><li><strong>Shared memory tile + halo</strong>: reduces redundant DRAM loads (~7→1.2 average loads per output). DRAM throughput drops (less data moved) while compute occupancy same; memory dependency stalls fall.</li><li><strong>Double buffering + cp.async</strong>: Overlaps global fetch for next tile; kernel time -18%.</li><li><strong>Register blocking</strong>: Each thread computes 2×2 outputs; adds ILP, moderate register increase but still acceptable occupancy; -12% time.</li><li><strong>Precision reduction (FP32→FP16 accumulate FP32)</strong>: If error tolerable, halves bytes; bandwidth headroom yields another -20% time.</li></ol><p>Result: 2.3× speedup overall, moving kernel closer to compute-bound; roofline placement shifts right (higher OI) then up (higher utilization).</p><hr><h2 id="13-checklist-before-shipping">13. Checklist Before Shipping</h2><ol><li>Are all major global memory streams coalesced? (Check sector requests vs. transactions.)</li><li>Are shared memory bank conflicts negligible (&lt; a few % of instructions)?</li><li>Any local memory (spill) loads left? If yes, justify.</li><li>Achieved occupancy above “latency hiding threshold” (often ~30–40% for mature kernels)?</li><li>Roofline: bound by memory or compute? Further work aligned accordingly.</li><li>Kernel launch params (block size, grid size) chosen via sweep—not guesswork.</li><li>Regression tests cover numerical correctness after precision or reordering changes.</li></ol><hr><h2 id="14-further-reading-titles">14. Further Reading (Titles)</h2><ul><li>&ldquo;Optimizing Parallel Reduction in CUDA&rdquo; (classic reduction patterns)</li><li>&ldquo;Efficient Shared Memory Usage in Stencil Computations&rdquo;</li><li>&ldquo;GPU Roofline Model: Application Characterization&rdquo;</li><li>&ldquo;Asynchronous Copy (cp.async) Best Practices&rdquo;</li><li>Vendor architecture whitepapers (memory subsystem sections)</li><li>Nsight Compute / Systems User Guides</li></ul><hr><h2 id="15-summary">15. Summary</h2><p>GPU performance is primarily a data movement orchestration problem. Exploit registers for immediacy, shared memory for cooperative reuse, caches for spatial locality, and asynchronous pipelines for overlap. Optimize <em>operational intensity</em> and <em>latency hiding mechanisms</em> before micro-tweaking instruction sequences. A disciplined measurement loop (profile → hypothesize → transform → re-profile) turns the memory hierarchy from an obstacle into an enabler of near-peak throughput.</p></div><footer class="ce1a612 c6dfb1e c3ecea6"><div class="c364589">Categories:
<a href=/categories/parallelism/>parallelism</a>, <a href=/categories/gpgpu/>gpgpu</a></div><div>Tags:
<a href=/tags/cuda/>#cuda</a>, <a href=/tags/gpu/>#gpu</a>, <a href=/tags/memory/>#memory</a>, <a href=/tags/performance/>#performance</a></div></footer></article></main><footer class="ccdf0e8" role=contentinfo aria-label=Footer><div class="cfdda01 c133889 c5df473 c0eecc8 c69618a c6942b3 c03620d c2a9f27 c7c11d8 c82c52d c14527b"><div class="c6dfb1e c3ecea6 c39ef11 c88ae6f">&copy; 2026 Leonardo Benicio. All rights
reserved.</div><div class="c6942b3 c7c11d8 cd1fd22"><a href=https://github.com/lbenicio target=_blank rel="noopener noreferrer" aria-label=GitHub class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.5-.67 1.08-.82 1.7s-.2 1.27-.18 1.9V22"/></svg>
<span class="cba5854">GitHub</span>
</a><a href=https://www.linkedin.com/in/leonardo-benicio target=_blank rel="noopener noreferrer" aria-label=LinkedIn class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452H17.21V14.86c0-1.333-.027-3.046-1.858-3.046-1.86.0-2.145 1.45-2.145 2.948v5.69H9.069V9h3.112v1.561h.044c.434-.82 1.494-1.686 3.074-1.686 3.29.0 3.897 2.165 3.897 4.983v6.594zM5.337 7.433a1.805 1.805.0 11-.002-3.61 1.805 1.805.0 01.002 3.61zM6.763 20.452H3.911V9h2.852v11.452z"/></svg>
<span class="cba5854">LinkedIn</span>
</a><a href=https://twitter.com/lbenicio_ target=_blank rel="noopener noreferrer" aria-label=Twitter class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M19.633 7.997c.013.177.013.354.013.53.0 5.386-4.099 11.599-11.6 11.599-2.31.0-4.457-.676-6.265-1.842.324.038.636.05.972.05 1.91.0 3.67-.65 5.07-1.755a4.099 4.099.0 01-3.827-2.84c.25.039.5.064.763.064.363.0.726-.051 1.065-.139A4.091 4.091.0 012.542 9.649v-.051c.538.3 1.162.482 1.824.507A4.082 4.082.0 012.54 6.7c0-.751.2-1.435.551-2.034a11.63 11.63.0 008.44 4.281 4.615 4.615.0 01-.101-.938 4.091 4.091.0 017.078-2.799 8.1 8.1.0 002.595-.988 4.112 4.112.0 01-1.8 2.261 8.2 8.2.0 002.357-.638A8.824 8.824.0 0119.613 7.96z"/></svg>
<span class="cba5854">Twitter</span></a></div></div></footer></body></html>