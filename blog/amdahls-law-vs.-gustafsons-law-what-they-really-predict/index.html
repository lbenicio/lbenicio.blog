<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no"><title>Amdahl’s Law vs. Gustafson’s Law: What They Really Predict · Leonardo Benicio</title><meta name=description content="When does parallelism pay off? Compare Amdahl’s and Gustafson’s models, see where each applies, and learn how to reason about speedups in practice."><link rel=alternate type=application/rss+xml title=RSS href=https://lbenicio.dev/index.xml><link rel=canonical href=https://blog.lbenicio.dev/blog/amdahls-law-vs.-gustafsons-law-what-they-really-predict/><link rel=preload href=/static/fonts/OpenSans-Regular.ttf as=font type=font/ttf crossorigin><link rel="stylesheet" href="/assets/css/fonts.min.40e2054b739ac45a0f9c940f4b44ec00c3b372356ebf61440a413c0337c5512e.css" crossorigin="anonymous" integrity="sha256-QOIFS3OaxFoPnJQPS0TsAMOzcjVuv2FECkE8AzfFUS4="><link rel="shortcut icon" href=/static/assets/favicon/favicon.ico><link rel=icon type=image/x-icon href=/static/assets/favicon/favicon.ico><link rel=icon href=/static/assets/favicon/favicon.svg type=image/svg+xml><link rel=icon href=/static/assets/favicon/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=/static/assets/favicon/favicon-16x16.png sizes=16x16 type=image/png><link rel=apple-touch-icon href=/static/assets/favicon/apple-touch-icon.png><link rel=manifest href=/static/assets/favicon/site.webmanifest><link rel=mask-icon href=/static/assets/favicon/safari-pinned-tab.svg color=#209cee><meta name=msapplication-TileColor content="#209cee"><meta name=msapplication-config content="/static/assets/favicon/browserconfig.xml"><meta name=theme-color content="#d2e9f8"><meta property="og:title" content="Amdahl’s Law vs. Gustafson’s Law: What They Really Predict · Leonardo Benicio"><meta property="og:description" content="When does parallelism pay off? Compare Amdahl’s and Gustafson’s models, see where each applies, and learn how to reason about speedups in practice."><meta property="og:url" content="https://blog.lbenicio.dev/blog/amdahls-law-vs.-gustafsons-law-what-they-really-predict/"><meta property="og:type" content="article"><meta property="og:image" content="https://blog.lbenicio.dev/static/assets/images/blog/parallel-speedup.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Amdahl’s Law vs. Gustafson’s Law: What They Really Predict · Leonardo Benicio"><meta name=twitter:description content="When does parallelism pay off? Compare Amdahl’s and Gustafson’s models, see where each applies, and learn how to reason about speedups in practice."><meta name=twitter:site content="@lbenicio_"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","name":"About Leonardo Benicio","url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Person","name":"Leonardo Benicio","sameAs":["https://github.com/lbenicio","https://www.linkedin.com/in/leonardo-benicio","https://twitter.com/lbenicio_"],"url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Home","position":1},{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Blog","position":2},{"@type":"ListItem","item":"https://blog.lbenicio.dev/blog/amdahls-law-vs.-gustafsons-law-what-they-really-predict/","name":"Amdahls Law vs. Gustafsons Law What They Really Predict","position":3}]}</script><link rel="stylesheet" href="/assets/css/main.min.1e8a566ac8bc3f0664d0db4ec8a015b07421c33fa11d336a6b914522a9cabf30.css" crossorigin="anonymous" integrity="sha256-6lhUOpwCHMSMROmggsVSp3AHKud6gBrIFGTzl3GV4BY="></head><body class="c6942b3 c03620d cf3bd2e"><script>(function(){try{document.addEventListener("gesturestart",function(e){e.preventDefault()}),document.addEventListener("touchstart",function(e){e.touches&&e.touches.length>1&&e.preventDefault()},{passive:!1});var e=0;document.addEventListener("touchend",function(t){var n=Date.now();n-e<=300&&t.preventDefault(),e=n},{passive:!1})}catch{}})()</script><a href=#content class="cba5854 c21e770 caffa6e cc5f604 cf2c31d cdd44dd c10dda9 c43876e c787e9b cddc2d2 cf55a7b c6dfb1e c9391e2">Skip to content</a>
<script>(function(){try{const e=localStorage.getItem("theme");e==="dark"&&document.documentElement.classList.add("dark");const t=document.querySelector('button[aria-label="Toggle theme"]');t&&t.setAttribute("aria-pressed",String(e==="dark"))}catch{}})();function toggleTheme(e){const s=document.documentElement,t=s.classList.toggle("dark");try{localStorage.setItem("theme",t?"dark":"light")}catch{}try{var n=e&&e.nodeType===1?e:document.querySelector('button[aria-label="Toggle theme"]');n&&n.setAttribute("aria-pressed",String(!!t))}catch{}}(function(){function e(){try{return document.documentElement.classList.contains("dark")?"dark":"light"}catch{return"light"}}function n(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(0)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!1,s.style.display="block"}catch{}o.setAttribute("aria-expanded","true"),n.setAttribute("aria-hidden","false");try{document.body.classList.add("c150bbe")}catch{}const i=document.getElementById("i190984");i&&i.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_open",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function t(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(100%)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!0,s.style.display="none"}catch{}o.setAttribute("aria-expanded","false"),n.setAttribute("aria-hidden","true");try{document.body.classList.remove("c150bbe")}catch{}o.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_close",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function s(e){e.key==="Escape"&&t("escape")}window.__openMobileMenu=n,window.__closeMobileMenu=t;try{window.addEventListener("keydown",s,!0)}catch{}})()</script><header class="cd019ba c98dfae cdd44dd cfdda01 c9ee25d ce2dc7a cd72dd7 cc0dc37" role=banner><div class="cfdda01 c6942b3 ccf47f4 c7c11d8"><a href=/ class="c87e2b0 c6942b3 c7c11d8 c1838fa cb594e4" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=32 height=32 class="c3de71a c4d5191">
<span class="cf8f011 c4d1253 cbd72bc cd7e69e">Leonardo Benicio</span></a><div class="c6942b3 c85cbd4 c7c11d8 ca798da c1838fa c7a0580"><nav class="cc1689c cd9b445 c75065d c04bab1" aria-label=Main><a href=/ class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Home</a>
<a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">About</a>
<a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Timeline</a>
<a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Reading</a>
<a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Publications</a>
<a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Contact</a></nav><button id="i1d73d4" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 c097fa1 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" onclick=toggleTheme(this) aria-label="Toggle theme" aria-pressed=false title="Toggle theme">
<svg class="cb26e41 c50ceea cb69a5c c4f45c8 c8c2c40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="cb26e41 c8fca2b cb69a5c c4f45c8 cc1689c c9c27ff" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><circle cx="12" cy="12" r="4"/><path d="M12 2v4"/><path d="M12 18v4"/><path d="M2 12h4"/><path d="M18 12h4"/><path d="M4.93 4.93l2.83 2.83"/><path d="M16.24 16.24l2.83 2.83"/><path d="M6.34 17.66l2.83-2.83"/><path d="M14.83 9.17l2.83-2.83"/></svg>
<span class="cba5854">Toggle theme</span></button><div class="c658bcf c097fa1"><button id="i975fb5" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" aria-label="Open menu" aria-controls="i98aca2" aria-expanded=false onclick='window.__openMobileMenu("button")' data-d38f920=mobile_menu_open_click>
<svg class="c20e4eb cb58471" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
<span class="cba5854">Open menu</span></button></div></div></div></header><div id="iad2af0" class="caffa6e ce4b5f4 c14639a" style=background-color:hsl(var(--background)) hidden onclick='window.__closeMobileMenu("overlay")' data-d38f920=mobile_menu_overlay_click></div><aside id="i98aca2" class="caffa6e c9efbc5 c437fa9 c49e97e c6c6936 c7cacca c7b34a4 c787e9b c88daee cad071a c6942b3 c03620d" role=dialog aria-modal=true aria-hidden=true aria-label="Mobile navigation" style="transform:translateX(100%);transition:transform 200ms ease-out;will-change:transform"><div class="c6942b3 c7c11d8 c82c52d c5df473 ccf47f4 c9ee25d"><a href=/ class="c6942b3 c7c11d8 c1838fa" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=24 height=24 class="c20e4eb cb58471">
<span class="c62aaf0 c7c1b66 cbd72bc">Leonardo Benicio</span>
</a><button id="i190984" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c514027 c286dd7 c2bd687 cfdce1d" aria-label="Close menu" onclick='window.__closeMobileMenu("button")' data-d38f920=mobile_menu_close_click>
<svg class="c16e528 c61f467" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 6 6 18"/><path d="m6 6 12 12"/></svg>
<span class="cba5854">Close</span></button></div><nav class="c85cbd4 ca0eaa4 c5df473 c6689b9"><ul class="cd69733"><li><a href=/ class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Home</a></li><li><a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>About</a></li><li><a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Timeline</a></li><li><a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Reading</a></li><li><a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Publications</a></li><li><a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Contact</a></li></ul></nav><div class="c60a4cc ccdf0e8 c277478 c13044e"><p>&copy; 2026 Leonardo Benicio</p></div></aside><div class="caffa6e c437fa9 ce9aced c97bba6 c15da2a c975cba" role=complementary aria-label="GitHub repository"><div class="c9d056d c252f85 ca22532 ca88a1a c876315"><div class="c6942b3 c7c11d8 c1d0018 cd1fd22 c6066e4 c43876e ce3d5b6 caa20d2 c3ecea6 c0cd2e2 cddc2d2 c3ed5c9 cd4074c c876315"><a href=https://github.com/lbenicio/aboutme target=_blank rel="noopener noreferrer" class="c6942b3 c7c11d8 cd1fd22 c71bae8 cfac1ac c19ee42 c25dc7c cb40739 cbbda39 cf55a7b" aria-label="View source on GitHub"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="cb26e41 c41bcd4 cf17690 cfa4e34 c78d562" aria-hidden="true"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></svg>
<span class="cb5c327 cd7e69e">Fork me</span></a></div></div></div><main id="i7eccc0" class="cfdda01 c5df473 c0eecc8 c85cbd4" role=main aria-label=Content><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Amdahls Law vs. Gustafsons Law What They Really Predict</span></li></ol></nav><article class="c461ba0 c1c203f cfb6084 c995404 c6ca165"><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Amdahls Law vs. Gustafsons Law What They Really Predict</span></li></ol></nav><header class="c8aedc7"><h1 class="cf304bc c6fb0fe cf8f011 cc484e1">Amdahl’s Law vs. Gustafson’s Law: What They Really Predict</h1><div class="c277478 c3ecea6 c8fb24a">2024-06-15
· Leonardo Benicio</div><div class="c1a1a3f c8124f2"><img src=/static/assets/images/blog/parallel-speedup.png alt class="cfdda01 c524300 c677556"></div><p class="lead c3ecea6">When does parallelism pay off? Compare Amdahl’s and Gustafson’s models, see where each applies, and learn how to reason about speedups in practice.</p></header><div class="content"><p>Amdahl’s Law and Gustafson’s Law are often presented as opposites, but they model different scenarios.</p><ul><li>Amdahl assumes a fixed problem size and asks: how much faster can I make this workload with P processors when a fraction s is inherently serial? The upper bound is:</li></ul><p>$$\text{Speedup}_A(P) = \frac{1}{s + \frac{1-s}{P}}.$$</p><ul><li>Gustafson assumes a fixed execution time and asks: given P processors, how much bigger can the problem become if parallel parts scale? The scaled speedup is:</li></ul><p>$$\text{Speedup}_G(P) = s + (1-s),P.$$</p><p>Neither law is “wrong.” Use Amdahl when the dataset is fixed (e.g., an SLA-bound query), and Gustafson when capacity grows with resources (e.g., larger simulations).</p><h3 id="practical-considerations">Practical considerations</h3><ul><li>The “serial fraction” s is not constant. It changes with cache behavior, synchronization, I/O, and algorithmic choices.</li><li>Contention and communication impose additional overhead. On NUMA machines and clusters, the effective 1/P region often degrades to 1/(P^α) for some α &lt; 1 due to bandwidth and latency.</li><li>Weak vs. strong scaling tests quantify these effects. Run both.</li></ul><h3 id="a-quick-experiment-sketch">A quick experiment sketch</h3><p>If you have a parallel kernel K and a serial setup S, measure wall times for varying P:</p><ul><li>Strong scaling: hold input size fixed; plot T(P). Compare empirical speedup with Amdahl.</li><li>Weak scaling: grow input size with P; check if time stays flat. Compare with Gustafson expectations.</li></ul><p>The punchline: choose your model based on product constraints (fixed time or fixed size), and validate with real measurements.</p><hr><h2 id="1-historical-context--motivation">1. Historical Context & Motivation</h2><p>Gene Amdahl introduced his law in 1967 to inject realism into expectations around adding processors to a system that runs a <em>fixed</em> workload (e.g., a benchmark problem size defined by an institution or an SLA‑bounded transaction). Later, John Gustafson (late 1980s) observed that in many scientific and data‑driven domains, <em>problem sizes</em> expand to absorb available compute time: researchers scale resolution, dimensionality, iteration counts, or ensemble size. Thus, holding execution time roughly constant while scaling problem size changes the algebra of perceived speedup. The supposed “contradiction” is simply that they answer different questions:</p><table><thead><tr><th>Question</th><th>Constraint</th><th>Varies</th><th>Appropriate Law</th></tr></thead><tbody><tr><td>“If I add cores, how much faster does this fixed job finish?”</td><td>Problem size fixed</td><td>Time</td><td>Amdahl</td></tr><tr><td>“If I add cores but keep wall time the same, how much <em>bigger</em> a job can I run?”</td><td>Time budget fixed</td><td>Problem size</td><td>Gustafson</td></tr></tbody></table><h2 id="2-formal-derivations--intuition">2. Formal Derivations & Intuition</h2><h3 id="amdahl-strong-scaling">Amdahl (Strong Scaling)</h3><p>Let a fraction ( s ) of execution be inherently serial and ( (1-s) ) be perfectly parallelizable. With ( P ) processors, the parallel portion ideally takes ( (1-s)/P ) of the original time, so normalized runtime is:
$$ T&rsquo;(P) = s + \frac{1-s}{P}. $$
Speedup is original time over new time:
$$ S<em>A(P) = \frac{1}{s + \frac{1-s}{P}}. $$
As ( P \to \infty ), ( S_A(P) \to 1/s ). Thus, _diminishing returns</em> appear once ( P \gg (1-s)/s ).</p><h3 id="gustafson-weak--scaled-scaling">Gustafson (Weak / Scaled Scaling)</h3><p>Assume we scale the <em>parallel</em> part proportionally to ( P ) while keeping wall time ~1. Let the original serial work still consume fraction ( s ) of the new runtime. Total scaled work executed relative to the single‑processor baseline is:
$$ W(P) = s + (1-s)P. $$
Interpreting this as an effective speedup vs. the single‑processor doing the same enlarged workload gives Gustafson’s form:
$$ S_G(P) = s + (1-s)P. $$
Here, the linear term dominates for large ( P ) unless ( s ) grows.</p><h3 id="reconciling-them">Reconciling Them</h3><p>If the serial fraction itself <em>shrinks</em> with larger problems (e.g., I/O or setup overhead amortizes), Gustafson’s optimistic scaling can still be bounded by other overheads (memory bandwidth, network contention) not in the simple algebra. In practice real speedup curves usually lie <em>between</em> naïve linear and Amdahl’s pessimistic upper bound.</p><h2 id="3-decomposing-the-serial-fraction">3. Decomposing the &ldquo;Serial Fraction&rdquo;</h2><p>The parameter ( s ) often bundles multiple phenomena:</p><ol><li>Truly sequential algorithmic stages (e.g., a final aggregation requiring ordered traversal).</li><li>Critical sections or locks (mutual exclusion reducing effective parallelism).</li><li>Communication & synchronization overhead (barriers, reductions, broadcast latency).</li><li>Load imbalance causing some workers to idle.</li><li>Resource contention (memory controllers, caches, interconnect bandwidth) flattening throughput.</li></ol><p>We can refine Amdahl’s model:
$$ T&rsquo;(P) = s*{alg} + s*{sync}(P) + s*{imb}(P) + \frac{1-s*{alg}}{P*{eff}(P)} $$
Where ( P*{eff}(P) \le P ) incorporates loss due to contention. Measuring / estimating each component directs optimization effort.</p><h2 id="4-numerical-examples">4. Numerical Examples</h2><p>Assume baseline runtime 100 seconds, with measured breakdown: 10 s serial init, 85 s parallel region, 5 s reduction. The “serial” parts sum to 15% (( s=0.15 )). Predicted Amdahl speedups:</p><table><thead><tr><th>P</th><th>Speedup S_A</th><th>Time (s)</th></tr></thead><tbody><tr><td>1</td><td>1.00</td><td>100.0</td></tr><tr><td>2</td><td>1.74</td><td>57.5</td></tr><tr><td>4</td><td>2.70</td><td>37.0</td></tr><tr><td>8</td><td>3.64</td><td>27.5</td></tr><tr><td>16</td><td>4.32</td><td>23.1</td></tr><tr><td>32</td><td>4.71</td><td>21.2</td></tr><tr><td>64</td><td>4.90</td><td>20.4</td></tr></tbody></table><p>Notice doubling cores past 16 yields small benefits. If we optimize the reduction (5 s) down to 1 s (now serial = 11/100 = 0.11): theoretical max jumps to ~9.09 vs. previous 6.67. <em>Reducing serial work often beats adding hardware.</em></p><p>Under weak scaling, if we hold time near 100 s but enlarge the parallel portion linearly with ( P ), the executed useful work measured against the baseline is ( S_G(P) ). With ( s=0.15 ): at 32 cores, ( S_G=0.15 + 0.85*32 = 27.35 ) “effective” speedup in problem size.</p><h2 id="5-memory-hierarchy--bandwidth-effects">5. Memory Hierarchy & Bandwidth Effects</h2><p>Even if code is “parallel,” memory bandwidth can cap speedup. Suppose per‑core memory demand drives total bandwidth past system limits; effective per-core throughput scales sublinearly. We can model that as:
$$ P*{eff}(P) = \min\left(P, \frac{B*{max}}{b_{core}}\right). $$
If each core wants 5 GB/s and the socket sustains 200 GB/s, linear scaling stops past 40 cores <strong>even if</strong> algorithmic parallelism remains. This interacts with both laws—Amdahl’s serial fraction effectively grows because the “parallel” region inflates in time relative to ideal.</p><h2 id="6-multi-level-parallelism">6. Multi-Level Parallelism</h2><p>Modern systems layer parallelism: vector (SIMD) lanes, cores, NUMA domains, nodes, GPUs, and possibly accelerators (TPUs). The composite speedup is multiplicative only if inefficiencies are independent. Practically, you evaluate scaling at each tier:</p><ol><li>Vectorization (SSE/AVX/GPU warps).</li><li>Thread (OpenMP / pthreads) across cores.</li><li>Process / rank (MPI) across nodes.</li><li>Task / pipeline parallelism (asynchronous I/O, overlapping compute & comms).</li></ol><p>Often a small serial fraction at one layer becomes dominant after you eliminate bottlenecks elsewhere. Continuous profiling (e.g., using Linux perf, VTune, Nsight Systems) is essential.</p><h2 id="7-overheads-hidden-in-gustafsons-framing">7. Overheads Hidden in Gustafson’s Framing</h2><p>Gustafson’s expression omits that <em>expanding</em> problem size may increase the serial fraction: initialization of larger grids, building bigger data structures, or longer reduction trees. Empirically, ( s ) can be modeled as ( s(P) = s_0 + c \log P ) (e.g., tree reductions). Plugging this into scaled speedup:
$$ S_G&rsquo;(P) = s(P) + (1-s(P))P $$
reveals eventual deviation from linearity.</p><h2 id="8-measurement-methodology">8. Measurement Methodology</h2><p>Steps to obtain credible scaling curves:</p><ol><li><strong>Baseline profiling:</strong> measure wall time, break down by phase; identify candidate serial components.</li><li><strong>Instrument barriers & reductions:</strong> timestamp entry/exit to quantify synchronization cost.</li><li><strong>Vary P systematically:</strong> run powers of two; collect (runtime, energy if relevant). Repeat for statistical confidence (variance can hide inflection points).</li><li><strong>Compute efficiency:</strong> ( E(P)=S(P)/P ). Watch where efficiency drops below thresholds (e.g., 50%).</li><li><strong>Fit models:</strong> simple regression to estimate ( s ); compare predicted vs observed; residual structure hints at unmodeled overhead.</li><li><strong>Iterate optimization:</strong> attack largest residual contributor; re-measure.</li></ol><h2 id="9-extensions-karpflatt-metric">9. Extensions: Karp–Flatt Metric</h2><p>The Karp–Flatt serial fraction estimate:
$$ e(P) = \frac{1/S(P) - 1/P}{1 - 1/P} $$
provides an <em>observed</em> effective serial fraction including all overheads. Plotting ( e(P) ) vs. ( P ) reveals trends: if it grows, you are encountering scaling penalties (communication, imbalance). Amdahl’s “s” is constant only in ideal cases.</p><h2 id="10-accelerators-gpus--heterogeneous-speedup">10. Accelerators (GPUs) & Heterogeneous Speedup</h2><p>Porting a parallel region to a GPU changes relative weights. Suppose compute kernel becomes 20× faster but data marshaling (CPU↔GPU transfers, kernel launch) adds a fixed overhead. New serial fraction might increase if transfers dominate at small problem sizes, reducing <em>strong scaling</em> benefit until you scale problem size (Gustafson scenario) to amortize overhead.</p><h3 id="simple-model">Simple Model</h3><p>Let original time = 1; parallel portion = 0.8 moved to GPU with speedup 20; transfer+launch overhead = 0.05 added to serial fraction. New time:
$$ T&rsquo; = (0.2 + 0.05) + \frac{0.8}{20} = 0.25 + 0.04 = 0.29 $$
Speedup ≈ 3.45× not 20×. Optimizing <em>data movement</em> (overlapping transfers, using pinned memory, kernel fusion) reduces the additive overhead making the GPU scale more like its theoretical compute advantage.</p><h2 id="11-diminishing-returns--cost-models">11. Diminishing Returns & Cost Models</h2><p>Hardware cost and energy scale roughly with ( P ). If speedup saturates, cost per unit work improves only up to the “knee” of the curve. Introduce a cost function:
$$ \text{Cost Efficiency}(P)=\frac{S(P)}{P^\beta} $$
with ( \beta\approx1 ) (linear cost). Choose ( P ) maximizing this. Real deployments often target <em>energy to solution</em>: measure joules using RAPL or GPU telemetry; energy often bottoms near the same region where parallel efficiency degrades.</p><h2 id="12-common-misinterpretations">12. Common Misinterpretations</h2><table><thead><tr><th>Myth</th><th>Clarification</th></tr></thead><tbody><tr><td>“Amdahl says adding more than N cores is pointless.”</td><td>No: it bounds speedup for that <em>fixed</em> problem. Bigger problems can still benefit.</td></tr><tr><td>“Gustafson guarantees linear scaling.”</td><td>Only if serial fraction stays constant and parallel work increases ideally.</td></tr><tr><td>“Serial fraction is inherent to language/runtime.”</td><td>Much is algorithm + data structure choice + synchronization strategy.</td></tr><tr><td>“Observed efficiency drop means algorithm is bad.”</td><td>Could be memory bandwidth saturation or network contention, not algorithmic serialism.</td></tr></tbody></table><h2 id="13-practical-checklist">13. Practical Checklist</h2><ol><li>Define scaling objective: reduce <em>time to answer</em> (Amdahl) or increase <em>resolution</em> (Gustafson).</li><li>Profile to partition time; quantify synchronization & imbalance.</li><li>Fit early data to Amdahl; estimate potential upper bound—do not over‑invest beyond it.</li><li>Evaluate memory / I/O throughput counters to find bandwidth ceilings.</li><li>Explore algorithmic changes (e.g., more parallel-friendly data layouts) before hardware scaling.</li><li>For weak scaling, track how serial initialization grows—keep it sublinear.</li><li>Revisit at new hardware generations; architectural shifts (cache sizes, NUMA topology) change effective ( s ).</li></ol><h2 id="14-tooling--instrumentation-tips">14. Tooling & Instrumentation Tips</h2><ul><li>Use <code>perf stat -d</code> (Linux) or VTune to examine instructions per cycle (IPC) shifts as P grows.</li><li>Insert high-resolution timers (TSC, chrono) around barriers to compute aggregate lost time.</li><li>Use tracing (e.g., OpenTelemetry spans for distributed tasks) to isolate stragglers.</li><li>For GPU: Nsight Systems to overlap copy/compute; Nsight Compute for memory transactions; watch achieved occupancy vs. theoretical.</li><li>For MPI: <code>mpiP</code> or built-in profiling interface to aggregate time in collectives.</li></ul><h2 id="15-putting-it-together-mini-case-study">15. Putting It Together: Mini Case Study</h2><p>A simulation code (baseline 1 hour on 1 core): 8% serial setup, 90% parallel kernel, 2% I/O flush. On 32 cores measured speedup is only 10× (instead of ~11.6 predicted by Amdahl with s=0.08). Investigation shows cache misses doubling due to data structure layout. After restructuring arrays-of-structs to struct-of-arrays, kernel memory bandwidth improves; speedup rises to 11.2×. Further improvement stalls—profiling reveals barrier imbalance (some threads idle). Applying domain decomposition with better partitioning trims imbalance; final speedup 11.5×, near theoretical. Decision: scaling beyond 32 cores offers &lt;5% gain; resources invested in increasing problem resolution instead (Gustafson scenario).</p><h2 id="16-further-reading-titles">16. Further Reading (Titles)</h2><ul><li>&ldquo;The Validity of Amdahl&rsquo;s Law in the Multicore Era&rdquo; (analysis papers)</li><li>&ldquo;A Case for Optimistic Parallelism&rdquo; (explores overhead and contention)</li><li>&ldquo;Roofline: An Insightful Visual Performance Model&rdquo; (memory vs compute bounds)</li><li>&ldquo;The Karp–Flatt Metric for Parallel Performance&rdquo; (derivation discussions)</li><li>&ldquo;Gustafson&rsquo;s Scaling Revisited&rdquo; (weak scaling nuances)</li><li>Vendor profiling guides (Intel VTune, NVIDIA Nsight) for practical measurement.</li></ul><h2 id="17-summary">17. Summary</h2><p>Amdahl’s Law bounds speedup for fixed workloads by highlighting that serial portions dominate with many processors. Gustafson’s Law reframes scaling for expanding workloads under fixed time budgets. Real systems interpose memory bandwidth, synchronization, and imbalance, making <em>effective</em> scaling a function of more than an algorithmic serial fraction. Use both perspectives: Amdahl to judge <em>when to stop adding cores</em>, Gustafson to decide <em>how to spend newly available cores</em>. Always ground assumptions in measurement.</p></div><footer class="ce1a612 c6dfb1e c3ecea6"><div class="c364589">Categories:
<a href=/categories/theory/>theory</a>, <a href=/categories/performance/>performance</a></div><div>Tags:
<a href=/tags/parallelism/>#parallelism</a>, <a href=/tags/scalability/>#scalability</a>, <a href=/tags/speedup/>#speedup</a>, <a href=/tags/hpc/>#hpc</a></div></footer></article></main><footer class="ccdf0e8" role=contentinfo aria-label=Footer><div class="cfdda01 c133889 c5df473 c0eecc8 c69618a c6942b3 c03620d c2a9f27 c7c11d8 c82c52d c14527b"><div class="c6dfb1e c3ecea6 c39ef11 c88ae6f">&copy; 2026 Leonardo Benicio. All rights
reserved.</div><div class="c6942b3 c7c11d8 cd1fd22"><a href=https://github.com/lbenicio target=_blank rel="noopener noreferrer" aria-label=GitHub class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.5-.67 1.08-.82 1.7s-.2 1.27-.18 1.9V22"/></svg>
<span class="cba5854">GitHub</span>
</a><a href=https://www.linkedin.com/in/leonardo-benicio target=_blank rel="noopener noreferrer" aria-label=LinkedIn class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452H17.21V14.86c0-1.333-.027-3.046-1.858-3.046-1.86.0-2.145 1.45-2.145 2.948v5.69H9.069V9h3.112v1.561h.044c.434-.82 1.494-1.686 3.074-1.686 3.29.0 3.897 2.165 3.897 4.983v6.594zM5.337 7.433a1.805 1.805.0 11-.002-3.61 1.805 1.805.0 01.002 3.61zM6.763 20.452H3.911V9h2.852v11.452z"/></svg>
<span class="cba5854">LinkedIn</span>
</a><a href=https://twitter.com/lbenicio_ target=_blank rel="noopener noreferrer" aria-label=Twitter class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M19.633 7.997c.013.177.013.354.013.53.0 5.386-4.099 11.599-11.6 11.599-2.31.0-4.457-.676-6.265-1.842.324.038.636.05.972.05 1.91.0 3.67-.65 5.07-1.755a4.099 4.099.0 01-3.827-2.84c.25.039.5.064.763.064.363.0.726-.051 1.065-.139A4.091 4.091.0 012.542 9.649v-.051c.538.3 1.162.482 1.824.507A4.082 4.082.0 012.54 6.7c0-.751.2-1.435.551-2.034a11.63 11.63.0 008.44 4.281 4.615 4.615.0 01-.101-.938 4.091 4.091.0 017.078-2.799 8.1 8.1.0 002.595-.988 4.112 4.112.0 01-1.8 2.261 8.2 8.2.0 002.357-.638A8.824 8.824.0 0119.613 7.96z"/></svg>
<span class="cba5854">Twitter</span></a></div></div></footer></body></html>