<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no"><title>Database Internals: Storage Engines, Transactions, and Recovery · Leonardo Benicio</title><meta name=description content="A deep technical walkthrough of how databases store data, ensure correctness, and recover from crashes — covering B-trees, LSM-trees, write-ahead logging, MVCC, isolation levels, and replication."><link rel=alternate type=application/rss+xml title=RSS href=https://lbenicio.dev/index.xml><link rel=canonical href=https://blog.lbenicio.dev/blog/database-internals-storage-engines-transactions-and-recovery/><link rel=preload href=/static/fonts/OpenSans-Regular.ttf as=font type=font/ttf crossorigin><link rel="stylesheet" href="/assets/css/fonts.min.40e2054b739ac45a0f9c940f4b44ec00c3b372356ebf61440a413c0337c5512e.css" crossorigin="anonymous" integrity="sha256-QOIFS3OaxFoPnJQPS0TsAMOzcjVuv2FECkE8AzfFUS4="><link rel="shortcut icon" href=/static/assets/favicon/favicon.ico><link rel=icon type=image/x-icon href=/static/assets/favicon/favicon.ico><link rel=icon href=/static/assets/favicon/favicon.svg type=image/svg+xml><link rel=icon href=/static/assets/favicon/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=/static/assets/favicon/favicon-16x16.png sizes=16x16 type=image/png><link rel=apple-touch-icon href=/static/assets/favicon/apple-touch-icon.png><link rel=manifest href=/static/assets/favicon/site.webmanifest><link rel=mask-icon href=/static/assets/favicon/safari-pinned-tab.svg color=#209cee><meta name=msapplication-TileColor content="#209cee"><meta name=msapplication-config content="/static/assets/favicon/browserconfig.xml"><meta name=theme-color content="#d2e9f8"><meta property="og:title" content="Database Internals: Storage Engines, Transactions, and Recovery · Leonardo Benicio"><meta property="og:description" content="A deep technical walkthrough of how databases store data, ensure correctness, and recover from crashes — covering B-trees, LSM-trees, write-ahead logging, MVCC, isolation levels, and replication."><meta property="og:url" content="https://blog.lbenicio.dev/blog/database-internals-storage-engines-transactions-and-recovery/"><meta property="og:type" content="article"><meta property="og:image" content="https://blog.lbenicio.dev/static/assets/images/blog/database-internals-transactions-storage-engines.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Database Internals: Storage Engines, Transactions, and Recovery · Leonardo Benicio"><meta name=twitter:description content="A deep technical walkthrough of how databases store data, ensure correctness, and recover from crashes — covering B-trees, LSM-trees, write-ahead logging, MVCC, isolation levels, and replication."><meta name=twitter:site content="@lbenicio_"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","name":"About Leonardo Benicio","url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Person","name":"Leonardo Benicio","sameAs":["https://github.com/lbenicio","https://www.linkedin.com/in/leonardo-benicio","https://twitter.com/lbenicio_"],"url":"https://blog.lbenicio.dev"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Home","position":1},{"@type":"ListItem","item":"https://blog.lbenicio.dev/","name":"Blog","position":2},{"@type":"ListItem","item":"https://blog.lbenicio.dev/blog/database-internals-storage-engines-transactions-and-recovery/","name":"Database Internals Storage Engines Transactions and Recovery","position":3}]}</script><link rel="stylesheet" href="/assets/css/main.min.1e8a566ac8bc3f0664d0db4ec8a015b07421c33fa11d336a6b914522a9cabf30.css" crossorigin="anonymous" integrity="sha256-6lhUOpwCHMSMROmggsVSp3AHKud6gBrIFGTzl3GV4BY="></head><body class="c6942b3 c03620d cf3bd2e"><script>(function(){try{document.addEventListener("gesturestart",function(e){e.preventDefault()}),document.addEventListener("touchstart",function(e){e.touches&&e.touches.length>1&&e.preventDefault()},{passive:!1});var e=0;document.addEventListener("touchend",function(t){var n=Date.now();n-e<=300&&t.preventDefault(),e=n},{passive:!1})}catch{}})()</script><a href=#content class="cba5854 c21e770 caffa6e cc5f604 cf2c31d cdd44dd c10dda9 c43876e c787e9b cddc2d2 cf55a7b c6dfb1e c9391e2">Skip to content</a>
<script>(function(){try{const e=localStorage.getItem("theme");e==="dark"&&document.documentElement.classList.add("dark");const t=document.querySelector('button[aria-label="Toggle theme"]');t&&t.setAttribute("aria-pressed",String(e==="dark"))}catch{}})();function toggleTheme(e){const s=document.documentElement,t=s.classList.toggle("dark");try{localStorage.setItem("theme",t?"dark":"light")}catch{}try{var n=e&&e.nodeType===1?e:document.querySelector('button[aria-label="Toggle theme"]');n&&n.setAttribute("aria-pressed",String(!!t))}catch{}}(function(){function e(){try{return document.documentElement.classList.contains("dark")?"dark":"light"}catch{return"light"}}function n(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(0)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!1,s.style.display="block"}catch{}o.setAttribute("aria-expanded","true"),n.setAttribute("aria-hidden","false");try{document.body.classList.add("c150bbe")}catch{}const i=document.getElementById("i190984");i&&i.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_open",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function t(t){const n=document.getElementById("i98aca2"),s=document.getElementById("iad2af0"),o=document.getElementById("i975fb5");if(!n||!s||!o)return;try{n.style.transform="translateX(100%)",n.style.transition||(n.style.transition="transform 200ms ease-out")}catch{}try{s.hidden=!0,s.style.display="none"}catch{}o.setAttribute("aria-expanded","false"),n.setAttribute("aria-hidden","true");try{document.body.classList.remove("c150bbe")}catch{}o.focus();try{window.umami&&typeof window.umami.track=="function"&&window.umami.track("mobile_menu_close",{page:location.pathname,theme:e(),source:t||"programmatic"})}catch{}}function s(e){e.key==="Escape"&&t("escape")}window.__openMobileMenu=n,window.__closeMobileMenu=t;try{window.addEventListener("keydown",s,!0)}catch{}})()</script><header class="cd019ba c98dfae cdd44dd cfdda01 c9ee25d ce2dc7a cd72dd7 cc0dc37" role=banner><div class="cfdda01 c6942b3 ccf47f4 c7c11d8"><a href=/ class="c87e2b0 c6942b3 c7c11d8 c1838fa cb594e4" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=32 height=32 class="c3de71a c4d5191">
<span class="cf8f011 c4d1253 cbd72bc cd7e69e">Leonardo Benicio</span></a><div class="c6942b3 c85cbd4 c7c11d8 ca798da c1838fa c7a0580"><nav class="cc1689c cd9b445 c75065d c04bab1" aria-label=Main><a href=/ class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Home</a>
<a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">About</a>
<a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Timeline</a>
<a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Reading</a>
<a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Publications</a>
<a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c4d1253 c9e4539 cbbda39 c01f421 c19ee42 c3ecea6">Contact</a></nav><button id="i1d73d4" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 c097fa1 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" onclick=toggleTheme(this) aria-label="Toggle theme" aria-pressed=false title="Toggle theme">
<svg class="cb26e41 c50ceea cb69a5c c4f45c8 c8c2c40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="cb26e41 c8fca2b cb69a5c c4f45c8 cc1689c c9c27ff" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><circle cx="12" cy="12" r="4"/><path d="M12 2v4"/><path d="M12 18v4"/><path d="M2 12h4"/><path d="M18 12h4"/><path d="M4.93 4.93l2.83 2.83"/><path d="M16.24 16.24l2.83 2.83"/><path d="M6.34 17.66l2.83-2.83"/><path d="M14.83 9.17l2.83-2.83"/></svg>
<span class="cba5854">Toggle theme</span></button><div class="c658bcf c097fa1"><button id="i975fb5" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c8e184d c514027 c88daee c7a66a6 cfc01c7 c286dd7 c2bd687 cfdce1d cfef18f" aria-label="Open menu" aria-controls="i98aca2" aria-expanded=false onclick='window.__openMobileMenu("button")' data-d38f920=mobile_menu_open_click>
<svg class="c20e4eb cb58471" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg>
<span class="cba5854">Open menu</span></button></div></div></div></header><div id="iad2af0" class="caffa6e ce4b5f4 c14639a" style=background-color:hsl(var(--background)) hidden onclick='window.__closeMobileMenu("overlay")' data-d38f920=mobile_menu_overlay_click></div><aside id="i98aca2" class="caffa6e c9efbc5 c437fa9 c49e97e c6c6936 c7cacca c7b34a4 c787e9b c88daee cad071a c6942b3 c03620d" role=dialog aria-modal=true aria-hidden=true aria-label="Mobile navigation" style="transform:translateX(100%);transition:transform 200ms ease-out;will-change:transform"><div class="c6942b3 c7c11d8 c82c52d c5df473 ccf47f4 c9ee25d"><a href=/ class="c6942b3 c7c11d8 c1838fa" aria-label=Home><img src=/static/assets/favicon/favicon.svg alt=Logo width=24 height=24 class="c20e4eb cb58471">
<span class="c62aaf0 c7c1b66 cbd72bc">Leonardo Benicio</span>
</a><button id="i190984" type=button class="c1d6c20 c81ac7c c6a899b c7c11d8 c1d0018 c10dda9 c514027 c286dd7 c2bd687 cfdce1d" aria-label="Close menu" onclick='window.__closeMobileMenu("button")' data-d38f920=mobile_menu_close_click>
<svg class="c16e528 c61f467" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 6 6 18"/><path d="m6 6 12 12"/></svg>
<span class="cba5854">Close</span></button></div><nav class="c85cbd4 ca0eaa4 c5df473 c6689b9"><ul class="cd69733"><li><a href=/ class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Home</a></li><li><a href=https://lbenicio.dev/about target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>About</a></li><li><a href=https://lbenicio.dev/timeline target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Timeline</a></li><li><a href=https://lbenicio.dev/reading target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Reading</a></li><li><a href=https://publications.lbenicio.dev target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Publications</a></li><li><a href=https://lbenicio.dev/contact target=_blank rel="noopener noreferrer" class="c3b5299 c10dda9 cddc2d2 cf55a7b c7c1b66 cbbda39 c3ecea6 c19ee42 c514027" onclick=window.__closeMobileMenu()>Contact</a></li></ul></nav><div class="c60a4cc ccdf0e8 c277478 c13044e"><p>&copy; 2026 Leonardo Benicio</p></div></aside><div class="caffa6e c437fa9 ce9aced c97bba6 c15da2a c975cba" role=complementary aria-label="GitHub repository"><div class="c9d056d c252f85 ca22532 ca88a1a c876315"><div class="c6942b3 c7c11d8 c1d0018 cd1fd22 c6066e4 c43876e ce3d5b6 caa20d2 c3ecea6 c0cd2e2 cddc2d2 c3ed5c9 cd4074c c876315"><a href=https://github.com/lbenicio/aboutme target=_blank rel="noopener noreferrer" class="c6942b3 c7c11d8 cd1fd22 c71bae8 cfac1ac c19ee42 c25dc7c cb40739 cbbda39 cf55a7b" aria-label="View source on GitHub"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="cb26e41 c41bcd4 cf17690 cfa4e34 c78d562" aria-hidden="true"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"/><path d="M9 18c-4.51 2-5-2-7-2"/></svg>
<span class="cb5c327 cd7e69e">Fork me</span></a></div></div></div><main id="i7eccc0" class="cfdda01 c5df473 c0eecc8 c85cbd4" role=main aria-label=Content><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Database Internals Storage Engines Transactions and Recovery</span></li></ol></nav><article class="c461ba0 c1c203f cfb6084 c995404 c6ca165"><nav class="cb545ce c8d8ae4 c277478" aria-label=Breadcrumb><ol class="c6942b3 c3adaf2 c7c11d8 cd365ee c3ecea6"><li><a href=/ class="c19ee42 c71bae8 cfac1ac">Home</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><a href=/ class="c19ee42 c71bae8 cfac1ac">Blog</a></li><li class="c6942b3 c7c11d8 cd365ee"><span class="cb82ddd">/</span><span class="c88daee">Database Internals Storage Engines Transactions and Recovery</span></li></ol></nav><header class="c8aedc7"><h1 class="cf304bc c6fb0fe cf8f011 cc484e1">Database Internals: Storage Engines, Transactions, and Recovery</h1><div class="c277478 c3ecea6 c8fb24a">2025-12-21
· Leonardo Benicio</div><div class="c1a1a3f c8124f2"><img src=/static/assets/images/blog/database-internals-transactions-storage-engines.png alt class="cfdda01 c524300 c677556"></div><p class="lead c3ecea6">A deep technical walkthrough of how databases store data, ensure correctness, and recover from crashes — covering B-trees, LSM-trees, write-ahead logging, MVCC, isolation levels, and replication.</p></header><div class="content"><p>Databases are much more than SQL parsers and client libraries — their core is a storage engine that durably stores and efficiently retrieves data while preserving the guarantees applications depend upon. This article unpacks how modern databases manage on-disk data structures, coordinate concurrent access, provide transactional semantics, and recover from crashes. We&rsquo;ll look at B-trees and LSM-trees, the write-ahead log, MVCC and isolation levels, recovery algorithms, and practical tuning advice for real-world systems.</p><h2 id="1-the-database-stack-responsibilities-and-components">1. The Database Stack: responsibilities and components</h2><p>A storage engine&rsquo;s main responsibilities:</p><ul><li>Durable storage: Persist committed transactions so they survive crashes.</li><li>Efficient access: Serve point lookups, range scans, and index queries with low latency.</li><li>Concurrency control: Allow multiple clients to operate safely in parallel.</li><li>Atomicity and consistency: Ensure transactions appear atomic and preserve integrity constraints.</li><li>Recovery: After a crash, restore a consistent state and finish or roll back in-flight operations.</li></ul><p>Key components:</p><ul><li>Write-Ahead Log (WAL): Durable sequential log of changes.</li><li>In-memory buffers (memtables/cache): Fast read/write layer.</li><li>On-disk structures: B-trees or SSTables which store persistent data.</li><li>Checkpointing/compaction: Periodic actions to reduce WAL replay and rewrite data into compact form.</li><li>Transaction manager: Tracks in-flight transactions, versions, and commit state.</li><li>Replication & consensus: For high availability and global durability.</li></ul><p>This layered separation allows databases to trade off read/write performance, latency, and space amplification while ensuring correctness.</p><h2 id="2-page-oriented-storage-and-record-layout">2. Page-oriented storage and record layout</h2><p>Most storage engines organize disk into fixed-size pages (typically 4KB or 8KB) — the unit of I/O and caching.</p><h3 id="21-typical-page-layout">2.1 Typical page layout</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Page header (fixed):
</span></span><span style=display:flex><span>- Page type (leaf, interior, overflow)
</span></span><span style=display:flex><span>- LSN (log sequence number) of last modification
</span></span><span style=display:flex><span>- Free space pointer / slot array offset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Slot array (for variable records):
</span></span><span style=display:flex><span>- Offsets to record beginnings (allows compaction and variable length)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Records: key, value, metadata
</span></span><span style=display:flex><span>- Key length (varint)
</span></span><span style=display:flex><span>- Value length (varint)
</span></span><span style=display:flex><span>- Inline or overflow storage for big values
</span></span></code></pre></div><p>Page design choices affect fragmentation, scanning speed, and update complexity. For example, updates that increase record size may cause split or overflow pages, requiring extra work.</p><h3 id="22-page-based-caching-and-dirty-management">2.2 Page-based caching and dirty management</h3><ul><li>Buffer pool: In-memory cache of recently used pages (LRU or CLOCK eviction).</li><li>Dirty pages: Modified pages that must be flushed to disk before their WAL becomes irrelevant.</li><li>Pinning: Prevent eviction while a page is in use.</li></ul><p>Efficient buffer management reduces disk I/O and improves throughput.</p><h2 id="3-b-trees-the-classic-on-disk-index">3. B-Trees: the classic on-disk index</h2><p>B-trees (and B+trees) are the canonical balanced tree used for clustered indexes and range queries.</p><h3 id="31-node-structure-and-invariants">3.1 Node structure and invariants</h3><ul><li>Each node contains up to M keys and M+1 pointers.</li><li>All leaves at same depth (balanced).</li><li>Height is small for large datasets (e.g., 4–5 levels for billions of rows when page size is 4KB).</li></ul><p>B+tree variation: keys in internal nodes, full records stored only in leaves — optimizes range scans.</p><h3 id="32-search-and-insert">3.2 Search and insert</h3><p>Search complexity: O(log_M N) disk pages touched.</p><p>Insertion algorithm (high-level):</p><ol><li>Search down to leaf where key belongs.</li><li>Insert key/value into leaf. If it overflows (too many keys), split.</li><li>Propagate split to parent, possibly up to root (which can increase height).</li></ol><p>Splitting is expensive (requires I/O to write new pages and update parent). To amortize cost, many databases batch writes or apply them via WAL before page updates.</p><h3 id="33-deletion-and-rebalancing">3.3 Deletion and rebalancing</h3><p>Deletion may cause underflow. Many implementations either rebalance with neighbors (borrow) or merge nodes. Rebalancing minimizes tree height changes but increases write amplification.</p><h3 id="34-locking-and-concurrency">3.4 Locking and concurrency</h3><p>Classic B-tree concurrency techniques:</p><ul><li>Latch coupling (hand-over-hand locking): Acquire a lock on parent, then child; release parent when child lock obtained.</li><li>Intent locks (MDL): Indicate intention to modify a subtree so higher-level operations avoid contention.</li><li>Lock-free or optimistic approaches: Use version counters and detect conflicts after traversals.</li></ul><p>High-performance systems favor latch-free reads with short critical sections for structural modifications.</p><h2 id="4-lsm-trees-write-optimized-storage-engines">4. LSM-Trees: write-optimized storage engines</h2><p>Log-Structured Merge Trees (LSM) invert the classic B-tree trade-offs: optimize for writes by turning random I/O into sequential writes and performing compaction in the background.</p><h3 id="41-components-of-an-lsm-engine">4.1 Components of an LSM engine</h3><ul><li>Memtable: In-memory ordered structure (skiplist or tree) that accepts writes.</li><li>WAL: Append-only log to guarantee durability of memtable contents.</li><li>SSTables (sorted string tables): Immutable on-disk files produced by flushing memtables.</li><li>Compaction: Background process merging multiple SSTables into new ones, discarding obsolete versions.</li></ul><p>Flow:</p><ol><li>Client writes → memtable (fast) + WAL (durable).</li><li>When memtable full → flush to SSTable (sequential write).</li><li>Compaction merges SSTables and removes tombstones.</li></ol><h3 id="42-read-path-complexity">4.2 Read path complexity</h3><p>Reads need to check memtable first, then across SSTable levels (often using bloom filters to avoid scanning files), then merge results if multiple entries exist for the same key.</p><p>SSTable layout typically includes:</p><ul><li>Block index (per-chunk sampling of keys)</li><li>Bloom filter for quick negative checks</li><li>Restart points to enable binary search inside compressed blocks</li></ul><h3 id="43-compaction-strategies-and-tuning">4.3 Compaction strategies and tuning</h3><p>Compaction governs space amplification, write amplification, and read performance.</p><ul><li>Levelled compaction (used by RocksDB): Files organized in levels where each level is larger by a factor (e.g., 10). Compaction keeps levels disjoint key ranges, reducing read amplification.</li><li>Size-tiered compaction: Merge similarly-sized files to reduce the number of files, but may increase read amplification.</li></ul><p>Tuning knobs:</p><ul><li>Compaction threads and throughput throttling.</li><li>Fanout between levels (space multiplier).</li><li>Trigger thresholds for minor vs major compactions.</li></ul><p>Tradeoffs:</p><ul><li>More compaction → lower read amplification, higher write amplification, more CPU</li><li>Less compaction → cheaper writes, more files to consult on reads</li></ul><h3 id="44-tombstones-and-delete-semantics">4.4 Tombstones and delete semantics</h3><p>Deletes in LSM are represented as tombstones — special marker entries. Tombstones are removed only during compaction, so reads must respect them and treat deleted keys as absent until tombstone is purged.</p><h2 id="5-the-write-ahead-log-wal-and-durability">5. The Write-Ahead Log (WAL) and durability</h2><p>WAL is the backbone of durability: a sequential record of changes that allows replay after crashes.</p><h3 id="51-wal-mechanics">5.1 WAL mechanics</h3><p>Principles:</p><ul><li>Append-only: Writes are appended to a log file and flushed to disk (fsync or fdatasync) before acknowledging commits.</li><li>Idempotent or ordered writes: Each log record includes an LSN (log sequence number) used to order changes.</li><li>WAL record types: Begin txn, update (page delta or key-value), commit, checkpoint markers.</li></ul><p>On recovery, the database replays WAL records, reapplying committed changes and rolling back partial ones if necessary.</p><h3 id="52-group-commit-and-latency-amortization">5.2 Group commit and latency amortization</h3><p>Flushing the WAL per-transaction is expensive. Group commit batches multiple transactions&rsquo; WAL records before a single disk flush, amortizing fsync cost across many transactions.</p><p>Batching strategies:</p><ul><li>Synchronous: Wait for all transactions in group to be buffered then flush once.</li><li>Asynchronous: Background flusher flushes WAL at regular intervals (reduces latency guarantees: producers may return before data durable).</li></ul><p>If durability is critical (e.g., financial systems), prefer synchronous group commit with short wait windows (ms-level).</p><h3 id="53-checkpoints-and-reducing-recovery-time">5.3 Checkpoints and reducing recovery time</h3><p>A checkpoint writes a consistent snapshot of on-disk structures (pages or SSTable manifests) and records the LSN up to which recovery must replay WAL. Regular checkpoints bound recovery time by avoiding full WAL replays since inception.</p><h2 id="6-transactions-isolation-levels-and-mvcc">6. Transactions, isolation levels, and MVCC</h2><p>Transactions provide atomic multi-statement updates. Isolation levels determine how concurrent transactions interact.</p><h3 id="61-acid-recap">6.1 ACID recap</h3><ul><li>Atomicity: All-or-nothing semantics (often implemented using WAL and rollback).</li><li>Consistency: Database invariants are preserved (schema, constraints).</li><li>Isolation: Concurrent transactions do not interfere (various guarantees).</li><li>Durability: Committed transactions survive crashes (WAL + commit flush).</li></ul><h3 id="62-isolation-levels">6.2 Isolation levels</h3><p>ANSI SQL defines several isolation levels with increasing guarantees:</p><ul><li>Read Uncommitted: Low isolation, may see dirty reads.</li><li>Read Committed: No dirty reads; sees only committed data.</li><li>Repeatable Read: Guarantees repeatable reads within a transaction (prevents non-repeatable reads), but may still allow phantoms depending on implementation.</li><li>Serializable: Equivalent to serial execution; highest guarantee.</li></ul><p>Databases implement these with different techniques; e.g., Snapshot Isolation (SI) is used widely because it avoids many anomalies of weaker levels while being performant.</p><h3 id="63-mvcc-multi-version-concurrency-control">6.3 MVCC (Multi-Version Concurrency Control)</h3><p>MVCC allows readers to see a consistent snapshot without blocking writers by keeping multiple versions of data.</p><p>Core ideas:</p><ul><li>Each update writes a new version with a commit timestamp or LSN.</li><li>Reads choose the version visible to their snapshot timestamp.</li><li>Old versions are retained until no active transactions need them (garbage collection).</li></ul><p>MVCC data layout (simplified):</p><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>Key -&gt; [Version: {value, commit_ts, txn_id}] -&gt; [older versions...]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Read(snapshot_ts): find first version with commit_ts &lt;= snapshot_ts
</span></span><span style=display:flex><span>Write: append new uncommitted version, record in WAL
</span></span><span style=display:flex><span>Commit: set commit_ts and flush
</span></span></code></pre></div><p>Read-only transactions can use a stable snapshot and never block writers — excellent for analytical queries and consistent backups.</p><h3 id="64-anomalies-and-si-vs-serializable">6.4 Anomalies and SI vs Serializable</h3><p>Snapshot Isolation prevents many anomalies (dirty reads, non-repeatable reads) but may allow write skew anomalies where two transactions read overlapping data and write disjoint sets producing an invalid combined state. Serializable isolation requires extra mechanisms (e.g., predicate locking, SSI — Serializable Snapshot Isolation) to eliminate such anomalies, often with higher contention.</p><h2 id="7-concurrency-control-locking-vs-optimistic">7. Concurrency control: locking vs optimistic</h2><h3 id="71-pessimistic-locking">7.1 Pessimistic locking</h3><ul><li>Lock at row or page granularity (shared/exclusive modes).</li><li>Prevents conflicting access upfront.</li><li>Good for workloads with high write contention or long transactions.</li><li>Deadlocks must be detected or prevented (wait-for graph and timeout-based detection).</li></ul><h3 id="72-optimistic-concurrency-control-occ">7.2 Optimistic concurrency control (OCC)</h3><ul><li>Transactions proceed without taking locks, validating at commit time.</li><li>If validation fails (conflicting write), transaction aborts and must retry.</li><li>Works well for workloads with low conflict rates and short transactions.</li></ul><p>Validation approach:</p><ol><li>Read phase: Transaction reads data into local workspace, records read set.</li><li>Validation phase: At commit, ensure no conflicting writes committed since read&rsquo;s start snapshot.</li><li>Write phase: If validation passed, apply updates (often with WAL and commit sync).</li></ol><h3 id="73-hybrid-approaches-and-contention-mitigation">7.3 Hybrid approaches and contention mitigation</h3><ul><li>Short transactions: OCC is effective.</li><li>High contention: Locking or partitioning reduces aborts.</li><li>Partition-based systems: Shard data so many transactions are single-shard and conflict-free.</li></ul><h2 id="8-crash-recovery-redo-undo-and-checkpoints">8. Crash recovery: redo, undo, and checkpoints</h2><p>Recovery ensures the database returns to a durable consistent state after a crash.</p><h3 id="81-aries-like-recovery-widely-used">8.1 ARIES-like recovery (widely used)</h3><p>ARIES (Algorithms for Recovery and Isolation Exploiting Semantics) is a well-known approach built around WAL and page-based logging.</p><p>Phases:</p><ol><li>Analysis: Read the log forward from the last checkpoint to determine the set of losers (in-flight transactions) and dirty pages.</li><li>Redo: Reapply all logged updates from the oldest needed LSN to ensure pages are up-to-date.</li><li>Undo: Roll back incomplete transactions by undoing their logged changes, writing compensation log records (CLRs) so undo is itself redoable.</li></ol><p>Key properties:</p><ul><li>Repeating history during redo ensures idempotence: reapplying the same WAL doesn&rsquo;t change correctness.</li><li>CLRs make the undo phase safe and resumable after subsequent crashes.</li></ul><h3 id="82-checkpointing">8.2 Checkpointing</h3><p>A checkpoint records:</p><ul><li>Dirty page table (which pages may have unflushed changes) and their earliest LSN.</li><li>Transaction table (active transactions and their states).</li></ul><p>Checkpoint frequency trades off recovery time and runtime overhead. More frequent checkpoints reduce recovery time but introduce more I/O.</p><h3 id="83-incremental-and-fuzzy-checkpoints">8.3 Incremental and fuzzy checkpoints</h3><ul><li>Fuzzy checkpoint: Takes a snapshot of in-memory structures without pausing the world; may require more redo work but avoids long pauses.</li><li>Incremental checkpoint: Flushes a subset of dirty pages continuously to avoid large spikes.</li></ul><h2 id="9-replication-and-distributed-transactions">9. Replication and distributed transactions</h2><p>For availability and scale, databases replicate data across nodes.</p><h3 id="91-replication-modes">9.1 Replication modes</h3><ul><li><p>Asynchronous (eventual): Primary applies writes and sends to replicas; commits return before replicas are durable.</p><ul><li>Low write latency, potential data loss if primary fails.</li></ul></li><li><p>Synchronous: Primary waits for acknowledgment from a quorum (or all) replicas before committing.</p><ul><li>Higher latency, stronger durability.</li></ul></li><li><p>Semi-synchronous: Middle ground; primary waits for at least one replica to confirm receipt but not necessarily durable.</p></li></ul><h3 id="92-replication-techniques">9.2 Replication techniques</h3><ul><li>Statement-based replication: Replicate SQL statements (hard to get deterministic behavior).</li><li>Row-based replication: Replicate row changes directly (more reliable but larger bandwidth).</li><li>Logical replication: Replicate logical changes (DML) with transformation capability.</li></ul><h3 id="93-distributed-transactions-and-two-phase-commit-2pc">9.3 Distributed transactions and Two-Phase Commit (2PC)</h3><p>2PC ensures atomic commits across multiple nodes:</p><ol><li>Prepare phase: Coordinator asks participants to prepare; participants vote YES/NO and persist a prepare record to local WAL.</li><li>Commit phase: If all YES, coordinator asks participants to commit; otherwise, it aborts.</li></ol><p>Drawbacks:</p><ul><li>2PC blocks participants if coordinator crashes (can be mitigated with coordinator replicas or 3PC variants).</li><li>Performance overhead: multiple network round trips and syncs.</li></ul><p>Optimizations:</p><ul><li>Presumed commit/abort variants</li><li>Combining 2PC with group commit and batching</li><li>Using Paxos/Raft-based consensus for metadata and leader election instead of naive 2PC</li></ul><h2 id="10-indexes-query-patterns-and-advanced-storage-techniques">10. Indexes, query patterns, and advanced storage techniques</h2><h3 id="101-secondary-and-covering-indexes">10.1 Secondary and covering indexes</h3><ul><li>Secondary index: Index on a non-primary key attribute; requires maintaining index on writes.</li><li>Covering index: Contains all columns required by query; avoids lookup to primary store.</li></ul><p>Tradeoffs:</p><ul><li>More indexes → faster reads, slower and heavier writes (index maintenance), increased storage.</li></ul><h3 id="102-full-text-and-inverted-indexes">10.2 Full-text and inverted indexes</h3><ul><li>Inverted index maps terms to posting lists (document IDs + positions).</li><li>Typically stored as compressed posting lists optimized for scans.</li><li>Writes require updating multiple posting lists; often handled asynchronously or with near-real-time layers (memtables + segment merging).</li></ul><h3 id="103-columnar-storage-and-vectorized-execution">10.3 Columnar storage and vectorized execution</h3><ul><li>Column stores are optimized for analytics: store columns contiguously for compression and SIMD-friendly processing.</li><li>Columnar storage shines for scans and aggregations, often combined with vectorized execution engines to amortize CPU overhead.</li></ul><h3 id="104-compression-and-space-optimization">10.4 Compression and space optimization</h3><ul><li>Compression reduces I/O and memory footprint; common techniques include prefix encoding, dictionary encoding, run-length encoding, and page-level compression.</li><li>Tradeoffs: CPU cost for compress/decompress vs savings in IO and cache utilization.</li></ul><h2 id="11-observability-metrics-and-troubleshooting">11. Observability, metrics, and troubleshooting</h2><p>Monitoring and tools are essential to diagnose performance and correctness issues.</p><h3 id="111-key-runtime-metrics">11.1 Key runtime metrics</h3><ul><li>Throughput (ops/sec) split by reads/writes</li><li>Latency percentiles (p50, p95, p99, p999)</li><li>WAL flush time and fsync latency</li><li>Compaction throughput and queue sizes</li><li>Number of open file descriptors and SSTable count</li><li>Buffer pool hit rate and dirty page counts</li><li>Transaction abort rate and average retries</li></ul><h3 id="112-tracing-and-profiling">11.2 Tracing and profiling</h3><ul><li>Distributed tracing (W3C Trace, OpenTelemetry) for cross-node request flows.</li><li>Flame graphs for CPU hotspots (compaction, WAL writing, encryption/decryption).</li><li>Tools: perf, eBPF-based tracing, database-specific telemetry.</li></ul><h3 id="113-debugging-checklist">11.3 Debugging checklist</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>When investigating database anomalies:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>□ Check disk and fsync latency (iostat, blktrace)
</span></span><span style=display:flex><span>□ Inspect WAL throughput and flush latency
</span></span><span style=display:flex><span>□ Check compaction backlog and rate
</span></span><span style=display:flex><span>□ Monitor background threads and CPU utilization
</span></span><span style=display:flex><span>□ Check buffer pool hit/miss ratios
</span></span><span style=display:flex><span>□ Review recent schema/index changes
</span></span><span style=display:flex><span>□ Search for lock contention and transaction wait graphs
</span></span><span style=display:flex><span>□ Reproduce high-latency query with tracing enabled
</span></span><span style=display:flex><span>□ Capture sample SSTables or pages for offline inspection
</span></span><span style=display:flex><span>□ Verify replication lag and last-applied LSN on replicas
</span></span></code></pre></div><h2 id="12-practical-tuning-and-best-practices">12. Practical tuning and best practices</h2><p>A few concise guidelines for production systems:</p><ul><li>Choose storage engine based on workload: LSM for write-heavy workloads, B-tree for read/scan-heavy workloads with low write amplification sensitivity.</li><li>Tune WAL group commit and commit frequency to balance latency and throughput.</li><li>Provision enough memory for memtables and buffer pools to reduce I/O.</li><li>Use bloom filters and adequate block sizes to optimize point reads in LSM.</li><li>Monitor and configure compaction to avoid large backlogs; tune parallelism conservatively.</li><li>Avoid unbounded long-running transactions; they delay MVCC cleanup and compaction.</li><li>Use appropriate isolation level: start with read-committed or SI, move to serializable only if necessary.</li></ul><h2 id="13-advanced-topics-and-case-studies">13. Advanced topics and case studies</h2><p>This section dives into practical, advanced topics you will encounter in production systems: consensus and leader-based replication, snapshotting and backups, corruption detection and repair, online schema evolution, and real-world engine examples.</p><h3 id="131-consensus-and-leader-based-replication">13.1 Consensus and leader-based replication</h3><p>Distributed databases commonly use a single-writer leader model for simplicity and strong consistency. Two widely-used consensus algorithms provide safe leader election and replicated logs:</p><ul><li>Paxos: A proven but subtle algorithm; the original formulation is complex to implement directly.</li><li>Raft: A more engineer-friendly formulation that provides the same safety properties with clearer invariants (leader election, log replication, membership changes).</li></ul><p>Core ideas:</p><ul><li>Leader election: A candidate solicits votes; the node with the most up-to-date log wins leadership.</li><li>Log replication: Leader appends commands to its log and replicates to followers; commit is when a quorum persists the entry.</li><li>Safety under leader changes: New leader must have the most recent committed prefix to avoid lost commits.</li></ul><p>Practical considerations:</p><ul><li>Synchronous replication to a quorum provides durability guarantees even if some replicas fail but increases commit latency.</li><li>Read-only requests can be served by followers if stale reads are acceptable, or via leader-assisted leases for safe linearizable reads.</li><li>Membership changes (adding/removing replicas) must be done carefully to maintain quorum properties — Raft uses joint consensus for this.</li></ul><h3 id="132-snapshots-backups-and-point-in-time-recovery">13.2 Snapshots, backups, and point-in-time recovery</h3><p>Backups are essential for disaster recovery and long-term retention. Common mechanisms:</p><ul><li>Full snapshot: Copy of data files at a point in time; fast restores but expensive to create.</li><li>Incremental backup: Save only changed pages or SSTables since last snapshot; efficient storage but more complex restores.</li><li>Point-in-time recovery (PITR): Use WAL segments to replay changes up to a desired LSN/ts.</li></ul><p>Practical flow for PITR:</p><ol><li>Restore the latest snapshot.</li><li>Replay WAL incrementally until the target LSN or timestamp.</li><li>Stop recovery and open database for reads/writes at that logical point.</li></ol><p>Storage tips:</p><ul><li>Keep WAL archives and snapshots reproducible and verify checksums after writing.</li><li>Automate periodic verification of restore processes (test restores) to ensure backups are usable.</li></ul><h3 id="133-corruption-detection-checksums-and-repair">13.3 Corruption detection, checksums, and repair</h3><p>Bit-rot and partial writes happen. Defenses include:</p><ul><li>Per-page or per-block checksums: Calculate checksums on write and verify on read.</li><li>Doublewrite buffer (InnoDB pattern): Write page twice to disk (doublewrite area) to avoid torn-page corruption on partial page writes.</li><li>SSTable-level checksums and corruption markers: Detect and skip corrupted files during compaction and replication.</li></ul><p>Repair strategies:</p><ul><li>Replicated systems: Rebuild data from healthy replicas (preferred).</li><li>Single-node systems: Use last-known-good snapshots, or WAL with careful replay and validation.</li><li>Avoid in-place repairs without verification; always prefer rebuilding from verified sources when possible.</li></ul><h3 id="134-online-schema-changes-and-backfill-strategies">13.4 Online schema changes and backfill strategies</h3><p>Schema evolution without downtime is a common requirement. Strategies:</p><ul><li>Expand-only changes: Add new columns with defaults handled lazily (no immediate backfill).</li><li>Backfill in background: Add new index or compute column values with a background job that updates rows while keeping existing writes visible.</li><li>Swap-in pointer: Create new table/index, populate it, then atomically swap metadata pointers so traffic points to the new structure.</li></ul><p>Caveats:</p><ul><li>Long-running backfills can cause contention and trigger compaction or vacuum work; throttle such jobs.</li><li>Ensure transactional visibility semantics during the transition so that readers and writers see a consistent view.</li></ul><h3 id="135-materialized-views-and-incremental-maintenance">13.5 Materialized views and incremental maintenance</h3><p>Materialized views (MVs) cache query results for performance. Maintenance approaches:</p><ul><li>Immediate update: Maintain MV on every write (strong consistency, high write cost).</li><li>Deferred/periodic refresh: Recompute MV on a schedule (lower write cost, eventual freshness).</li><li>Incremental maintenance: Apply diffs using change capture (WAL or change-stream) to update MVs efficiently.</li></ul><p>Incremental maintenance needs careful handling of concurrency and ordering: use the same ordering guarantees as primary data (LSN/commit timestamps) to apply changes safely.</p><h3 id="136-security-encryption-and-access-control">13.6 Security: encryption and access control</h3><ul><li>In-transit encryption: TLS between client and server, and node-to-node encryption for replication.</li><li>At-rest encryption: Encrypt WAL and data files with AES-GCM or similar; manage keys with KMS and rotate keys carefully.</li></ul><p>Performance implications:</p><ul><li>Encryption increases CPU utilization; offloading or dedicated crypto hardware can help.</li><li>Compression then encryption is usually optimal (compress before encrypting).</li></ul><h3 id="137-case-studies-postgres-innodb-and-rocksdb">13.7 Case studies: Postgres, InnoDB, and RocksDB</h3><p>Postgres (WAL/XLOG + checkpoints):</p><ul><li>WAL stores write-ahead records (XLOG) and is flushed on commit depending on synchronous_commit.</li><li>Checkpoints write dirty pages to reduce WAL replay on recovery; checkpoint tuning affects both runtime I/O and recovery time.</li></ul><p>InnoDB (doublewrite + clustered B-tree):</p><ul><li>InnoDB uses a clustered B+tree for primary tables and a doublewrite buffer to prevent torn pages.</li><li>It also supports change buffering (insert buffering) to defer random writes and improve throughput.</li></ul><p>RocksDB (LSM + compaction):</p><ul><li>RocksDB exposes many knobs: memtable size, block size, bloom filters per level, compaction style, and compaction threads.</li><li>It offers universal/levelled/leveled-compaction tradeoffs; tuning requires workload profiling.</li></ul><h3 id="138-multi-region-and-global-considerations">13.8 Multi-region and global considerations</h3><p>Designing for geo-distribution introduces new tradeoffs:</p><ul><li>Latency vs consistency: Synchronous replication across regions increases commit latency dramatically; asynchronous or CRDT-based approaches offer lower latency with weaker consistency.</li><li>Data locality: Route requests to nearest replicas when possible, but be mindful of stale reads.</li><li>Failover automation: Automate leader failover with clear health checks to avoid split-brain.</li></ul><h3 id="139-repair-and-resilience-patterns">13.9 Repair and resilience patterns</h3><ul><li>Self-healing replicas: Nodes detect corruption and request fresh data from healthy peers.</li><li>Read repair: On reads, detect divergence and schedule repairs.</li><li>Re-replication: Maintain redundancy factor by re-copying missing or corrupted shards.</li></ul><h3 id="1310-mvcc-garbage-collection-and-vacuum-strategies">13.10 MVCC garbage collection and vacuum strategies</h3><p>MVCC requires periodic cleanup of old versions to reclaim space and reduce read amplification.</p><ul><li>Conservative vacuuming: Only remove versions when no transaction can possibly need them (safe but may accumulate bloat).</li><li>Aggressive vacuuming: Reclaim space quickly to reduce storage/bloat at the cost of more CPU and IO.</li></ul><p>Postgres example:</p><ul><li>Autovacuum scans tables based on update/delete-rate heuristics and triggers VACUUM to reclaim dead tuples.</li><li>Long-running transactions prevent tuple removal (because their snapshot might still need old versions), causing table bloat and higher autovacuum costs.</li></ul><p>Practical tips:</p><ul><li>Monitor long transactions (pg_stat_activity in Postgres) and alert on transactions older than acceptable thresholds.</li><li>Tune autovacuum thresholds and scale-up autovacuum workers if you have high update rates.</li><li>For LSMs: large numbers of tombstones delay compaction; tune compaction and reduce tombstone retention windows.</li></ul><h3 id="1311-global-ordering-and-timestamp-allocation-spanner-style">13.11 Global ordering and timestamp allocation (Spanner-style)</h3><p>Systems like Google Spanner provide externally-consistent distributed transactions by using a tightly synchronized time API (TrueTime) to assign timestamps.</p><p>Key points:</p><ul><li>TrueTime provides an interval [earliest, latest] for the current physical time, allowing servers to assign conservative commit timestamps that respect causality.</li><li>If a leader assigns a commit timestamp, it may delay commit until the latest allowed time has passed to avoid anomalies — this can add latency but simplifies correctness.</li></ul><p>If you don&rsquo;t have a global clock, logical clocks (Lamport or hybrid logical clocks) plus conservative protocols can be used, but they complicate external consistency guarantees.</p><h3 id="1312-sagas-and-application-level-compensation">13.12 Sagas and application-level compensation</h3><p>Not all distributed business workflows require ACID across services. Sagas are a pattern for long-lived distributed operations using compensating actions:</p><ul><li>Each step is a local transaction; if any step fails, run compensating transactions on completed steps to undo effects.</li><li>Requires idempotent compensating actions and careful ordering.</li></ul><p>Use-cases:</p><ul><li>Multi-service order fulfillment where each microservice commits locally, and occasional compensating refunds are acceptable.</li><li>When acceptably eventual correctness and high availability trump strict atomicity.</li></ul><h3 id="1313-benchmarking-and-realistic-load-testing">13.13 Benchmarking and realistic load testing</h3><p>Synthetic microbenchmarks are useful for isolating parts of the stack, but realistic testing must mirror production workloads. Key considerations:</p><ul><li>Use representative data sizes, distributions (zipfian, uniform), and operation mixes (read/write ratio).</li><li>Measure latency percentiles (p50/p95/p99/p999), not just averages.</li><li>Include background tasks (compaction, checkpoint) in test to measure interference.</li></ul><p>Tools and commands:</p><ul><li><p>YCSB for key-value workloads: tune thread count, request distribution, and record count.</p></li><li><p>sysbench for OLTP-like workloads on MySQL/Postgres:</p><p>sysbench oltp_read_write &ndash;threads=128 &ndash;time=600 &ndash;tables=32 &ndash;table-size=100000 run</p></li><li><p>For RocksDB: built-in db_bench with options for writes, compaction threads, and bloom filters.</p></li></ul><p>Interpretation:</p><ul><li>A slight throughput increase with a big latency tail (p99 spike) often signals contention or background work. Investigate blocking activities (fsync, compaction) at those times.</li><li>Long tail latencies deserve attention even if average latency is acceptable.</li></ul><h3 id="1314-practical-recovery-walkthrough-example">13.14 Practical recovery walkthrough (example)</h3><p>A high-level recovery flow for a crashed primary:</p><ol><li>Failover orchestration: Coordinator promotes a healthy replica (ensure it has recent LSN and is consistent).</li><li>Recover crashed node: Restore last known-good snapshot, replay WAL logs to catch up to a safe LSN, run consistency checks.</li><li>Re-join as a replica: Begin streaming WALs from new leader and confirm replication lag returns to low levels.</li></ol><p>Commands (example for Postgres):</p><ul><li>Inspect WAL and checkpoints: <code>pg_controldata</code> and <code>pg_waldump</code> (or <code>pg_wal</code> helpers).</li><li>Restore from base backup: <code>pg_basebackup</code> followed by WAL replay or using <code>pg_restore</code> for logical backups.</li></ul><p>For RocksDB:</p><ul><li>Use <code>ldb</code>/<code>sst_dump</code> for inspecting SSTables and <code>repair</code> to rebuild if metadata is inconsistent (prefer rebuilding from healthy replicas if possible).</li></ul><h3 id="1315-final-notes-on-operational-hygiene">13.15 Final notes on operational hygiene</h3><ul><li>Automate recovery drills and test restores frequently.</li><li>Keep WAL archives for the retention window required by compliance and business needs.</li><li>Make configuration changes with canary rollouts to observe effects before global rollout.</li></ul><h2 id="14-final-checklist-and-best-practices">14. Final checklist and best practices</h2><p>A condensed checklist to run through during diagnosis or design:</p><ul><li>Architecture: Is the chosen storage model (LSM vs B-tree) aligned with the workload?</li><li>Durability: Are WAL flush and replication settings enforcing your durability goals?</li><li>Concurrency: Are transaction length and isolation tuned to avoid long-lived snapshots?</li><li>Observability: Do you capture WAL, compaction, and checkpoint metrics and alerts?</li><li>Backups: Do you have automated, tested snapshots and WAL archival for PITR?</li><li>Corruption handling: Are checksums, replication health, and repair workflows defined and tested?</li></ul><p>A condensed checklist to run through during diagnosis or design:</p><ul><li>Architecture: Is the chosen storage model (LSM vs B-tree) aligned with the workload?</li><li>Durability: Are WAL flush and replication settings enforcing your durability goals?</li><li>Concurrency: Are transaction length and isolation tuned to avoid long-lived snapshots?</li><li>Observability: Do you capture WAL, compaction, and checkpoint metrics and alerts?</li><li>Backups: Do you have automated, tested snapshots and WAL archival for PITR?</li><li>Corruption handling: Are checksums, replication health, and repair workflows defined and tested?</li></ul><h2 id="15-summary-and-final-thoughts">15. Summary and final thoughts</h2><p>Database internals are a rich collection of engineering solutions designed to make storage fast, available, and correct. From the micro-optimizations inside a page to the global tradeoffs of cross-region replication, every design choice has measurable consequences. By understanding these mechanisms — WAL, memtables, SSTables, B-trees, MVCC, compaction, checkpoints, and consensus — you can make informed design and operational decisions that meet your application&rsquo;s needs.</p><h3 id="151-quick-troubleshooting-checklist">15.1 Quick troubleshooting checklist</h3><div class="highlight"><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class="language-text" data-lang=text><span style=display:flex><span>□ Is WAL flush latency high?
</span></span><span style=display:flex><span>□ Are compaction threads saturated?
</span></span><span style=display:flex><span>□ Are there many long-running transactions preventing cleanup?
</span></span><span style=display:flex><span>□ Is replication lag growing on any node?
</span></span><span style=display:flex><span>□ Are buffer pool misses causing excessive disk reads?
</span></span><span style=display:flex><span>□ Are fsyncs or disk I/O the limiting factor?
</span></span><span style=display:flex><span>□ Do you have automated, tested restores from snapshots and WAL?
</span></span></code></pre></div><p>With these advanced topics and practical checklists you should be equipped to reason about database behavior under load, tune storage systems for your workloads, and design resilient architectures for production use.</p></div><footer class="ce1a612 c6dfb1e c3ecea6"><div class="c364589">Categories:
<a href=/categories/fundamentals/>fundamentals</a>, <a href=/categories/systems/>systems</a></div><div>Tags:
<a href=/tags/databases/>#databases</a>, <a href=/tags/storage/>#storage</a>, <a href=/tags/mvcc/>#mvcc</a>, <a href=/tags/transactions/>#transactions</a>, <a href=/tags/replication/>#replication</a>, <a href=/tags/fundamentals/>#fundamentals</a></div></footer></article></main><footer class="ccdf0e8" role=contentinfo aria-label=Footer><div class="cfdda01 c133889 c5df473 c0eecc8 c69618a c6942b3 c03620d c2a9f27 c7c11d8 c82c52d c14527b"><div class="c6dfb1e c3ecea6 c39ef11 c88ae6f">&copy; 2026 Leonardo Benicio. All rights
reserved.</div><div class="c6942b3 c7c11d8 cd1fd22"><a href=https://github.com/lbenicio target=_blank rel="noopener noreferrer" aria-label=GitHub class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 22v-4a4.8 4.8.0 00-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35.0-3.5.0.0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35.0 3.5A5.403 5.403.0 004 9c0 3.5 3 5.5 6 5.5-.39.5-.67 1.08-.82 1.7s-.2 1.27-.18 1.9V22"/></svg>
<span class="cba5854">GitHub</span>
</a><a href=https://www.linkedin.com/in/leonardo-benicio target=_blank rel="noopener noreferrer" aria-label=LinkedIn class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452H17.21V14.86c0-1.333-.027-3.046-1.858-3.046-1.86.0-2.145 1.45-2.145 2.948v5.69H9.069V9h3.112v1.561h.044c.434-.82 1.494-1.686 3.074-1.686 3.29.0 3.897 2.165 3.897 4.983v6.594zM5.337 7.433a1.805 1.805.0 11-.002-3.61 1.805 1.805.0 01.002 3.61zM6.763 20.452H3.911V9h2.852v11.452z"/></svg>
<span class="cba5854">LinkedIn</span>
</a><a href=https://twitter.com/lbenicio_ target=_blank rel="noopener noreferrer" aria-label=Twitter class="c1d6c20 c7c11d8 c1d0018 cd1fd22 cb5c327 c10dda9 c6dfb1e cbbda39 cfc01c7 c01f421 c286dd7 c2bd687 cfdce1d cfef18f c000b66 cf55a7b c514027"><svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M19.633 7.997c.013.177.013.354.013.53.0 5.386-4.099 11.599-11.6 11.599-2.31.0-4.457-.676-6.265-1.842.324.038.636.05.972.05 1.91.0 3.67-.65 5.07-1.755a4.099 4.099.0 01-3.827-2.84c.25.039.5.064.763.064.363.0.726-.051 1.065-.139A4.091 4.091.0 012.542 9.649v-.051c.538.3 1.162.482 1.824.507A4.082 4.082.0 012.54 6.7c0-.751.2-1.435.551-2.034a11.63 11.63.0 008.44 4.281 4.615 4.615.0 01-.101-.938 4.091 4.091.0 017.078-2.799 8.1 8.1.0 002.595-.988 4.112 4.112.0 01-1.8 2.261 8.2 8.2.0 002.357-.638A8.824 8.824.0 0119.613 7.96z"/></svg>
<span class="cba5854">Twitter</span></a></div></div></footer></body></html>