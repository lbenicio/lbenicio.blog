<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Storage on Leonardo Benicio</title><link>https://lbenicio.dev/tags/storage/</link><description>Recent content in Storage on Leonardo Benicio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 04 Oct 2025 10:00:00 +0000</lastBuildDate><atom:link href="https://lbenicio.dev/tags/storage/index.xml" rel="self" type="application/rss+xml"/><item><title>Learned Indexes: When Models Replace B‑Trees</title><link>https://lbenicio.dev/blog/learned-indexes-when-models-replace-btrees/</link><pubDate>Sat, 04 Oct 2025 10:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/learned-indexes-when-models-replace-btrees/</guid><description>&lt;p&gt;If you’ve spent a career trusting B‑trees and hash tables, the idea of using a machine‑learned model as an index can feel like swapping a torque wrench for a Ouija board. But learned indexes aren’t a gimmick. They exploit a simple observation: real data isn’t uniformly random. It has shape—monotonic keys, skewed distributions, natural clusters—and a model can learn that shape to predict where a key lives in a sorted array. The payoff is smaller indexes, fewer cache misses, and—sometimes—dramatically faster lookups.&lt;/p&gt;</description></item><item><title>GPUDirect Storage in 2025: Optimizing the End-to-End Data Path</title><link>https://lbenicio.dev/blog/gpudirect-storage-in-2025-optimizing-the-end-to-end-data-path/</link><pubDate>Tue, 16 Sep 2025 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/gpudirect-storage-in-2025-optimizing-the-end-to-end-data-path/</guid><description>&lt;p&gt;High-performance analytics and training pipelines increasingly hinge on how &lt;em&gt;fast&lt;/em&gt; and &lt;em&gt;efficiently&lt;/em&gt; data reaches GPU memory. Compute has outpaced I/O: a single multi-GPU node can sustain tens of TFLOPs while starved by a few misconfigured storage or copy stages. GPUDirect Storage (GDS) extends the GPUDirect family (peer-to-peer, RDMA) to allow DMA engines (NVMe, NIC) to move bytes directly between storage and GPU memory—bypassing redundant copies through host DRAM and reducing CPU intervention.&lt;/p&gt;</description></item><item><title>Merkle Trees and Content‑Addressable Storage</title><link>https://lbenicio.dev/blog/merkle-trees-and-contentaddressable-storage/</link><pubDate>Mon, 17 Aug 2020 10:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/merkle-trees-and-contentaddressable-storage/</guid><description>&lt;p&gt;Hash the content, not the location—that’s the core of content‑addressable storage (CAS). Combine it with Merkle trees (or DAGs) and you get efficient verification, deduplication, and synchronization. This post connects the dots from Git to large‑scale object stores.&lt;/p&gt;
&lt;h2 id="why-merkle"&gt;Why Merkle?&lt;/h2&gt;
&lt;p&gt;Parent hashes commit to child hashes; any change percolates up. You can verify integrity by checking a root hash and a short proof path.&lt;/p&gt;
&lt;h2 id="uses"&gt;Uses&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Git commits and trees; shallow clones via missing subtrees.&lt;/li&gt;
&lt;li&gt;Package managers with integrity checks.&lt;/li&gt;
&lt;li&gt;Deduplicated backups with chunking and rolling hashes.&lt;/li&gt;
&lt;li&gt;Object stores that replicate by exchanging missing subgraphs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="practical-notes"&gt;Practical notes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Hash choice (SHA‑256 vs BLAKE3) affects speed and hardware support.&lt;/li&gt;
&lt;li&gt;Chunking strategy controls dedupe granularity; rolling fingerprints (Rabin) find natural boundaries.&lt;/li&gt;
&lt;li&gt;Store metadata alongside blobs to avoid rehashing for trivial changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="1-from-trees-to-dags-modeling-versions-that-share-content"&gt;1) From trees to DAGs: modeling versions that share content&lt;/h2&gt;
&lt;p&gt;Classic Merkle trees have a fixed arity and two kinds of nodes: leaves containing hashes of fixed‑size blocks, and internal nodes containing hashes of their children. In real systems, multiple versions of content share substructure: two versions of a directory share most files, two backups share most chunks, two container images share many layers. That sharing naturally forms a directed acyclic graph (DAG) where a node can be referenced from multiple parents. The root is still a commitment to the whole, but now many roots can reference common subgraphs without duplication.&lt;/p&gt;</description></item></channel></rss>