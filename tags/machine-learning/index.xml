<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine-Learning on Leonardo Benicio</title><link>https://lbenicio.dev/tags/machine-learning/</link><description>Recent content in Machine-Learning on Leonardo Benicio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 04 Oct 2025 10:00:00 +0000</lastBuildDate><atom:link href="https://lbenicio.dev/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Learned Indexes: When Models Replace B‑Trees</title><link>https://lbenicio.dev/blog/learned-indexes-when-models-replace-btrees/</link><pubDate>Sat, 04 Oct 2025 10:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/learned-indexes-when-models-replace-btrees/</guid><description>&lt;p&gt;If you’ve spent a career trusting B‑trees and hash tables, the idea of using a machine‑learned model as an index can feel like swapping a torque wrench for a Ouija board. But learned indexes aren’t a gimmick. They exploit a simple observation: real data isn’t uniformly random. It has shape—monotonic keys, skewed distributions, natural clusters—and a model can learn that shape to predict where a key lives in a sorted array. The payoff is smaller indexes, fewer cache misses, and—sometimes—dramatically faster lookups.&lt;/p&gt;</description></item><item><title>Keeping the Model Awake: Building a Self-Healing ML Inference Platform</title><link>https://lbenicio.dev/blog/keeping-the-model-awake-building-a-self-healing-ml-inference-platform/</link><pubDate>Tue, 14 Feb 2023 07:20:00 +0000</pubDate><guid>https://lbenicio.dev/blog/keeping-the-model-awake-building-a-self-healing-ml-inference-platform/</guid><description>&lt;p&gt;During a winter holiday freeze, our recommendation API refused to scale. GPUs idled waiting for models to load, autoscalers fought each other, and on-call engineers reheated leftovers at 3 a.m. while spike traffic slammed into origin. We promised leadership that this would never happen again. The solution wasn&amp;rsquo;t magic; it was a self-healing inference platform blending old-school reliability, modern ML tooling, and relentless experimentation.&lt;/p&gt;
&lt;p&gt;This post documents the rebuild. We&amp;rsquo;ll explore model packaging, warm-up rituals, adaptive scheduling, observability, chaos drills, and the social contract between ML researchers and production engineers. The goal: keep models awake, snappy, and trustworthy even when the world throws curveballs.&lt;/p&gt;</description></item><item><title>Artificial Intelligence: A Modern Approach (4th ed.)</title><link>https://lbenicio.dev/reading/artificial-intelligence-a-modern-approach-4th-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/artificial-intelligence-a-modern-approach-4th-ed./</guid><description>&lt;p&gt;Definitive textbook on AI covering search, knowledge, planning, learning, and applications.&lt;/p&gt;</description></item></channel></rss>